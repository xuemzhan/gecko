import asyncio
import os
from typing import Any, Dict

from pydantic import BaseModel, Field

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from gecko.core.agent import Agent
from gecko.core.message import Message
from gecko.core.memory import TokenMemory
from gecko.core.toolbox import ToolBox
from gecko.core.engine.react import ReActEngine
from gecko.plugins.tools.base import BaseTool
from gecko.plugins.models.zhipu import ZhipuGLM, glm_4_5_air

# ==========================================
# 1. å®šä¹‰ç®€å•çš„å·¥å…·
# ==========================================

class CalculatorTool(BaseTool):
    name: str = "calculator"
    description: str = "Useful for performing basic arithmetic operations. Input should be a math expression string."
    parameters: Dict[str, Any] = {
        "type": "object",
        "properties": {
            "expression": {
                "type": "string",
                "description": "The math expression to evaluate, e.g., '2 + 2'"
            }
        },
        "required": ["expression"]
    }

    async def execute(self, arguments: Dict[str, Any]) -> str:
        expression = arguments.get("expression")
        try:
            # æ³¨æ„ï¼ševal åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ˜¯ä¸å®‰å…¨çš„ï¼Œä»…ç”¨äºæ¼”ç¤º
            return str(eval(expression))
        except Exception as e:
            return f"Error: {str(e)}"

class WeatherTool(BaseTool):
    name: str = "get_current_weather"
    description: str = "Get the current weather in a given location"
    parameters: Dict[str, Any] = {
        "type": "object",
        "properties": {
            "location": {
                "type": "string",
                "description": "The city and state, e.g. San Francisco, CA"
            },
            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
        },
        "required": ["location"]
    }

    async def execute(self, arguments: Dict[str, Any]) -> str:
        location = arguments.get("location")
        return f"The weather in {location} is sunny and 25Â°C."

# ==========================================
# 2. å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
# ==========================================

class AnalysisReport(BaseModel):
    """åˆ†ææŠ¥å‘Šç»“æ„"""
    summary: str = Field(description="å¯¹ç”¨æˆ·é—®é¢˜çš„ç®€çŸ­æ€»ç»“")
    action_items: list[str] = Field(description="å»ºè®®é‡‡å–çš„è¡ŒåŠ¨é¡¹åˆ—è¡¨")
    priority: str = Field(description="ä¼˜å…ˆçº§ (High/Medium/Low)")

# ==========================================
# 3. ä¸»æ¼”ç¤ºæµç¨‹
# ==========================================

async def main():
    # 1. åˆå§‹åŒ–æ¨¡å‹ (ä½¿ç”¨æä¾›çš„ ZhipuGLM å®ç°)
    # è¯·ç¡®ä¿ ZHIPU_API_KEY ç¯å¢ƒå˜é‡å·²è®¾ç½®ï¼Œæˆ–è€…åœ¨æ„é€ å‡½æ•°ä¸­ä¼ å…¥
    api_key = os.getenv("ZHIPU_API_KEY", "3bd5e6fdc377489c80dbb435b84d7560.izN8bDXCVR1FNSYS")
    llm = ZhipuGLM(api_key=api_key, model="glm-4-flash") # ä½¿ç”¨ flash æ¨¡å‹é€Ÿåº¦æ›´å¿«

    # 2. åˆå§‹åŒ–å·¥å…·ç®±
    toolbox = ToolBox(tools=[CalculatorTool(), WeatherTool()])

    # 3. åˆå§‹åŒ–è®°å¿†
    memory = TokenMemory(session_id="react_demo_session", max_tokens=2000)

    # 4. æ„å»º Agent (ä½¿ç”¨ ReActEngine)
    agent = Agent(
        model=llm,
        toolbox=toolbox,
        memory=memory,
        engine_cls=ReActEngine,
        max_turns=5 # é™åˆ¶æœ€å¤§æ€è€ƒè½®æ•°
    )

    print("\nğŸš€ ReAct Agent Demo (Powered by ZhipuGLM)\n")

    # --- åœºæ™¯ 1: éœ€è¦ä½¿ç”¨å·¥å…·çš„å¤æ‚æŸ¥è¯¢ ---
    query1 = "What is 123 * 45? Also, what's the weather in Beijing?"
    print(f"ğŸ‘¤ User: {query1}")
    print("ğŸ¤– Agent (Thinking...):")
    
    # ä½¿ç”¨ run() æ–¹æ³• (éæµå¼)
    response1 = await agent.run(query1)
    print(f"ğŸ’¡ Final Answer: {response1.content}\n")
    
    # æŸ¥çœ‹ç»Ÿè®¡ (ReActEngine ä¼šè®°å½•å·¥å…·è°ƒç”¨)
    if agent.engine.stats:
        print(f"ğŸ“Š Stats: Steps={agent.engine.stats.total_steps}, ToolCalls={agent.engine.stats.tool_calls}")

    print("-" * 50)

    # --- åœºæ™¯ 2: ç»“æ„åŒ–è¾“å‡º ---
    query2 = "Based on the weather in Beijing, suggest a weekend plan."
    print(f"\nğŸ‘¤ User: {query2} (Requesting Structured Output)")
    
    # ä½¿ç”¨ run() å¹¶æŒ‡å®š response_model
    result = await agent.run(query2, response_model=AnalysisReport)
    print(f"ğŸ“¦ Structured Result:\n{result.model_dump_json(indent=2)}\n")

    print("-" * 50)

    # --- åœºæ™¯ 3: æµå¼è¾“å‡º ---
    query3 = "Tell me a short story about a Gecko programmer."
    print(f"\nğŸ‘¤ User: {query3} (Streaming Mode)")
    print("ğŸŒŠ Stream: ", end="", flush=True)
    
    async for chunk in agent.stream(query3):
        print(chunk, end="", flush=True)
    print("\n")

if __name__ == "__main__":
    # ç¡®ä¿å®‰è£…äº† litellm
    # pip install litellm
    asyncio.run(main())