[1] examples/compose/team_demo.py
```python
# examples/team_demo.py
"""
Team å¤šæ™ºèƒ½ä½“åä½œç¤ºä¾‹ (Updated for V0.2)

å±•ç¤º Gecko Team å¼•æ“çš„å¹¶è¡Œå¤„ç†èƒ½åŠ›ï¼š
1. ä¸“å®¶è¯„å®¡å›¢æ¨¡å¼ (Panel of Experts)
2. å¹¶å‘æ§åˆ¶ (Rate Limiting)
3. å®¹é”™æœºåˆ¶ (Partial Failure) -> [Updated] ä½¿ç”¨ MemberResult å¤„ç†ç»“æœ
4. ç»“æœèšåˆ (Aggregation)

è¿è¡Œå‰æï¼š
    export ZHIPU_API_KEY="your_api_key"
"""
from __future__ import annotations

import asyncio
import os
from typing import List

# [Updated] å¼•å…¥ MemberResult ç”¨äºç±»å‹å®‰å…¨çš„å¤„ç†
from gecko.compose.team import Team, MemberResult
from gecko.core.agent import Agent
from gecko.core.builder import AgentBuilder
from gecko.core.logging import get_logger
# [Updated] ä½¿ç”¨æ–°çš„æ¨¡å‹ç±»
from gecko.plugins.models.presets.zhipu import ZhipuChat

logger = get_logger(__name__)


# ========================= 1. è¾…åŠ©å‡½æ•° =========================

def create_expert(role: str, prompt: str, api_key: str) -> Agent:
    """
    åˆ›å»ºä¸€ä¸ªç‰¹å®šè§’è‰²çš„ä¸“å®¶ Agent
    """
    # [Updated] ä½¿ç”¨ ZhipuChat ç±»å®ä¾‹åŒ–
    model = ZhipuChat(api_key=api_key, model="glm-4-air", temperature=0.8)
    
    return (
        AgentBuilder()
        .with_model(model)
        .with_session_id(f"expert_{role}")
        .with_system_prompt(f"ä½ æ˜¯ä¸€ä½{role}ã€‚{prompt} è¯·ç®€çŸ­å›ç­”ï¼ˆ50å­—ä»¥å†…ï¼‰ã€‚")
        .build()
    )


async def aggregate_results(results: List[MemberResult]) -> str:
    """
    èšåˆå‡½æ•°ï¼šå°†å›¢é˜Ÿçš„æ„è§æ±‡æ€»
    [Updated] é€‚é… MemberResult ç»“æ„ï¼Œæ˜¾å¼æ£€æŸ¥æˆåŠŸçŠ¶æ€
    """
    summary = []
    # Team.run ç°åœ¨è¿”å› List[MemberResult]
    for res in results:
        i = res.member_index + 1
        
        if res.is_success:
            # æˆåŠŸï¼šç›´æ¥è·å– result (Team é»˜è®¤ä¼šæå– content)
            summary.append(f"ä¸“å®¶ {i}: {res.result}")
        else:
            # å¤±è´¥ï¼šä» error å­—æ®µè·å–ä¿¡æ¯
            summary.append(f"ä¸“å®¶ {i}: [ç¼ºå¸­] (Error: {res.error})")
            
    return "\n".join(summary)


# ========================= 2. ä¸»æµç¨‹ =========================

async def main():
    api_key = os.environ.get("ZHIPU_API_KEY")
    if not api_key:
        logger.error("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ ZHIPU_API_KEY")
        return

    logger.info("ğŸš€ åˆå§‹åŒ–ä¸“å®¶è¯„å®¡å›¢...")

    # 1. ç»„å»ºå›¢é˜Ÿ
    # å®šä¹‰ä¸‰ä¸ªä¸åŒè§†è§’çš„ä¸“å®¶
    optimist = create_expert(
        "ä¹è§‚ä¸»ä¹‰æœªæ¥å­¦å®¶", 
        "è¯·å¯¹æœªæ¥çš„ AI å‘å±•ç»™å‡ºä¸€ä¸ªæå…¶ä¹è§‚çš„é¢„æµ‹ã€‚", 
        api_key
    )
    
    pessimist = create_expert(
        "æ‚²è§‚ä¸»ä¹‰å®‰å…¨ä¸“å®¶", 
        "è¯·è­¦å‘Šäººç±» AI å¯èƒ½å¸¦æ¥çš„æœ€å¤§ç”Ÿå­˜é£é™©ã€‚", 
        api_key
    )
    
    realist = create_expert(
        "åŠ¡å®å·¥ç¨‹å¸ˆ", 
        "è¯·ä»æŠ€æœ¯è½åœ°è§’åº¦è¯„ä¼°æœªæ¥ 5 å¹´ AI çš„å®é™…åº”ç”¨ã€‚", 
        api_key
    )

    # 2. åˆ›å»º Team å¼•æ“
    # è®¾ç½® max_concurrent=2ï¼Œæ¼”ç¤ºæµé‡æ•´å½¢
    team = Team(
        members=[optimist, pessimist, realist],
        name="AI_Review_Board",
        max_concurrent=2
    )

    topic = "æˆ‘ä»¬åº”è¯¥å¦‚ä½•çœ‹å¾… AGI çš„åˆ°æ¥ï¼Ÿ"
    print(f"\nğŸ™ï¸ è®®é¢˜: {topic}\n")

    # 3. å¹¶è¡Œæ‰§è¡Œ
    # [Updated] Team.run è¿”å› List[MemberResult]
    member_results = await team.run(topic)

    # 4. ç»“æœå±•ç¤º
    print("-" * 20 + " è¯„å®¡ç»“æœ " + "-" * 20)
    final_report = await aggregate_results(member_results)
    print(final_report)
    print("-" * 50)


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—çº§åˆ«ä»¥ä¾¿è§‚å¯Ÿ Team çš„å¹¶å‘æ‰§è¡Œæ—¥å¿—
    import logging
    logging.basicConfig(level=logging.INFO)
    
    asyncio.run(main())
```

[2] examples/compose/workflow_dag_demo.py
```python
# examples/workflow_dag.py
import asyncio
import os
from typing import List

from gecko.compose.workflow import Workflow
from gecko.compose.nodes import step, Next
# [Refactor Note] å¼•å…¥ MemberResult
from gecko.compose.team import Team, MemberResult
from gecko.core.builder import AgentBuilder
from gecko.core.message import Message
# [Refactor Note] ä½¿ç”¨æ–°çš„ Model Preset ç±»
from gecko.plugins.models.presets.zhipu import ZhipuChat 

# æ£€æŸ¥ API Key
api_key = os.getenv("ZHIPU_API_KEY")
if not api_key:
    print("âš ï¸ Warning: ZHIPU_API_KEY not found in env. Mocking behavior might be needed.")

# å·¥å‚å‡½æ•°ï¼šåˆ›å»ºæ–°çš„ Agent å®ä¾‹
def make_agent(role_name: str = "Assistant"):
    # [Refactor] ä½¿ç”¨ ZhipuChat ç±»
    model = ZhipuChat(api_key=api_key, model="glm-4-flash", temperature=0.7) # type: ignore
    return AgentBuilder().with_model(model).with_session_id(f"agent_{role_name}").build()

@step("research")
async def research(context):
    """
    è°ƒç ”èŠ‚ç‚¹ï¼šä¼˜å…ˆä½¿ç”¨ä¸Šä¸€è½®çš„åé¦ˆï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨åˆå§‹è¾“å…¥
    """
    # 1. å°è¯•è·å–ä¸Šä¸€æ­¥ä¼ æ¥çš„â€œä¿®æ­£æŒ‡ä»¤â€ï¼ˆç”± Next.input æ³¨å…¥åˆ° last_outputï¼‰
    # 2. å¦‚æœæ²¡æœ‰ï¼Œä½¿ç”¨å…¨å±€åˆå§‹è¾“å…¥ context.input
    topic = context.get_last_output()
    
    # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œlast_output é»˜è®¤ä¸º input
    # å¦‚æœæ˜¯ä» Loop å›è·³è¿‡æ¥ï¼Œlast_output æ˜¯ "new_prompt"
    
    print(f"\nğŸ” [Research] æ­£åœ¨è°ƒç ”: {topic}")
    
    agent = make_agent("Researcher")
    output = await agent.run([Message(role="user", content=f"{topic}")])
    return output.content # type: ignore

# å®šä¹‰ Team èŠ‚ç‚¹
# [Refactor] Team ç°åœ¨æ˜¯ç±»å‹å®‰å…¨çš„ï¼Œæˆå‘˜å¯ä»¥æ˜¯ Agent
team_node = Team(members=[make_agent("Reviewer_1"), make_agent("Reviewer_2")], name="ReviewBoard")

@step("check_quality")
async def check_quality(context):
    """
    è´¨æ£€èŠ‚ç‚¹ï¼šå†³å®šæ˜¯å¦é€šè¿‡ï¼Œæˆ–è€…æ‰“å›é‡åš
    """
    # Team çš„è¾“å‡ºåœ¨ history ä¸­ï¼Œkey æ˜¯èŠ‚ç‚¹å "team_review"
    raw_result = context.history.get("team_review")
    
    # [Refactor Note] Team ç°åœ¨è¿”å› List[MemberResult]
    combined_text = ""
    if isinstance(raw_result, list):
        valid_contents = []
        for res in raw_result:
            # æ˜¾å¼æ£€æŸ¥ç±»å‹å’ŒæˆåŠŸçŠ¶æ€
            if isinstance(res, MemberResult):
                if res.is_success:
                    valid_contents.append(str(res.result))
                else:
                    print(f"âš ï¸ å¿½ç•¥å¤±è´¥çš„ä¸“å®¶æ„è§: {res.error}")
        combined_text = "\n---\n".join(valid_contents)
    else:
        # é˜²å¾¡æ€§ä»£ç 
        combined_text = str(raw_result)
        
    text_len = len(combined_text)
    print(f"ğŸ§ [Check] å½“å‰æœ‰æ•ˆå†…å®¹é•¿åº¦: {text_len} å­—ç¬¦")

    # è·å–æˆ–åˆå§‹åŒ–å¾ªç¯è®¡æ•°å™¨ (ä½¿ç”¨ WorkflowContext.state)
    loop_count = context.state.get("loop_count", 0)
    
    # è®¾å®šé˜ˆå€¼ï¼šæ¯”å¦‚é•¿åº¦å°äº 100 ä¸”é‡è¯•æ¬¡æ•°å°‘äº 2 æ¬¡
    if text_len < 100 and loop_count < 2:
        new_count = loop_count + 1
        # æ›´æ–°çŠ¶æ€
        context.state["loop_count"] = new_count
        print(f"âš ï¸ [Check] å†…å®¹å¤ªçŸ­ï¼Œç¬¬ {new_count} æ¬¡æ‰“å›é‡åš...")
        
        new_prompt = f"ä¹‹å‰çš„å†…å®¹å¤ªçŸ­äº†ï¼ˆåªæœ‰{text_len}å­—ï¼‰ã€‚è¯·é’ˆå¯¹ '{context.input}' å†™ä¸€ç¯‡ä¸å°‘äº 200 å­—çš„è¯¦ç»†åˆ†ææŠ¥å‘Šã€‚"
        
        # è¿”å› Next æŒ‡ä»¤ï¼š
        # - node: è·³è½¬å› research èŠ‚ç‚¹
        # - input: å°† new_prompt ä¼ é€’ç»™ research èŠ‚ç‚¹
        # - [Phase 2 Feature] ä¹Ÿå¯ä»¥ä½¿ç”¨ update_state={"loop_count": new_count} æ¥æ›´æ–°çŠ¶æ€
        return Next(node="research", input=new_prompt)
    
    print("âœ… [Check] è´¨é‡è¾¾æ ‡ (æˆ–å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°)")
    return f"æœ€ç»ˆæŠ¥å‘Š (ç»è¿‡ {loop_count} æ¬¡ä¿®æ­£):\n{combined_text}"

async def main():
    # [Phase 2 Feature] æ˜¾å¼å¼€å¯ allow_cyclesï¼Œè™½ç„¶è¿™é‡Œæˆ‘ä»¬ç”¨ Next è·³è½¬ï¼Œä½†è¿™æ˜¯æ¨èåšæ³•
    workflow = Workflow("ResearchLoop", allow_cycles=True)
    
    # 1. æ³¨å†ŒèŠ‚ç‚¹
    workflow.add_node("research", research)
    workflow.add_node("team_review", team_node)
    workflow.add_node("check", check_quality)
    
    # 2. å®šä¹‰æµå‘
    workflow.set_entry_point("research")
    workflow.add_edge("research", "team_review")
    workflow.add_edge("team_review", "check")
    # check -> research çš„è¾¹ç”±ä»£ç é€»è¾‘åŠ¨æ€æ§åˆ¶ (Next)
    
    print("ğŸš€ å¯åŠ¨å·¥ä½œæµ...")
    
    if not api_key:
        print("ğŸš« ç¼ºå°‘ API Keyï¼Œæ¼”ç¤ºå°†å¤±è´¥æˆ–ä½¿ç”¨ Mock æ•°æ®ã€‚")
        return

    # åˆå§‹è¾“å…¥ç®€å•ä¸€ç‚¹ï¼Œæ•…æ„è¯±å¯¼ç¬¬ä¸€æ¬¡ç”Ÿæˆè¾ƒçŸ­çš„å†…å®¹
    output = await workflow.execute("ç®€è¿° AI Agent")
    print("\nğŸ‰ å·¥ä½œæµç»“æŸ Result:\n", output)

if __name__ == "__main__":
    asyncio.run(main())
```

[3] examples/compose/workflow_demo.py
```python
# examples/workflow_demo.py
"""
Workflow ç¼–æ’ç¤ºä¾‹ (Updated for V0.2)

å±•ç¤º Gecko Workflow å¼•æ“çš„æ ¸å¿ƒç‰¹æ€§ï¼š
1. æ¡ä»¶åˆ†æ”¯ (Conditional Branching)
2. å¾ªç¯ä¸è·³è½¬ (Next Instruction)
3. [Updated] çŠ¶æ€è‡ªåŠ¨æ›´æ–° (Next.update_state) - Phase 2 æ–°ç‰¹æ€§
4. [Updated] æ˜¾å¼å¾ªç¯æ”¯æŒ (allow_cycles) - Phase 2 æ–°ç‰¹æ€§

è¿è¡Œå‰æï¼š
    export ZHIPU_API_KEY="your_api_key"
"""
from __future__ import annotations

import asyncio
import os
from typing import Any

from gecko.compose.nodes import Next, step
from gecko.compose.workflow import Workflow, WorkflowContext
from gecko.core.agent import Agent
from gecko.core.builder import AgentBuilder
from gecko.core.logging import get_logger
# [Updated] ä½¿ç”¨æ–°çš„æ¨¡å‹ç±»
from gecko.plugins.models.presets.zhipu import ZhipuChat

logger = get_logger(__name__)


# ========================= 1. å®šä¹‰èŠ‚ç‚¹ =========================

@step(name="InputAnalyzer")
async def analyze_input(user_input: str, context: WorkflowContext):
    """
    èŠ‚ç‚¹ 1: åˆ†æç”¨æˆ·è¾“å…¥
    """
    logger.info(f"ğŸ” åˆ†æè¾“å…¥: {user_input}")
    
    # åœ¨ Context ä¸­å­˜å‚¨çŠ¶æ€
    context.state["original_query"] = user_input
    
    # [Phase 2 Update] è¿™é‡Œçš„ loop_count åˆå§‹åŒ–å¯ä»¥é€šè¿‡ Next(..., update_state=...) åœ¨åç»­èŠ‚ç‚¹å®Œæˆï¼Œ
    # æˆ–è€…åœ¨æ­¤å¤„åˆå§‹åŒ–ã€‚ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬è¿™é‡Œåªå­˜ queryã€‚
    
    return len(user_input)


@step(name="QuickResponse")
def quick_response(length: int):
    """
    èŠ‚ç‚¹ 2A: å¿«é€Ÿå›å¤ (åˆ†æ”¯ A)
    """
    logger.info("âš¡ï¸ æ‰§è¡Œå¿«é€Ÿå›å¤è·¯å¾„")
    return f"è¾“å…¥å¤ªçŸ­ ({length} å­—ç¬¦)ï¼Œè¯·æä¾›æ›´å¤šç»†èŠ‚ã€‚"


@step(name="DeepThinking")
async def deep_thinking_agent(context: WorkflowContext):
    """
    èŠ‚ç‚¹ 2B: æ·±åº¦æ€è€ƒ (åˆ†æ”¯ B) - ä½¿ç”¨ Agent
    """
    logger.info("ğŸ§  æ‰§è¡Œæ·±åº¦æ€è€ƒè·¯å¾„ (Agent)")
    query = context.state["original_query"]
    
    # æ„å»º Agent
    api_key = os.environ.get("ZHIPU_API_KEY")
    if not api_key:
        return "Error: No API Key found"

    # [Updated] ä½¿ç”¨ ZhipuChat
    model = ZhipuChat(api_key=api_key, model="glm-4-flash")
    agent = (
        AgentBuilder()
        .with_model(model)
        .with_session_id("demo_session")
        .build()
    )
    
    # æ‰§è¡Œ Agent
    # æ³¨æ„ï¼šç”±äº Phase 1 ç§»é™¤äº†éšå¼æ‹†åŒ…ï¼ŒAgent è¿™é‡Œæ¥æ”¶çš„æ˜¯å­—ç¬¦ä¸² query (ä» state è·å–)
    # å¦‚æœ DeepThinking çš„ä¸Šæ¸¸èŠ‚ç‚¹è¿”å›äº† dictï¼Œè¿™é‡Œéœ€è¦æ˜¾å¼å¤„ç†ã€‚
    result = await agent.run(f"è¯·ç®€è¦åˆ†æè¿™å¥è¯çš„æƒ…æ„Ÿï¼š{query}")
    return result.content # type: ignore


@step(name="RefinementLoop")
def refinement_loop(context: WorkflowContext):
    """
    èŠ‚ç‚¹ 3: ä¼˜åŒ–å¾ªç¯ (Loop)
    [Updated] ä½¿ç”¨ Phase 2 çš„ update_state ç‰¹æ€§ç®€åŒ–çŠ¶æ€ç®¡ç†
    """
    last_output = context.get_last_output()
    # è¿™é‡Œçš„ loop_count å¦‚æœä¸å­˜åœ¨åˆ™é»˜è®¤ä¸º 0
    loop_count = context.state.get("loop_count", 0)
    
    logger.info(f"ğŸ”„ æ£€æŸ¥ç»“æœ (Loop {loop_count}): {str(last_output)[:20]}...")
    
    # æ¨¡æ‹Ÿï¼šå¦‚æœæ˜¯ Error ä¸”é‡è¯•æ¬¡æ•°æœªåˆ°
    if "Error" in str(last_output) and loop_count < 2:
        logger.warning("âš ï¸ æ£€æµ‹åˆ°é”™è¯¯ï¼Œè§¦å‘é‡è¯•å¾ªç¯...")
        
        # [Phase 2 Feature] ä½¿ç”¨ update_state åœ¨è·³è½¬æ—¶è‡ªåŠ¨æ›´æ–°è®¡æ•°å™¨
        # è¿™æ ·å°±ä¸éœ€è¦æ‰‹åŠ¨æ“ä½œ context.state["loop_count"] += 1
        return Next(
            node="Deep", 
            input=context.state["original_query"],
            update_state={"loop_count": loop_count + 1}
        )
    
    return last_output


@step(name="FinalSummary")
async def final_summary(result: Any):
    """
    èŠ‚ç‚¹ 4: æœ€ç»ˆæ±‡æ€»
    """
    logger.info("âœ… ç”Ÿæˆæœ€ç»ˆæ‘˜è¦")
    return f"=== Workflow Result ===\n{result}"


# ========================= 2. æ„å»ºä¸è¿è¡Œ =========================

async def main():
    # 1. åˆ›å»º Workflow
    # [Phase 2 Feature] æ˜¾å¼å¼€å¯å¾ªç¯æ”¯æŒ (allow_cycles=True)
    # è™½ç„¶è¿™é‡Œä¸»è¦é  Next è·³è½¬ï¼Œä½†å¼€å¯æ­¤é€‰é¡¹æ˜¯ V0.2 çš„æ¨èåšæ³•ï¼Œé¿å…é™æ€æ£€æŸ¥è¯¯æŠ¥å¤æ‚æ‹“æ‰‘
    wf = Workflow(name="DemoFlow", max_steps=20, allow_cycles=True)
    
    # 2. æ·»åŠ èŠ‚ç‚¹
    wf.add_node("Analyze", analyze_input)
    wf.add_node("Quick", quick_response)
    wf.add_node("Deep", deep_thinking_agent)  # æ³¨å†Œåä¸º "Deep"
    wf.add_node("LoopCheck", refinement_loop)
    wf.add_node("Summary", final_summary)
    
    # 3. å®šä¹‰è¾¹ä¸æ¡ä»¶ (Topology)
    
    # å…¥å£ -> åˆ†æ
    wf.set_entry_point("Analyze")
    
    # åˆ†æ -> åˆ†æ”¯ (æ ¹æ®è¾“å…¥é•¿åº¦)
    # [Phase 1 Update] get_last_output_as(int) ç¡®ä¿ç±»å‹å®‰å…¨
    wf.add_edge("Analyze", "Quick", lambda ctx: ctx.get_last_output_as(int) < 5)
    wf.add_edge("Analyze", "Deep", lambda ctx: ctx.get_last_output_as(int) >= 5)
    
    # åˆ†æ”¯æ±‡èš -> å¾ªç¯æ£€æŸ¥
    wf.add_edge("Quick", "LoopCheck")
    wf.add_edge("Deep", "LoopCheck")
    
    # å¾ªç¯æ£€æŸ¥ -> ç»“æŸ
    wf.add_edge("LoopCheck", "Summary")
    
    # 4. éªŒè¯ç»“æ„
    if not wf.validate():
        print("âŒ Workflow éªŒè¯å¤±è´¥")
        return

    # æ‰“å°ç»“æ„å›¾
    wf.print_structure()
    
    print("\n" + "="*40)
    print("Case 1: çŸ­è¾“å…¥ (èµ°å¿«é€Ÿåˆ†æ”¯)")
    print("="*40)
    res1 = await wf.execute("Hi")
    print(f"\n{res1}")
    
    print("\n" + "="*40)
    print("Case 2: é•¿è¾“å…¥ (èµ° Agent åˆ†æ”¯)")
    print("="*40)
    # æç¤ºï¼šç¡®ä¿ç¯å¢ƒå˜é‡ ZHIPU_API_KEY å·²è®¾ç½®
    res2 = await wf.execute("æˆ‘ä»Šå¤©éå¸¸å¼€å¿ƒï¼Œæƒ³å†™ä»£ç ï¼")
    print(f"\n{res2}")


if __name__ == "__main__":
    try:
        import uvloop
        uvloop.install()
    except ImportError:
        pass
        
    asyncio.run(main())
```

[4] examples/compose/workflow_next_resume_demo.py
```python
# examples/compose/workflow_next_resume_demo.py
"""
Workflow Next æŒ‡ä»¤æ–­ç‚¹æ¢å¤ç¤ºä¾‹

æ¼”ç¤º Gecko å¦‚ä½•å¤„ç† Next æŒ‡ä»¤çš„åŠ¨æ€è·³è½¬æŒä¹…åŒ–ï¼š
1. èŠ‚ç‚¹ A è¿”å› Next("B", input="...")ã€‚
2. ç³»ç»Ÿåœ¨è·³è½¬åã€B æ‰§è¡Œå‰å´©æºƒã€‚
3. ç³»ç»Ÿæ¢å¤ï¼Œç›´æ¥ä» next_pointer æŒ‡å‘çš„ B ç»§ç»­æ‰§è¡Œï¼Œè€Œä¸é‡å¤æ‰§è¡Œ Aã€‚
"""
import asyncio
import os
import sys

# ç¡®ä¿å¯ä»¥å¯¼å…¥ gecko
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from gecko.compose.workflow import Workflow, WorkflowContext, CheckpointStrategy
from gecko.compose.nodes import step, Next
from gecko.plugins.storage.backends.sqlite import SQLiteStorage
from gecko.core.logging import setup_logging
from gecko.core.exceptions import WorkflowError

setup_logging(level="INFO")

# å…¨å±€æ ‡è®°ï¼Œæ¨¡æ‹Ÿç¬¬ä¸€æ¬¡è¿è¡Œå´©æºƒ
CRASH_FLAG = True

@step("StartNode")
async def start_node(context: WorkflowContext):
    print("\n>>> [StartNode] æ‰§è¡Œä¸­...")
    # åŠ¨æ€è·³è½¬åˆ° NextNodeï¼Œå¹¶æºå¸¦æ•°æ®
    # æœŸæœ›è¡Œä¸ºï¼šStartNode æ‰§è¡Œå®Œåï¼ŒNext æŒ‡ä»¤è¢«æŒä¹…åŒ–
    return Next(node="NextNode", input="Jumped Data")

@step("NextNode")
async def next_node(context: WorkflowContext):
    global CRASH_FLAG
    print("\n>>> [NextNode] å‡†å¤‡æ‰§è¡Œ...")
    
    # è·å–ä¸Šä¸€æ­¥ä¼ æ¥çš„æ•°æ®
    inp = context.get_last_output()
    print(f"    æ”¶åˆ°è¾“å…¥: {inp}")
    
    if CRASH_FLAG:
        print("    ğŸ’€ [NextNode] æ¨¡æ‹Ÿç³»ç»Ÿå´©æºƒ! (Crash before logic)")
        CRASH_FLAG = False
        raise RuntimeError("System Crash in NextNode")
    
    print("    âœ… [NextNode] æ‰§è¡ŒæˆåŠŸ")
    return f"Processed({inp})"

async def main():
    db_file = "next_resume.db"
    db_url = f"sqlite:///{db_file}"
    
    if os.path.exists(db_file):
        os.remove(db_file)

    storage = SQLiteStorage(db_url)
    await storage.initialize()

    wf = Workflow(
        name="NextResumeFlow", 
        storage=storage,
        checkpoint_strategy=CheckpointStrategy.ALWAYS
    )
    
    wf.add_node("StartNode", start_node)
    wf.add_node("NextNode", next_node)
    # æ³¨æ„ï¼šè¿™é‡Œæ²¡æœ‰æ˜¾å¼æ·»åŠ  StartNode -> NextNode çš„è¾¹
    # å®Œå…¨ä¾èµ– Next æŒ‡ä»¤è·³è½¬
    wf.set_entry_point("StartNode")

    session_id = "next_crash_session"

    print(f"\n{'='*50}")
    print("ROUND 1: é¦–æ¬¡è¿è¡Œ (é¢„æœŸåœ¨è·³è½¬åã€NextNode å‰å´©æºƒ)")
    print(f"{'='*50}")

    try:
        await wf.execute("Init", session_id=session_id)
    except WorkflowError as e:
        print(f"\nğŸ”´ æ•è·åˆ°é¢„æœŸå¼‚å¸¸: {e}")

    print(f"\n{'='*50}")
    print("ROUND 2: æ¢å¤è¿è¡Œ (é¢„æœŸç›´æ¥ä» NextNode å¼€å§‹)")
    print(f"{'='*50}")
    
    # é‡ç½® Workflow å®ä¾‹æ¨¡æ‹Ÿé‡å¯ (å…³é”®æ˜¯ storage å’Œ session_id ä¸€è‡´)
    # å®é™…ä¸Šç”¨åŒä¸€ä¸ª wf å®ä¾‹ä¹Ÿå¯ä»¥
    
    try:
        # æ¢å¤æ‰§è¡Œ
        # æœŸæœ›ï¼šStartNode ä¸ä¼šè¢«é‡æ–°æ‰§è¡Œï¼ˆæ²¡æœ‰ ">>> [StartNode] æ‰§è¡Œä¸­..." è¾“å‡ºï¼‰
        # ç›´æ¥è¿›å…¥ NextNodeï¼Œä¸”èƒ½è·å–åˆ° "Jumped Data"
        result = await wf.resume(session_id=session_id)
        print(f"\nğŸ‰ æ¢å¤æˆåŠŸ! æœ€ç»ˆç»“æœ: {result}")
        
    except Exception as e:
        print(f"âŒ æ¢å¤å¤±è´¥: {e}")

    await storage.shutdown()
    if os.path.exists(db_file):
        os.remove(db_file)

if __name__ == "__main__":
    asyncio.run(main())
```

[5] examples/compose/workflow_resume_demo.py
```python
# examples/workflow_resume_demo.py
"""
Workflow æ–­ç‚¹æ¢å¤ç¤ºä¾‹ (Resumability Demo)

æ¼”ç¤º Gecko å¦‚ä½•å¤„ç†ç³»ç»Ÿå´©æºƒå’ŒçŠ¶æ€æ¢å¤ï¼š
1. ä½¿ç”¨ SQLite æŒä¹…åŒ–çŠ¶æ€ (åŸºäºé‡æ„åçš„ Storage æ’ä»¶)
2. æ¨¡æ‹ŸèŠ‚ç‚¹æ‰§è¡Œä¸­çš„æ„å¤–å´©æºƒ
3. ä½¿ç”¨ resume() æ¥å£ä»æ–­ç‚¹ç»§ç»­æ‰§è¡Œ (Phase 3 æ–°ç‰¹æ€§)
"""
import asyncio
import os
import sys

# ç¡®ä¿å¯ä»¥å¯¼å…¥ gecko
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from gecko.compose.workflow import Workflow, WorkflowContext, CheckpointStrategy
from gecko.compose.nodes import step, Next
from gecko.plugins.storage.backends.sqlite import SQLiteStorage
from gecko.core.logging import setup_logging
# [Fix] Import WorkflowError
from gecko.core.exceptions import WorkflowError

# é…ç½®æ—¥å¿—ä»¥ä¾¿è§‚å¯Ÿæ¢å¤è¿‡ç¨‹
setup_logging(level="INFO")

# å…¨å±€æ ‡è®°ï¼Œç”¨äºæ¨¡æ‹Ÿâ€œç¬¬ä¸€æ¬¡å¿…æŒ‚ï¼Œç¬¬äºŒæ¬¡æˆåŠŸâ€
FAIL_FLAG = True

# ========================= å®šä¹‰èŠ‚ç‚¹ =========================

@step("Step_A")
async def step_a(context: WorkflowContext):
    print("\n>>> æ‰§è¡ŒèŠ‚ç‚¹ A (åˆå§‹åŒ–æ•°æ®)...")
    # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
    await asyncio.sleep(0.5)
    return "Data A"

@step("Step_B")
async def step_b(context: WorkflowContext):
    global FAIL_FLAG
    print("\n>>> æ‰§è¡ŒèŠ‚ç‚¹ B (å¤„ç†æ•°æ®)...")
    
    # è·å–ä¸Šä¸€æ­¥ç»“æœ
    prev = context.get_last_output()
    print(f"    èŠ‚ç‚¹ B æ”¶åˆ°: {prev}")
    
    if FAIL_FLAG:
        print("    ğŸ’€ æ¨¡æ‹Ÿç³»ç»Ÿå´©æºƒ! (System Crash)")
        FAIL_FLAG = False 
        raise RuntimeError("Unexpected System Failure in Node B")
    
    print("    âœ… èŠ‚ç‚¹ B æ‰§è¡ŒæˆåŠŸ")
    
    # [ä¿®æ”¹] ä½¿ç”¨ Next è·³è½¬ï¼ŒéªŒè¯åŠ¨æ€æŒ‡é’ˆæ¢å¤
    return Next(node="C", input=f"Processed({prev})")

@step("Step_C")
async def step_c(context: WorkflowContext):
    print("\n>>> æ‰§è¡ŒèŠ‚ç‚¹ C (æœ€ç»ˆæ±‡æ€»)...")
    # [ä¿®æ”¹] éªŒè¯è¾“å…¥æ˜¯å¦é€šè¿‡ Next ä¼ é€’è¿‡æ¥
    prev = context.get_last_output()
    print(f"    èŠ‚ç‚¹ C æ”¶åˆ°: {prev}")
    return f"FinalResult -> {prev}"

# ========================= ä¸»æµç¨‹ =========================

async def main():
    db_file = "resume_demo.db"
    db_url = f"sqlite:///{db_file}"
    
    # æ¸…ç†æ—§æ•°æ®ç¡®ä¿ Demo å¯é‡å¤
    if os.path.exists(db_file):
        try:
            os.remove(db_file)
        except:
            pass

    print(f"ğŸ”Œ åˆå§‹åŒ–å­˜å‚¨: {db_url}")
    # 1. åˆå§‹åŒ–å­˜å‚¨
    # æ–­ç‚¹æ¢å¤å¿…é¡»ä¾èµ–æŒä¹…åŒ–å­˜å‚¨
    storage = SQLiteStorage(db_url)
    await storage.initialize()

    # 2. å®šä¹‰å·¥ä½œæµ
    wf = Workflow(
        name="ResumableFlow", 
        storage=storage,
        # [Phase 3 Feature] ç­–ç•¥: ALWAYS (æ¯æ­¥ä¿å­˜)ï¼Œè¿™æ˜¯ Resume çš„å‰æ
        checkpoint_strategy=CheckpointStrategy.ALWAYS
    )
    
    wf.add_node("A", step_a)
    wf.add_node("B", step_b)
    wf.add_node("C", step_c)
    
    wf.add_edge("A", "B")
    wf.add_edge("B", "C")
    wf.set_entry_point("A")

    session_id = "crash_test_session_001"

    print(f"\n{'='*50}")
    print("ROUND 1: é¦–æ¬¡è¿è¡Œ (é¢„æœŸåœ¨ B èŠ‚ç‚¹å´©æºƒ)")
    print(f"{'='*50}")

    try:
        # æ­£å¸¸æ‰§è¡Œ
        await wf.execute("Start", session_id=session_id)
    except WorkflowError as e: # [Fix] Catch WorkflowError correctly
        print(f"\nğŸ”´ æ•è·åˆ°é¢„æœŸå¼‚å¸¸: {e}")
        print("   å·¥ä½œæµå·²ä¸­æ–­ã€‚çŠ¶æ€åº”å·²ä¿å­˜åˆ° SQLiteã€‚")
    except Exception as e:
        print(f"\nğŸ”´ æ•è·åˆ°å…¶ä»–å¼‚å¸¸: {e}")

    print(f"\n{'='*50}")
    print("ROUND 2: æ¢å¤è¿è¡Œ (é¢„æœŸè·³è¿‡ Aï¼Œé‡è¯• Bï¼Œå®Œæˆ C)")
    print(f"{'='*50}")
    
    # æ¨¡æ‹Ÿé‡å¯ç³»ç»Ÿï¼šå¯ä»¥é‡æ–°å®ä¾‹åŒ– Workflow å¯¹è±¡ï¼Œåªè¦ session_id å’Œ storage ä¸€æ ·
    # wf_new = Workflow(..., storage=storage) 
    
    try:
        # [Phase 3 Feature] è°ƒç”¨ resume è€Œä¸æ˜¯ execute
        # å¼•æ“ä¼šè‡ªåŠ¨åŠ è½½ä¸Šæ¬¡çš„çŠ¶æ€ï¼Œå‘ç° A å·²å®Œæˆï¼Œä» B å¼€å§‹é‡è¯•
        final_result = await wf.resume(session_id=session_id)
        
        print(f"\nğŸ‰ å·¥ä½œæµæ¢å¤å¹¶å®Œæˆ!")
        print(f"   æœ€ç»ˆç»“æœ: {final_result}")
        
    except Exception as e:
        print(f"âŒ æ¢å¤å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise

    # æ¸…ç†
    await storage.shutdown()
    if os.path.exists(db_file):
        try:
            os.remove(db_file)
            # SQLite WAL æ¨¡å¼å¯èƒ½ä¼šäº§ç”Ÿé¢å¤–æ–‡ä»¶
            if os.path.exists(db_file + "-wal"): os.remove(db_file + "-wal")
            if os.path.exists(db_file + "-shm"): os.remove(db_file + "-shm")
        except:
            pass

if __name__ == "__main__":
    asyncio.run(main())
```

[6] examples/core/engine_base_demo.py
```python
import asyncio
import time
from typing import Any, AsyncIterator, List, Type, Dict

from pydantic import BaseModel, Field

# Gecko æ ¸å¿ƒç»„ä»¶å¯¼å…¥
from gecko.core.engine.base import CognitiveEngine, AgentOutput
from gecko.core.message import Message
from gecko.core.memory import TokenMemory
from gecko.core.toolbox import ToolBox
from gecko.core.protocols import (
    ModelProtocol, 
    CompletionResponse, 
    CompletionChoice, 
    StreamChunk
)

# ==========================================
# 1. æ¨¡æ‹Ÿç»„ä»¶ (Mock Components)
# ==========================================

class MockModel(ModelProtocol):
    """
    ä¸€ä¸ªç®€å•çš„ Mock æ¨¡å‹ï¼Œå®ç°äº† ModelProtocolã€‚
    å®ƒåªæ˜¯å›æ˜¾ç”¨æˆ·çš„è¾“å…¥ï¼Œæˆ–è€…ç”Ÿæˆé¢„å®šä¹‰çš„æµå¼æ•°æ®ã€‚
    """
    async def acompletion(self, messages: List[Dict[str, Any]], **kwargs) -> CompletionResponse:
        # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        await asyncio.sleep(0.1)
        
        last_content = messages[-1]["content"]
        response_text = f"Mock Response to: {last_content}"
        
        return CompletionResponse(
            choices=[
                CompletionChoice(message={"role": "assistant", "content": response_text})
            ],
            usage={"prompt_tokens": 10, "completion_tokens": 5, "total_tokens": 15} # type: ignore
        )

    async def astream(self, messages: List[Dict[str, Any]], **kwargs) -> AsyncIterator[StreamChunk]:
        # æ¨¡æ‹Ÿæµå¼è¾“å‡º
        full_text = "This is a streaming response from the mock model."
        for word in full_text.split():
            await asyncio.sleep(0.05)
            yield StreamChunk(
                choices=[{"delta": {"content": word + " "}}]
            )

    def count_tokens(self, text_or_messages) -> int:
        # ç®€å•æ¨¡æ‹Ÿï¼šæŒ‰å­—ç¬¦æ•°ä¼°ç®—ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹
        if isinstance(text_or_messages, list):
            text = "".join(str(m.get("content", "")) for m in text_or_messages)
        else:
            text = str(text_or_messages)
        return len(text) // 4

# ==========================================
# 2. è‡ªå®šä¹‰å¼•æ“å®ç° (Custom Engine)
# ==========================================

class DemoEngine(CognitiveEngine):
    """
    ç»§æ‰¿ CognitiveEngine çš„æ¼”ç¤ºå¼•æ“ã€‚
    å¿…é¡»å®ç° step() æ–¹æ³•ã€‚
    """
    
    async def step(self, input_messages: List[Message], **kwargs) -> AgentOutput:
        """
        å®ç°æ ¸å¿ƒæ¨ç†é€»è¾‘ï¼ˆå¸¦ç»Ÿè®¡ä¿®å¤ï¼‰
        """
        # â±ï¸ 1. å¼€å§‹è®¡æ—¶
        start_time = time.time()
        
        # 2. éªŒè¯è¾“å…¥
        self.validate_input(input_messages)
        
        # 3. è§¦å‘ before_step hook
        await self.before_step(input_messages, **kwargs)

        # 4. å‡†å¤‡æ•°æ®
        formatted_msgs = [m.to_openai_format() for m in input_messages]
        
        try:
            # 5. è°ƒç”¨æ¨¡å‹
            response = await self.model.acompletion(formatted_msgs)
            content = response.choices[0].message["content"]
            
            # è·å– token ä½¿ç”¨é‡ (MockModel è¿”å›äº† usage)
            # å¦‚æœ response.usage æ˜¯å¯¹è±¡åˆ™å–å±æ€§ï¼Œå¦‚æœæ˜¯å­—å…¸åˆ™å–é”®å€¼
            usage_info = response.usage
            total_tokens = 0
            if isinstance(usage_info, dict):
                total_tokens = usage_info.get("total_tokens", 0)
            elif hasattr(usage_info, "total_tokens"):
                total_tokens = usage_info.total_tokens # type: ignore

            # 6. æ„å»ºè¾“å‡º
            output = AgentOutput(
                content=content,
                metadata={"finish_reason": "stop"}
            )
            
            # 7. è§¦å‘ after_step hook
            await self.after_step(input_messages, output, **kwargs)
            
            # âœ… 8. [ä¿®å¤ç‚¹] æ‰‹åŠ¨æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            duration = time.time() - start_time
            if self.stats:
                self.stats.add_step(duration, tokens=total_tokens)
            
            return output
            
        except Exception as e:
            # âœ… 9. [ä¿®å¤ç‚¹] è®°å½•é”™è¯¯ç»Ÿè®¡
            if self.stats:
                self.stats.errors += 1
                
            # é”™è¯¯å¤„ç† hook
            await self.on_error(e, input_messages)
            raise

    async def step_stream(self, input_messages: List[Message], **kwargs) -> AsyncIterator[str]: # type: ignore
        """
        è¦†ç›–æµå¼æ¨ç†æ–¹æ³•
        """
        formatted_msgs = [m.to_openai_format() for m in input_messages]
        
        async for chunk in self.model.astream(formatted_msgs): # type: ignore
            content = chunk.content
            if content:
                yield content

    async def step_structured(
        self, 
        input_messages: List[Message], 
        response_model: Type[BaseModel], 
        **kwargs
    ) -> BaseModel:
        """
        è¦†ç›–ç»“æ„åŒ–è¾“å‡ºæ–¹æ³• (æ¨¡æ‹Ÿå®ç°)
        """
        # æ¨¡æ‹Ÿï¼šç›´æ¥è¿”å›ä¸€ä¸ªä¼ªé€ çš„ç»“æ„åŒ–å¯¹è±¡
        # å®é™…åœºæ™¯ä¸­è¿™é‡Œä¼šè°ƒç”¨ StructureEngine
        print(f"   [Engine] Parsing structured output for {response_model.__name__}...")
        await asyncio.sleep(0.1)
        
        return response_model(
            reasoning="Simulated reasoning",
            score=95,
            tags=["demo", "mock"]
        )

# ==========================================
# 3. è¾…åŠ©æ•°æ®ç»“æ„
# ==========================================

class AnalysisResult(BaseModel):
    """ç”¨äºæµ‹è¯•ç»“æ„åŒ–è¾“å‡ºçš„æ¨¡å‹"""
    reasoning: str = Field(description="æ€è€ƒè¿‡ç¨‹")
    score: int = Field(description="è¯„åˆ†")
    tags: List[str] = Field(description="æ ‡ç­¾")

# ==========================================
# 4. ä¸»æ¼”ç¤ºæµç¨‹
# ==========================================

async def main():
    print("ğŸš€ Starting Engine Base Demo...\n")

    # --- åˆå§‹åŒ–ä¾èµ– ---
    model = MockModel()
    toolbox = ToolBox() # ç©ºå·¥å…·ç®±
    # æ³¨æ„ï¼šè¿™é‡Œç®€å• mock memoryï¼Œå®é™…åº”ä¼ å…¥ SessionInterface å®ç°
    memory = TokenMemory(session_id="demo_session", max_tokens=1000)

    # --- ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨åˆå§‹åŒ–å¼•æ“ ---
    print("1ï¸âƒ£  Testing Context Manager & Basic Step")
    async with DemoEngine(model, toolbox, memory) as engine:
        
        # --- è®¾ç½® Hooks ---
        async def my_before_hook(messages, **kwargs):
            print(f"   [Hook] Before step: Processing {len(messages)} messages")

        async def my_after_hook(messages, output, **kwargs):
            print(f"   [Hook] After step: Generated {len(output.content)} chars")

        engine.before_step_hook = my_before_hook
        engine.after_step_hook = my_after_hook

        # --- æµ‹è¯•æ™®é€šæ¨ç† ---
        user_msg = Message.user("Hello Gecko!")
        print(f"   User: {user_msg.content}")
        
        output = await engine.step([user_msg])
        print(f"   Agent: {output.content}\n")

        # --- æµ‹è¯•æµå¼æ¨ç† ---
        print("2ï¸âƒ£  Testing Streaming")
        print("   Agent (Stream): ", end="", flush=True)
        async for token in engine.step_stream([Message.user("Stream me!")]):
            print(token, end="", flush=True)
        print("\n")

        # --- æµ‹è¯•ç»“æ„åŒ–è¾“å‡º ---
        print("3ï¸âƒ£  Testing Structured Output")
        result = await engine.step_structured(
            [Message.user("Analyze this")], 
            response_model=AnalysisResult
        )
        print(f"   Result: {result.model_dump_json()}\n")

        # --- æŸ¥çœ‹ç»Ÿè®¡ ---
        print("4ï¸âƒ£  Execution Stats")
        stats = engine.get_stats()
        print(f"   Total Steps: {stats['total_steps']}") # type: ignore
        print(f"   Total Time:  {stats['total_time']:.4f}s") # type: ignore
        print(f"   Avg Time:    {stats['avg_step_time']:.4f}s") # type: ignore
        print(f"   Errors:      {stats['errors']}") # type: ignore

if __name__ == "__main__":
    asyncio.run(main())
```

[7] examples/core/engine_react_demo.py
```python
# examples/core/engine_react_demo.py
import asyncio
import os
from typing import Any, Dict

from pydantic import BaseModel, Field

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from gecko.core.agent import Agent
from gecko.core.message import Message
from gecko.core.memory import TokenMemory
from gecko.core.toolbox import ToolBox
from gecko.core.engine.react import ReActEngine
from gecko.plugins.tools.base import BaseTool
# [ä¿®æ”¹] å¯¼å…¥æ–°çš„æ¨¡å‹ç±»
from gecko.plugins.models import ZhipuChat

# ==========================================
# 1. å®šä¹‰ç®€å•çš„å·¥å…· (ä¿æŒä¸å˜)
# ==========================================

class CalculatorTool(BaseTool):
    name: str = "calculator"
    description: str = "Useful for performing basic arithmetic operations. Input should be a math expression string."
    parameters: Dict[str, Any] = { # type: ignore
        "type": "object",
        "properties": {
            "expression": {
                "type": "string",
                "description": "The math expression to evaluate, e.g., '2 + 2'"
            }
        },
        "required": ["expression"]
    }
    # ä¸ºäº†å…¼å®¹æ–°ç‰ˆ BaseToolï¼Œè¿™é‡Œè™½ç„¶æ²¡æœ‰ç”¨ args_schemaï¼Œä½†æ‰‹åŠ¨å®ç°äº† parameters å±æ€§
    # å¦‚æœä½¿ç”¨æ–°ç‰ˆ BaseToolï¼Œå»ºè®®å®šä¹‰ Pydantic Modelã€‚
    # è¿™é‡Œä¸ºäº†æœ€å°åŒ–æ”¹åŠ¨ï¼Œæˆ‘ä»¬é€šè¿‡è¦†ç›– _run å¹¶å¿½ç•¥ç±»å‹æ£€æŸ¥æ¥é€‚é… Demo
    
    # å®šä¹‰ä¸€ä¸ªä¸´æ—¶çš„ args schema ä»¥æ»¡è¶³ BaseTool åˆå§‹åŒ–æ£€æŸ¥
    class Args(BaseModel):
        expression: str
    args_schema: type[BaseModel] = Args

    async def _run(self, args: Args) -> str: # type: ignore
        expression = args.expression
        try:
            # æ³¨æ„ï¼ševal åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ˜¯ä¸å®‰å…¨çš„ï¼Œä»…ç”¨äºæ¼”ç¤º
            return str(eval(expression))
        except Exception as e:
            return f"Error: {str(e)}"

class WeatherTool(BaseTool):
    name: str = "get_current_weather"
    description: str = "Get the current weather in a given location"
    
    class Args(BaseModel):
        location: str
        unit: str = "celsius"
    args_schema: type[BaseModel] = Args

    async def _run(self, args: Args) -> str: # type: ignore
        return f"The weather in {args.location} is sunny and 25Â°C."

# ==========================================
# 2. å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹ (ä¿æŒä¸å˜)
# ==========================================

class AnalysisReport(BaseModel):
    """åˆ†ææŠ¥å‘Šç»“æ„"""
    summary: str = Field(description="å¯¹ç”¨æˆ·é—®é¢˜çš„ç®€çŸ­æ€»ç»“")
    action_items: list[str] = Field(description="å»ºè®®é‡‡å–çš„è¡ŒåŠ¨é¡¹åˆ—è¡¨")
    priority: str = Field(description="ä¼˜å…ˆçº§ (High/Medium/Low)")

# ==========================================
# 3. ä¸»æ¼”ç¤ºæµç¨‹
# ==========================================

async def main():
    # 1. åˆå§‹åŒ–æ¨¡å‹ [ä¿®æ”¹]
    api_key = os.getenv("ZHIPU_API_KEY")
    if not api_key:
        print("Please set ZHIPU_API_KEY environment variable.")
        return

    llm = ZhipuChat(api_key=api_key, model="glm-4-flash")

    # 2. åˆå§‹åŒ–å·¥å…·ç®±
    toolbox = ToolBox(tools=[CalculatorTool(), WeatherTool()])

    # 3. åˆå§‹åŒ–è®°å¿†
    memory = TokenMemory(session_id="react_demo_session", max_tokens=2000)

    # 4. æ„å»º Agent (ä½¿ç”¨ ReActEngine)
    agent = Agent(
        model=llm,
        toolbox=toolbox,
        memory=memory,
        engine_cls=ReActEngine,
        # å¢åŠ æœ€å¤§è½®æ•°(5->10)ï¼Œæµ‹è¯•è¿­ä»£å¾ªç¯çš„ç¨³å®šæ€§
        max_turns=10 # é™åˆ¶æœ€å¤§æ€è€ƒè½®æ•°
    )

    print("\nğŸš€ ReAct Agent Demo (Powered by ZhipuChat)\n")

    # --- åœºæ™¯ 1: éœ€è¦ä½¿ç”¨å·¥å…·çš„å¤æ‚æŸ¥è¯¢ ---
    query1 = "What is 123 * 45? Also, what's the weather in Beijing?"
    print(f"ğŸ‘¤ User: {query1}")
    print("ğŸ¤– Agent (Thinking...):")
    
    # ä½¿ç”¨ run() æ–¹æ³• (éæµå¼)
    response1 = await agent.run(query1)
    print(f"ğŸ’¡ Final Answer: {response1.content}\n") # type: ignore
    
    # æŸ¥çœ‹ç»Ÿè®¡
    if agent.engine.stats:
        print(f"ğŸ“Š Stats: Steps={agent.engine.stats.total_steps}, ToolCalls={agent.engine.stats.tool_calls}")

    print("-" * 50)

    # --- åœºæ™¯ 2: ç»“æ„åŒ–è¾“å‡º ---
    query2 = "Based on the weather in Beijing, suggest a weekend plan."
    print(f"\nğŸ‘¤ User: {query2} (Requesting Structured Output)")
    
    # ä½¿ç”¨ run() å¹¶æŒ‡å®š response_model
    result = await agent.run(query2, response_model=AnalysisReport)
    print(f"ğŸ“¦ Structured Result:\n{result.model_dump_json(indent=2)}\n")

    print("-" * 50)

    # --- åœºæ™¯ 3: æµå¼è¾“å‡º (é•¿æ–‡æœ¬/å¤šæ­¥æ¨ç†) ---
    # [ä¿®æ”¹] æ„é€ ä¸€ä¸ªéœ€è¦å¤šæ­¥æ€è€ƒçš„é—®é¢˜ï¼ŒéªŒè¯æµå¼è¿­ä»£
    query3 = "è¯·å…ˆè®¡ç®— 50 çš„é˜¶ä¹˜ï¼Œç„¶åæœç´¢è¿™ä¸ªæ•°å­—çš„ä½æ•°ï¼Œæœ€åå†™ä¸€é¦–å…³äºè¿™ä¸ªæ•°å­—çš„çŸ­è¯—ã€‚"
    print(f"\nğŸ‘¤ User: {query3} (Streaming Mode - Iterative)")
    print("ğŸŒŠ Stream: ", end="", flush=True)
    
    try:
        async for chunk in agent.stream(query3):
            print(chunk, end="", flush=True)
        print("\n")
    except RecursionError:
        print("\nâŒ Error: Recursion depth exceeded! (Optimization needed)")
    except Exception as e:
        print(f"\nâŒ Error: {e}")

if __name__ == "__main__":
    asyncio.run(main())
```

[8] examples/core/events_demo.py
```python
import asyncio
import time
from typing import Optional

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from gecko.core.events import EventBus, BaseEvent
from gecko.core.logging import get_logger

logger = get_logger(__name__)

# ==========================================
# 1. å®šä¹‰è‡ªå®šä¹‰äº‹ä»¶
# ==========================================

class UserLoginEvent(BaseEvent):
    """ç”¨æˆ·ç™»å½•äº‹ä»¶"""
    type: str = "user.login"
    
class OrderCreatedEvent(BaseEvent):
    """è®¢å•åˆ›å»ºäº‹ä»¶"""
    type: str = "order.created"

# ==========================================
# 2. å®šä¹‰å¤„ç†å™¨ (Handlers)
# ==========================================

async def async_logger(event: BaseEvent):
    """å¼‚æ­¥æ—¥å¿—å¤„ç†å™¨"""
    # æ¨¡æ‹Ÿè€—æ—¶ I/O
    await asyncio.sleep(0.1)
    print(f"ğŸ“ [Async Logger] {event.type}: {event.data}")

def sync_metrics(event: BaseEvent):
    """åŒæ­¥æŒ‡æ ‡ç»Ÿè®¡å¤„ç†å™¨"""
    print(f"ğŸ“Š [Sync Metrics] Counting event: {event.type}")

async def slow_processor(event: BaseEvent):
    """æ…¢é€Ÿå¤„ç†å™¨ï¼ˆç”¨äºæ¼”ç¤ºåå°ä»»åŠ¡ç­‰å¾…ï¼‰"""
    print(f"â³ [Slow Proc] Start processing {event.type}...")
    await asyncio.sleep(1.0) # æ¨¡æ‹Ÿé•¿ä»»åŠ¡
    print(f"âœ… [Slow Proc] Finished {event.type}")

# ==========================================
# 3. å®šä¹‰ä¸­é—´ä»¶ (Middleware)
# ==========================================

async def audit_middleware(event: BaseEvent) -> Optional[BaseEvent]:
    """å®¡è®¡ä¸­é—´ä»¶ï¼šç»™æ‰€æœ‰äº‹ä»¶æ·»åŠ å®¡è®¡æ—¶é—´æˆ³"""
    event.data["audit_ts"] = time.time()
    return event

async def spam_filter_middleware(event: BaseEvent) -> Optional[BaseEvent]:
    """åƒåœ¾è¿‡æ»¤ä¸­é—´ä»¶ï¼šæ‹¦æˆªåŒ…å« 'spam' çš„äº‹ä»¶"""
    if event.data.get("is_spam"):
        print(f"ğŸš« [Middleware] Blocked spam event: {event.type}")
        return None  # è¿”å› None æ‹¦æˆªäº‹ä»¶
    return event

# ==========================================
# 4. ä¸»æ¼”ç¤ºæµç¨‹
# ==========================================

async def main():
    print("ğŸš€ Starting EventBus Demo...\n")

    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨å¤„ç† shutdown
    async with EventBus() as bus:
        
        # --- æ³¨å†Œç»„ä»¶ ---
        print("1ï¸âƒ£  Registering Handlers & Middleware")
        
        # è®¢é˜…ç‰¹å®šäº‹ä»¶
        bus.subscribe("user.login", async_logger)
        bus.subscribe("user.login", sync_metrics)
        
        # è®¢é˜…æ‰€æœ‰äº‹ä»¶ (é€šé…ç¬¦)
        bus.subscribe("*", lambda e: print(f"ğŸ‘€ [Global Watcher] Saw {e.type}"))
        
        # æ³¨å†Œä¸­é—´ä»¶
        bus.add_middleware(audit_middleware)
        bus.add_middleware(spam_filter_middleware)
        print("   Done.\n")

        # --- åœºæ™¯ 1: æ­£å¸¸å‘å¸ƒ (ç­‰å¾…æ¨¡å¼) ---
        print("2ï¸âƒ£  Publishing User Login (Wait=True)")
        login_event = UserLoginEvent(data={"user_id": 101, "ip": "127.0.0.1"})
        
        await bus.publish(login_event, wait=True)
        # æ­¤æ—¶ async_logger å·²ç»æ‰§è¡Œå®Œæ¯•
        print("   Event processing completed.\n")

        # --- åœºæ™¯ 2: ä¸­é—´ä»¶æ‹¦æˆª ---
        print("3ï¸âƒ£  Publishing Spam Event")
        spam_event = OrderCreatedEvent(data={"order_id": 999, "is_spam": True})
        
        await bus.publish(spam_event, wait=True)
        print("   Spam event published (should be blocked).\n")

        # --- åœºæ™¯ 3: åå°ä»»åŠ¡ (ä¸ç­‰å¾…) ---
        print("4ï¸âƒ£  Publishing Slow Event (Wait=False)")
        
        # ä¸´æ—¶è®¢é˜…ä¸€ä¸ªæ…¢é€Ÿä»»åŠ¡
        bus.subscribe("order.created", slow_processor)
        
        order_event = OrderCreatedEvent(data={"order_id": 202, "amount": 50.0})
        
        # è¿™é‡Œä¸ä¼šé˜»å¡ 1ç§’ï¼Œè€Œæ˜¯ç«‹å³è¿”å›
        start_time = time.time()
        await bus.publish(order_event, wait=False)
        print(f"   Publish returned in {time.time() - start_time:.4f}s (Non-blocking)")
        print("   Main logic continues doing other work...\n")

    # --- è‡ªåŠ¨ Shutdown ---
    # é€€å‡º async with å—æ—¶ï¼Œä¼šè‡ªåŠ¨è°ƒç”¨ shutdown(wait=True)
    # è¿™å°†ç­‰å¾…ä¸Šé¢çš„ slow_processor æ‰§è¡Œå®Œæ¯•
    print("5ï¸âƒ£  EventBus Shutdown")
    print("   Context manager exited. All background tasks should be finished now.")

if __name__ == "__main__":
    asyncio.run(main())
```

[9] examples/core/memory_demo.py
```python
# examples/memory_demo.py
import asyncio
from unittest.mock import MagicMock
from gecko.core.memory import TokenMemory
from gecko.core.message import Message
from gecko.plugins.storage.backends.sqlite import SQLiteStorage


async def main():
    # 1. åˆ›å»ºå­˜å‚¨
    storage = SQLiteStorage("sqlite://./test.db")
    
    # [New] åˆ›å»ºä¸€ä¸ªç®€å•çš„ Mock Driver ç”¨äºæ¼”ç¤ºè®¡æ•°å§”æ‰˜
    mock_driver = MagicMock()
    mock_driver.count_tokens.return_value = 10 # æ¨¡æ‹Ÿæ¯æ¬¡è¿”å› 10 tokens
    
    # 2. åˆ›å»º TokenMemory
    memory = TokenMemory(
        session_id="user_123",
        storage=storage,
        max_tokens=4000,
        model_name="gpt-4",
        # [New] æ³¨å…¥ driver
        model_driver=mock_driver, 
        cache_size=1000,
        max_message_length=10000
    )
    
    print(memory)
    
    # 3. è®¡ç®—å•æ¡æ¶ˆæ¯
    msg = Message.user("What's the weather today?")
    tokens = memory.count_message_tokens(msg)
    print(f"\nå•æ¡æ¶ˆæ¯ tokens: {tokens} (Mocked value should be > 0)")
    
    # 4. æ‰¹é‡è®¡ç®—
    messages = [
        Message.user("Hello"),
        Message.assistant("Hi there!"),
        Message.user("How are you?"),
    ]
    
    # ä½¿ç”¨ç¼“å­˜
    counts1 = memory.count_messages_batch(messages, use_cache=True)
    print(f"\næ‰¹é‡è®¡æ•°ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰: {counts1}")
    
    # ä¸ä½¿ç”¨ç¼“å­˜ï¼ˆæ›´å¿«ï¼Œä½†ä¸ç¼“å­˜ç»“æœï¼‰
    counts2 = memory.count_messages_batch(messages, use_cache=False)
    print(f"æ‰¹é‡è®¡æ•°ï¼ˆä¸ä½¿ç”¨ç¼“å­˜ï¼‰: {counts2}")
    
    # 5. æµ‹è¯•ç¼“å­˜æ€§èƒ½
    print("\n=== ç¼“å­˜æ€§èƒ½æµ‹è¯• ===")
    
    # é¦–æ¬¡è®¡æ•°ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
    for _ in range(3):
        memory.count_message_tokens(msg)
    
    # æŸ¥çœ‹ç»Ÿè®¡
    memory.print_cache_stats()
    
    # 6. å†å²åŠ è½½æµ‹è¯•
    print("\n=== å†å²åŠ è½½æµ‹è¯• ===")
    
    # æ„é€ å¤§é‡å†å²æ¶ˆæ¯
    raw_messages = [
        {"role": "system", "content": "You are a helpful assistant."},
    ]
    
    for i in range(100):
        raw_messages.append({
            "role": "user",
            "content": f"Question {i}: Can you help me?"
        })
        raw_messages.append({
            "role": "assistant",
            "content": f"Answer {i}: Of course! I'm here to help."
        })
    
    # åŠ è½½å†å²ï¼ˆè‡ªåŠ¨è£å‰ªï¼‰
    history = await memory.get_history(raw_messages)
    
    print(f"åŸå§‹æ¶ˆæ¯æ•°: {len(raw_messages)}")
    print(f"åŠ è½½åæ¶ˆæ¯æ•°: {len(history)}")
    print(f"æ€» tokens: {sum(memory.count_message_tokens(m) for m in history)}")
    
    # 7. æ¸…ç©ºç¼“å­˜
    memory.clear_cache()
    print("\nç¼“å­˜å·²æ¸…ç©º")
    memory.print_cache_stats()


if __name__ == "__main__":
    asyncio.run(main())
```

[10] examples/core/message_demo.py
```python
# examples/message_demo.py
import asyncio
from gecko.core.message import Message, MediaResource


async def main():
    print("=== Gecko Message ç¤ºä¾‹ ===\n")
    
    # 1. ç®€å•æ–‡æœ¬æ¶ˆæ¯
    print("1. ç®€å•æ–‡æœ¬æ¶ˆæ¯")
    user_msg = Message.user("Hello, how are you?")
    print(f"   {user_msg}")
    print(f"   OpenAI æ ¼å¼: {user_msg.to_openai_format()}\n")
    
    # 2. åŠ©æ‰‹æ¶ˆæ¯
    print("2. åŠ©æ‰‹æ¶ˆæ¯")
    assistant_msg = Message.assistant("I'm doing great, thanks!")
    print(f"   {assistant_msg}\n")
    
    # 3. ç³»ç»Ÿæ¶ˆæ¯
    print("3. ç³»ç»Ÿæ¶ˆæ¯")
    system_msg = Message.system("You are a helpful assistant.")
    print(f"   {system_msg}\n")
    
    # 4. å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆåŒæ­¥ï¼‰
    print("4. å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆåŒæ­¥ï¼‰")
    # å‡è®¾æœ‰æœ¬åœ°å›¾ç‰‡
    # multimodal_msg = Message.user(
    #     text="What's in this image?",
    #     images=["./test_image.jpg"]
    # )
    # print(f"   {multimodal_msg}")
    # print(f"   åŒ…å« {multimodal_msg.get_image_count()} å¼ å›¾ç‰‡\n")
    
    # 5. å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆå¼‚æ­¥ï¼‰
    print("5. å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆå¼‚æ­¥ï¼‰")
    # async_msg = await Message.user_async(
    #     text="Analyze these images",
    #     images=["./image1.jpg", "./image2.jpg"]
    # )
    # print(f"   {async_msg}\n")
    
    # 6. å·¥å…·è¿”å›æ¶ˆæ¯
    print("6. å·¥å…·è¿”å›æ¶ˆæ¯")
    tool_msg = Message.tool_result(
        tool_call_id="call_123",
        content={"result": "Search completed", "count": 42},
        tool_name="search"
    )
    print(f"   {tool_msg}")
    print(f"   å†…å®¹: {tool_msg.get_text_content()[:50]}\n")
    
    # 7. ä» OpenAI æ ¼å¼è§£æ
    print("7. ä» OpenAI æ ¼å¼è§£æ")
    openai_format = {
        "role": "assistant",
        "content": "Here's what I found...",
        "tool_calls": [
            {
                "id": "call_1",
                "function": {
                    "name": "search",
                    "arguments": '{"query": "test"}'
                }
            }
        ]
    }
    parsed_msg = Message.from_openai(openai_format)
    print(f"   {parsed_msg}\n")
    
    # 8. æ¶ˆæ¯å·¥å…·æ–¹æ³•
    print("8. æ¶ˆæ¯å·¥å…·æ–¹æ³•")
    long_msg = Message.user("This is a very long message " * 20)
    print(f"   åŸå§‹é•¿åº¦: {len(long_msg.get_text_content())}")
    
    truncated = long_msg.truncate_content(50)
    print(f"   æˆªæ–­å: {truncated.get_text_content()}")
    
    print(f"   æ˜¯å¦ä¸ºç©º: {long_msg.is_empty()}")
    print(f"   æ˜¯å¦æœ‰å›¾ç‰‡: {long_msg.has_images()}\n")
    
    # 9. æ¶ˆæ¯å…‹éš†
    print("9. æ¶ˆæ¯å…‹éš†")
    cloned = user_msg.clone()
    print(f"   åŸå§‹: {user_msg}")
    print(f"   å…‹éš†: {cloned}")
    print(f"   æ˜¯å¦ç›¸åŒå¯¹è±¡: {cloned is user_msg}\n")
    
    # 10. MediaResource ç¤ºä¾‹
    print("10. MediaResource ç¤ºä¾‹")
    # ä» URL
    url_resource = MediaResource(
        url="https://example.com/image.jpg",
        detail="high"
    )
    print(f"   URL èµ„æº: {url_resource.to_openai_image_url()}")
    
    # ä» base64
    base64_resource = MediaResource(
        base64_data="iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==",
        mime_type="image/png"
    )
    print(f"   Base64 å¤§å°ä¼°ç®—: {base64_resource.get_size_estimate()} bytes\n")


if __name__ == "__main__":
    asyncio.run(main())
```

[11] examples/core/output_demo.py
```python
# examples/output_demo.py
from gecko.core.output import (
    AgentOutput,
    TokenUsage,
    create_text_output,
    create_tool_output,
    merge_outputs
)


def main():
    print("=== Gecko AgentOutput ç¤ºä¾‹ ===\n")
    
    # 1. ç®€å•æ–‡æœ¬è¾“å‡º
    print("1. ç®€å•æ–‡æœ¬è¾“å‡º")
    output1 = AgentOutput(content="Hello, how can I help you today?")
    print(f"   {output1}")
    print(f"   æœ‰å†…å®¹: {output1.has_content()}")
    print(f"   æ˜¯å¦ä¸ºç©º: {output1.is_empty()}\n")
    
    # 2. å¸¦ Token ä½¿ç”¨çš„è¾“å‡º
    print("2. å¸¦ Token ä½¿ç”¨ç»Ÿè®¡")
    usage = TokenUsage(
        prompt_tokens=100,
        completion_tokens=50,
        total_tokens=150
    )
    output2 = AgentOutput(
        content="Based on my analysis...",
        usage=usage
    )
    print(f"   {output2}")
    print(f"   Usage: {output2.usage}")
    
    # ä¼°ç®—æˆæœ¬ï¼ˆGPT-4 ä»·æ ¼ç¤ºä¾‹ï¼‰
    cost = usage.get_cost_estimate(
        prompt_price_per_1k=0.03,
        completion_price_per_1k=0.06
    )
    print(f"   ä¼°ç®—æˆæœ¬: ${cost:.4f}\n")
    
    # 3. å¸¦å·¥å…·è°ƒç”¨çš„è¾“å‡º
    print("3. å¸¦å·¥å…·è°ƒç”¨çš„è¾“å‡º")
    output3 = AgentOutput(
        content="I'll search for that information.",
        tool_calls=[
            {
                "id": "call_1",
                "function": {
                    "name": "search",
                    "arguments": '{"query": "AI trends 2024"}'
                }
            },
            {
                "id": "call_2",
                "function": {
                    "name": "calculator",
                    "arguments": '{"expression": "2+2"}'
                }
            }
        ]
    )
    print(f"   {output3}")
    print(f"   å·¥å…·è°ƒç”¨æ•°: {output3.tool_call_count()}")
    print(f"   å·¥å…·åç§°: {output3.get_tool_names()}\n")
    
    # 4. æ ¼å¼åŒ–è¾“å‡º
    print("4. æ ¼å¼åŒ–è¾“å‡º")
    print(output3.format())
    
    # 5. è¾“å‡ºç»Ÿè®¡
    print("5. è¾“å‡ºç»Ÿè®¡")
    stats = output3.get_stats()
    print(f"   ç»Ÿè®¡ä¿¡æ¯: {stats}\n")
    
    # 6. è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
    print("6. è½¬æ¢ä¸º OpenAI æ¶ˆæ¯æ ¼å¼")
    msg_dict = output3.to_message_dict()
    print(f"   {msg_dict}\n")
    
    # 7. ä½¿ç”¨å·¥å…·å‡½æ•°å¿«é€Ÿåˆ›å»º
    print("7. ä½¿ç”¨å·¥å…·å‡½æ•°")
    quick_output = create_text_output(
        "Quick response",
        usage=TokenUsage(prompt_tokens=10, completion_tokens=5),
        source="demo"
    )
    print(f"   {quick_output}")
    print(f"   å…ƒæ•°æ®: {quick_output.metadata}\n")
    
    # 8. åˆå¹¶å¤šä¸ªè¾“å‡º
    print("8. åˆå¹¶å¤šä¸ªè¾“å‡º")
    out1 = AgentOutput(content="Part 1", usage=TokenUsage(prompt_tokens=10, completion_tokens=5))
    out2 = AgentOutput(content="Part 2", usage=TokenUsage(prompt_tokens=20, completion_tokens=10))
    
    merged = merge_outputs([out1, out2])
    print(f"   åˆå¹¶å†…å®¹: {merged.content}")
    print(f"   åˆå¹¶ usage: {merged.usage}\n")
    
    # 9. è¾“å‡ºé¢„è§ˆ
    print("9. æ–‡æœ¬é¢„è§ˆ")
    long_output = AgentOutput(content="A" * 200)
    preview = long_output.get_text_preview(50)
    print(f"   é¢„è§ˆ: {preview}\n")
    
    # 10. å¸ƒå°”å€¼è½¬æ¢
    print("10. å¸ƒå°”å€¼è½¬æ¢")
    empty_output = AgentOutput()
    print(f"   ç©ºè¾“å‡º: bool(empty_output) = {bool(empty_output)}")
    print(f"   æœ‰æ•ˆè¾“å‡º: bool(output1) = {bool(output1)}")


if __name__ == "__main__":
    main()
```

[12] examples/core/prompt_demo.py
```python
# examples/prompt_demo.py
from gecko.core.prompt import PromptTemplate, PromptLibrary


def main():
    print("=== Gecko Prompt æ¨¡æ¿ç¤ºä¾‹ ===\n")
    
    # 1. åŸºç¡€æ¨¡æ¿
    print("1. åŸºç¡€æ¨¡æ¿")
    template = PromptTemplate(
        template="Hello, {{ name }}! You are {{ age }} years old.",
        input_variables=["name", "age"]
    )
    result = template.format(name="Alice", age=25)
    print(f"   ç»“æœ: {result}\n")
    
    # 2. å¸¦æ¡ä»¶çš„æ¨¡æ¿
    print("2. å¸¦æ¡ä»¶çš„æ¨¡æ¿")
    conditional = PromptTemplate(
        template="""
{% if premium %}
Welcome, Premium User {{ name }}!
You have access to advanced features.
{% else %}
Welcome, {{ name }}!
Consider upgrading to Premium.
{% endif %}
        """,
        input_variables=["name", "premium"]
    )
    print(conditional.format(name="Bob", premium=True))
    print(conditional.format(name="Charlie", premium=False))
    
    # 3. å¸¦å¾ªç¯çš„æ¨¡æ¿
    print("3. å¸¦å¾ªç¯çš„æ¨¡æ¿")
    loop_template = PromptTemplate(
        template="""
Available tools:
{% for tool in tools %}
- {{ tool.name }}: {{ tool.description }}
{% endfor %}
        """,
        input_variables=["tools"]
    )
    tools = [
        {"name": "search", "description": "Search the web"},
        {"name": "calculator", "description": "Perform calculations"},
    ]
    print(loop_template.format(tools=tools))
    
    # 4. è‡ªåŠ¨æå–å˜é‡
    print("4. è‡ªåŠ¨æå–å˜é‡")
    auto_template = PromptTemplate(
        template="User {{ user }} asked: {{ question }}"
    )
    detected_vars = auto_template.get_variables_from_template()
    print(f"   æ£€æµ‹åˆ°çš„å˜é‡: {detected_vars}")
    auto_template.input_variables = list(detected_vars)
    print(f"   æ ¼å¼åŒ–: {auto_template.format(user='Alice', question='What is AI?')}\n")
    
    # 5. éƒ¨åˆ†å¡«å……
    print("5. éƒ¨åˆ†å¡«å……")
    partial_template = PromptTemplate(
        template="Translate {{ text }} from {{ source }} to {{ target }}",
        input_variables=["text", "source", "target"]
    )
    # å›ºå®šæºè¯­è¨€å’Œç›®æ ‡è¯­è¨€
    partial = partial_template.partial(source="English", target="Chinese")
    print(f"   å‰©ä½™å˜é‡: {partial.input_variables}")
    print(f"   ç»“æœ: {partial.format(text='Hello')}\n")
    
    # 6. å®‰å…¨æ ¼å¼åŒ–ï¼ˆç¼ºå°‘å˜é‡ï¼‰
    print("6. å®‰å…¨æ ¼å¼åŒ–")
    result = template.format_safe(name="David")  # ç¼ºå°‘ age
    print(f"   ç»“æœ: {result}\n")
    
    # 7. ä»æ–‡ä»¶åŠ è½½ï¼ˆç¤ºä¾‹ï¼‰
    # print("7. ä»æ–‡ä»¶åŠ è½½")
    # template = PromptTemplate.from_file("./prompts/system.txt")
    
    # 8. Few-shot æ¨¡æ¿
    print("8. Few-shot å­¦ä¹ æ¨¡æ¿")
    examples = [
        {"input": "2 + 2", "output": "4"},
        {"input": "5 + 3", "output": "8"},
        {"input": "10 - 7", "output": "3"},
    ]
    few_shot = PromptTemplate.from_examples(
        examples,
        template="Q: {{ input }}\nA: {{ output }}"
    )
    print(few_shot.template)
    print()
    
    # 9. ä½¿ç”¨é¢„å®šä¹‰æ¨¡æ¿
    print("9. ä½¿ç”¨é¢„å®šä¹‰æ¨¡æ¿åº“")
    react_template = PromptLibrary.get_react_prompt()
    react_prompt = react_template.format(
        tools=[
            {"name": "search", "description": "Search the web"},
        ],
        question="What is the capital of France?"
    )
    print(react_prompt)
    print()
    
    # 10. æ‘˜è¦æ¨¡æ¿
    print("10. æ‘˜è¦æ¨¡æ¿")
    summary_template = PromptLibrary.get_summarization_prompt()
    summary_prompt = summary_template.format(
        text="This is a very long text that needs to be summarized...",
        max_words=20
    )
    print(summary_prompt)


if __name__ == "__main__":
    main()
```

[13] examples/core/protocol_demo.py
```python
# examples/protocol_demo.py
"""
Gecko Protocol æ¼”ç¤ºæ–‡ä»¶

å±•ç¤ºå¦‚ä½•å®ç°å’Œä½¿ç”¨ Gecko æ¡†æ¶ä¸­å®šä¹‰çš„å„ç§åè®®ã€‚

åŒ…å«çš„æ¼”ç¤ºï¼š
1. ModelProtocol - åŸºç¡€æ¨¡å‹å®ç°
2. StreamableModelProtocol - æµå¼æ¨¡å‹å®ç°
3. StorageProtocol - å­˜å‚¨åç«¯å®ç°
4. ToolProtocol - å·¥å…·å®ç°
5. EmbedderProtocol - åµŒå…¥æ¨¡å‹å®ç°
6. RunnableProtocol - å¯è¿è¡Œå¯¹è±¡å®ç°
7. VectorStoreProtocol - å‘é‡å­˜å‚¨å®ç°
8. èƒ½åŠ›æ£€æµ‹å’ŒéªŒè¯

è¿è¡Œæ–¹å¼:
    python examples/protocol_demo.py
"""

import asyncio
from typing import Any, AsyncIterator, Dict, List, Optional

from gecko.core.protocols import (
    # åè®®
    ModelProtocol,
    StreamableModelProtocol,
    StorageProtocol,
    ToolProtocol,
    EmbedderProtocol,
    RunnableProtocol,
    VectorStoreProtocol,
    # å“åº”æ¨¡å‹
    CompletionResponse,
    CompletionChoice,
    CompletionUsage,
    StreamChunk,
    # å·¥å…·å‡½æ•°
    check_protocol,
    supports_streaming,
    supports_function_calling,
    supports_vision,
    get_model_name,
    validate_model,
    validate_storage,
    validate_tool,
)


# ==================== 1. ModelProtocol ç¤ºä¾‹ ====================

class SimpleModel:
    """
    ç®€å•çš„æ¨¡å‹å®ç°ï¼ˆä»…æ”¯æŒè¡¥å…¨ï¼‰
    
    æ¼”ç¤ºï¼š
    - å®ç° ModelProtocol çš„æœ€å°è¦æ±‚
    - è¿”å›æ ‡å‡†çš„ CompletionResponse
    """
    
    def __init__(self, model_name: str = "simple-model-v1"):
        self.model_name = model_name
        self._call_count = 0
    
    async def acompletion(
        self, 
        messages: List[Dict[str, Any]], 
        **kwargs
    ) -> CompletionResponse:
        """å¼‚æ­¥è¡¥å…¨æ¥å£"""
        self._call_count += 1
        
        # æ¨¡æ‹Ÿ API è°ƒç”¨å»¶è¿Ÿ
        await asyncio.sleep(0.1)
        
        # æå–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        user_message = next(
            (msg["content"] for msg in reversed(messages) if msg["role"] == "user"),
            "No user message"
        )
        
        # æ„å»ºå“åº”
        response_content = f"Echo: {user_message} (call #{self._call_count})"
        
        return CompletionResponse(
            id=f"cmpl-{self._call_count}",
            model=self.model_name,
            created=1234567890,
            choices=[
                CompletionChoice(
                    index=0,
                    message={
                        "role": "assistant",
                        "content": response_content
                    },
                    finish_reason="stop"
                )
            ],
            usage=CompletionUsage(
                prompt_tokens=len(user_message),
                completion_tokens=len(response_content),
                total_tokens=len(user_message) + len(response_content)
            )
        )
    
    def count_tokens(self, text_or_messages) -> int:
        return 100 # Demo implementation


# ==================== 2. StreamableModelProtocol ç¤ºä¾‹ ====================

class StreamingModel:
    """
    æ”¯æŒæµå¼è¾“å‡ºçš„æ¨¡å‹
    
    æ¼”ç¤ºï¼š
    - å®ç° StreamableModelProtocol
    - æµå¼ç”Ÿæˆå“åº”å†…å®¹
    """
    
    def __init__(self, model_name: str = "streaming-model-v1"):
        self.model_name = model_name
        self._supports_function_calling = True
        self._supports_vision = False
    
    async def acompletion(
        self, 
        messages: List[Dict[str, Any]], 
        **kwargs
    ) -> CompletionResponse:
        """éæµå¼è¡¥å…¨"""
        await asyncio.sleep(0.1)
        
        user_message = next(
            (msg["content"] for msg in reversed(messages) if msg["role"] == "user"),
            ""
        )
        
        response_content = f"Complete response to: {user_message}"
        
        return CompletionResponse(
            id="cmpl-streaming",
            model=self.model_name,
            choices=[
                CompletionChoice(
                    message={"role": "assistant", "content": response_content},
                    finish_reason="stop"
                )
            ]
        )
    
    async def astream(
        self, 
        messages: List[Dict[str, Any]], 
        **kwargs
    ) -> AsyncIterator[StreamChunk]:
        """æµå¼è¡¥å…¨"""
        user_message = next(
            (msg["content"] for msg in reversed(messages) if msg["role"] == "user"),
            ""
        )
        
        response_text = f"Streaming response to: {user_message}"
        words = response_text.split()
        
        for i, word in enumerate(words):
            # æ¨¡æ‹Ÿæµå¼å»¶è¿Ÿ
            await asyncio.sleep(0.05)
            
            # ç”Ÿæˆ chunk
            chunk = StreamChunk(
                id="chunk-streaming",
                model=self.model_name,
                choices=[
                    {
                        "index": 0,
                        "delta": {"content": word + " "},
                        "finish_reason": None if i < len(words) - 1 else "stop"
                    }
                ]
            )
            
            yield chunk

    def count_tokens(self, text_or_messages) -> int:
        return 100 # Demo implementation


# ==================== 3. StorageProtocol ç¤ºä¾‹ ====================

class MemoryStorage:
    """
    å†…å­˜å­˜å‚¨åç«¯ï¼ˆç”¨äºæ¼”ç¤ºå’Œæµ‹è¯•ï¼‰
    
    æ¼”ç¤ºï¼š
    - å®ç° StorageProtocol
    - æ”¯æŒ TTLï¼ˆè¿‡æœŸæ—¶é—´ï¼‰
    """
    
    def __init__(self):
        self._data: Dict[str, Dict[str, Any]] = {}
    
    async def get(self, key: str) -> Optional[Dict[str, Any]]:
        """è·å–æ•°æ®"""
        if key not in self._data:
            return None
        
        item = self._data[key]
        
        # æ£€æŸ¥ TTL
        if "ttl" in item and "stored_at" in item:
            import time
            age = time.time() - item["stored_at"]
            if age > item["ttl"]:
                # å·²è¿‡æœŸï¼Œåˆ é™¤å¹¶è¿”å› None
                del self._data[key]
                return None
        
        return item.get("value")
    
    async def set(
        self, 
        key: str, 
        value: Dict[str, Any], 
        ttl: Optional[int] = None
    ) -> None:
        """å­˜å‚¨æ•°æ®"""
        import time
        
        self._data[key] = {
            "value": value,
            "stored_at": time.time(),
        }
        
        if ttl is not None:
            self._data[key]["ttl"] = ttl
    
    async def delete(self, key: str) -> bool:
        """åˆ é™¤æ•°æ®"""
        if key in self._data:
            del self._data[key]
            return True
        return False
    
    async def exists(self, key: str) -> bool:
        """æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨ï¼ˆåŒ…å«è¿‡æœŸæ£€æŸ¥ï¼‰"""
        result = await self.get(key)
        return result is not None
    
    async def clear(self) -> None:
        """æ¸…ç©ºæ‰€æœ‰æ•°æ®"""
        self._data.clear()


# ==================== 4. ToolProtocol ç¤ºä¾‹ ====================

class CalculatorTool:
    """
    è®¡ç®—å™¨å·¥å…·
    
    æ¼”ç¤ºï¼š
    - å®ç° ToolProtocol
    - å®šä¹‰å‚æ•° Schema
    - å®‰å…¨æ‰§è¡Œç”¨æˆ·è¾“å…¥
    """
    
    name = "calculator"
    description = "Execute mathematical expressions safely"
    parameters = {
        "type": "object",
        "properties": {
            "expression": {
                "type": "string",
                "description": "The mathematical expression to evaluate (e.g., '2+2', '10*5')"
            }
        },
        "required": ["expression"]
    }
    
    async def execute(self, arguments: Dict[str, Any]) -> str:
        """æ‰§è¡Œè®¡ç®—"""
        expression = arguments.get("expression", "")
        
        # å®‰å…¨æ£€æŸ¥ï¼šä»…å…è®¸æ•°å­—å’ŒåŸºæœ¬è¿ç®—ç¬¦
        allowed_chars = set("0123456789+-*/()., ")
        if not all(c in allowed_chars for c in expression):
            return f"Error: Invalid characters in expression '{expression}'"
        
        try:
            # ä½¿ç”¨ evalï¼ˆåœ¨å—æ§ç¯å¢ƒä¸­ï¼‰
            result = eval(expression, {"__builtins__": {}}, {})
            return f"Result: {result}"
        except Exception as e:
            return f"Error: {str(e)}"


class WebSearchTool:
    """
    ç½‘ç»œæœç´¢å·¥å…·ï¼ˆæ¨¡æ‹Ÿï¼‰
    
    æ¼”ç¤ºï¼š
    - æ›´å¤æ‚çš„å‚æ•° Schema
    - å¼‚æ­¥æ“ä½œ
    """
    
    name = "web_search"
    description = "Search the web for information"
    parameters = {
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "The search query"
            },
            "max_results": {
                "type": "integer",
                "description": "Maximum number of results to return",
                "default": 5
            },
            "language": {
                "type": "string",
                "description": "Search language (e.g., 'en', 'zh')",
                "default": "en"
            }
        },
        "required": ["query"]
    }
    
    async def execute(self, arguments: Dict[str, Any]) -> str:
        """æ‰§è¡Œæœç´¢"""
        query = arguments["query"]
        max_results = arguments.get("max_results", 5)
        language = arguments.get("language", "en")
        
        # æ¨¡æ‹Ÿæœç´¢å»¶è¿Ÿ
        await asyncio.sleep(0.2)
        
        # æ¨¡æ‹Ÿæœç´¢ç»“æœ
        results = [
            f"Result {i+1}: Information about '{query}' (lang: {language})"
            for i in range(max_results)
        ]
        
        return "\n".join(results)


# ==================== 5. EmbedderProtocol ç¤ºä¾‹ ====================

class SimpleEmbedder:
    """
    ç®€å•çš„åµŒå…¥æ¨¡å‹ï¼ˆä½¿ç”¨éšæœºå‘é‡æ¼”ç¤ºï¼‰
    
    æ¼”ç¤ºï¼š
    - å®ç° EmbedderProtocol
    - æ‰¹é‡å¤„ç†æ–‡æœ¬
    """
    
    def __init__(self, dimension: int = 384):
        self._dimension = dimension
    
    async def embed(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡åµŒå…¥æ–‡æœ¬"""
        import random
        
        # æ¨¡æ‹Ÿ API å»¶è¿Ÿ
        await asyncio.sleep(0.1)
        
        # ç”Ÿæˆéšæœºå‘é‡ï¼ˆå®é™…åº”è°ƒç”¨çœŸå®çš„åµŒå…¥æ¨¡å‹ï¼‰
        embeddings = []
        for text in texts:
            # ä½¿ç”¨æ–‡æœ¬é•¿åº¦ä½œä¸ºç§å­ï¼Œä¿æŒä¸€è‡´æ€§
            random.seed(len(text))
            embedding = [random.random() for _ in range(self._dimension)]
            embeddings.append(embedding)
        
        return embeddings
    
    async def embed_single(self, text: str) -> List[float]:
        """åµŒå…¥å•ä¸ªæ–‡æœ¬"""
        results = await self.embed([text])
        return results[0]
    
    def get_dimension(self) -> int:
        """è·å–å‘é‡ç»´åº¦"""
        return self._dimension


# ==================== 6. RunnableProtocol ç¤ºä¾‹ ====================

class SimpleAgent:
    """
    ç®€å•çš„å¯è¿è¡Œ Agent
    
    æ¼”ç¤ºï¼š
    - å®ç° RunnableProtocol
    - ç»Ÿä¸€çš„è¿è¡Œæ¥å£
    """
    
    def __init__(self, name: str = "SimpleAgent"):
        self.name = name
    
    async def run(self, input: Any) -> str:
        """è¿è¡Œ Agent"""
        # å¤„ç†ä¸åŒç±»å‹çš„è¾“å…¥
        if isinstance(input, str):
            query = input
        elif isinstance(input, dict):
            query = input.get("query", str(input))
        else:
            query = str(input)
        
        # æ¨¡æ‹Ÿå¤„ç†
        await asyncio.sleep(0.1)
        
        return f"[{self.name}] Processed: {query}"


# ==================== 7. VectorStoreProtocol ç¤ºä¾‹ ====================

class SimpleVectorStore:
    """
    ç®€å•çš„å‘é‡å­˜å‚¨ï¼ˆå†…å­˜å®ç°ï¼‰
    
    æ¼”ç¤ºï¼š
    - å®ç° VectorStoreProtocol
    - ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢
    """
    
    def __init__(self):
        self._vectors: Dict[str, List[float]] = {}
        self._metadata: Dict[str, Dict[str, Any]] = {}
    
    async def add(
        self,
        ids: List[str],
        vectors: List[List[float]],
        metadata: Optional[List[Dict[str, Any]]] = None,
    ) -> None:
        """æ·»åŠ å‘é‡"""
        for i, vector_id in enumerate(ids):
            self._vectors[vector_id] = vectors[i]
            if metadata and i < len(metadata):
                self._metadata[vector_id] = metadata[i]
    
    async def search(
        self,
        query_vector: List[float],
        top_k: int = 5,
        filters: Optional[Dict[str, Any]] = None,
    ) -> List[Dict[str, Any]]:
        """æ£€ç´¢ç›¸ä¼¼å‘é‡"""
        import math
        
        def cosine_similarity(v1: List[float], v2: List[float]) -> float:
            """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
            dot_product = sum(a * b for a, b in zip(v1, v2))
            magnitude1 = math.sqrt(sum(a * a for a in v1))
            magnitude2 = math.sqrt(sum(b * b for b in v2))
            
            if magnitude1 == 0 or magnitude2 == 0:
                return 0.0
            
            return dot_product / (magnitude1 * magnitude2)
        
        # è®¡ç®—æ‰€æœ‰å‘é‡çš„ç›¸ä¼¼åº¦
        similarities = []
        for vector_id, vector in self._vectors.items():
            # åº”ç”¨è¿‡æ»¤å™¨ï¼ˆå¦‚æœæœ‰ï¼‰
            if filters:
                metadata = self._metadata.get(vector_id, {})
                if not all(metadata.get(k) == v for k, v in filters.items()):
                    continue
            
            score = cosine_similarity(query_vector, vector)
            similarities.append({
                "id": vector_id,
                "score": score,
                "metadata": self._metadata.get(vector_id, {})
            })
        
        # æ’åºå¹¶è¿”å› top_k
        similarities.sort(key=lambda x: x["score"], reverse=True)
        return similarities[:top_k]
    
    async def delete(self, ids: List[str]) -> None:
        """åˆ é™¤å‘é‡"""
        for vector_id in ids:
            self._vectors.pop(vector_id, None)
            self._metadata.pop(vector_id, None)
    
    async def update(
        self,
        ids: List[str],
        metadata: List[Dict[str, Any]],
    ) -> None:
        """æ›´æ–°å…ƒæ•°æ®"""
        for i, vector_id in enumerate(ids):
            if vector_id in self._vectors and i < len(metadata):
                self._metadata[vector_id] = metadata[i]


# ==================== æ¼”ç¤ºå‡½æ•° ====================

async def demo_model_protocol():
    """æ¼”ç¤º ModelProtocol"""
    print("\n" + "=" * 60)
    print("1. ModelProtocol æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡å‹
    model = SimpleModel()
    
    # éªŒè¯åè®®
    print(f"âœ“ å®ç°äº† ModelProtocol: {check_protocol(model, ModelProtocol)}")
    print(f"âœ“ æ”¯æŒæµå¼: {supports_streaming(model)}")
    print(f"âœ“ æ¨¡å‹åç§°: {get_model_name(model)}")
    
    # è°ƒç”¨æ¨¡å‹
    messages = [
        {"role": "user", "content": "Hello, world!"}
    ]
    
    response = await model.acompletion(messages)
    print(f"\nè¯·æ±‚: {messages[0]['content']}")
    print(f"å“åº”: {response.choices[0].message['content']}")
    print(f"Token ä½¿ç”¨: {response.usage.total_tokens}") # type: ignore


async def demo_streaming_model():
    """æ¼”ç¤º StreamableModelProtocol"""
    print("\n" + "=" * 60)
    print("2. StreamableModelProtocol æ¼”ç¤º")
    print("=" * 60)
    
    model = StreamingModel()
    
    print(f"âœ“ å®ç°äº† StreamableModelProtocol: {check_protocol(model, StreamableModelProtocol)}")
    print(f"âœ“ æ”¯æŒæµå¼: {supports_streaming(model)}")
    print(f"âœ“ æ”¯æŒå‡½æ•°è°ƒç”¨: {supports_function_calling(model)}")
    
    # æµå¼è°ƒç”¨
    messages = [{"role": "user", "content": "Tell me a story"}]
    
    print("\næµå¼è¾“å‡º: ", end="")
    async for chunk in model.astream(messages):
        if chunk.content:
            print(chunk.content, end="", flush=True)
    print()


async def demo_storage_protocol():
    """æ¼”ç¤º StorageProtocol"""
    print("\n" + "=" * 60)
    print("3. StorageProtocol æ¼”ç¤º")
    print("=" * 60)
    
    storage = MemoryStorage()
    
    print(f"âœ“ å®ç°äº† StorageProtocol: {check_protocol(storage, StorageProtocol)}")
    validate_storage(storage)
    
    # å­˜å‚¨æ•°æ®
    await storage.set("user:123", {"name": "Alice", "age": 25})
    print("\nâœ“ å­˜å‚¨æ•°æ®: user:123")
    
    # è·å–æ•°æ®
    data = await storage.get("user:123")
    print(f"âœ“ è·å–æ•°æ®: {data}")
    
    # å¸¦ TTL çš„å­˜å‚¨
    await storage.set("temp:session", {"token": "abc123"}, ttl=2)
    print("\nâœ“ å­˜å‚¨ä¸´æ—¶æ•°æ® (TTL: 2ç§’)")
    
    print("âœ“ ç«‹å³è·å–:", await storage.get("temp:session"))
    
    print("âœ“ ç­‰å¾… 3 ç§’...")
    await asyncio.sleep(3)
    
    print("âœ“ å†æ¬¡è·å–:", await storage.get("temp:session"))


async def demo_tool_protocol():
    """æ¼”ç¤º ToolProtocol"""
    print("\n" + "=" * 60)
    print("4. ToolProtocol æ¼”ç¤º")
    print("=" * 60)
    
    # è®¡ç®—å™¨å·¥å…·
    calc = CalculatorTool()
    
    print(f"âœ“ å·¥å…·åç§°: {calc.name}")
    print(f"âœ“ å·¥å…·æè¿°: {calc.description}")
    print(f"âœ“ å®ç°äº† ToolProtocol: {check_protocol(calc, ToolProtocol)}")
    
    validate_tool(calc)
    
    # æ‰§è¡Œå·¥å…·
    result1 = await calc.execute({"expression": "2 + 2"})
    print(f"\nè®¡ç®— '2 + 2': {result1}")
    
    result2 = await calc.execute({"expression": "10 * 5 + 3"})
    print(f"è®¡ç®— '10 * 5 + 3': {result2}")
    
    # æœç´¢å·¥å…·
    print("\n" + "-" * 60)
    search = WebSearchTool()
    
    print(f"âœ“ å·¥å…·åç§°: {search.name}")
    validate_tool(search)
    
    result = await search.execute({
        "query": "Python asyncio",
        "max_results": 3,
        "language": "en"
    })
    print(f"\næœç´¢ç»“æœ:\n{result}")


async def demo_embedder_protocol():
    """æ¼”ç¤º EmbedderProtocol"""
    print("\n" + "=" * 60)
    print("5. EmbedderProtocol æ¼”ç¤º")
    print("=" * 60)
    
    embedder = SimpleEmbedder(dimension=8)  # ä½¿ç”¨å°ç»´åº¦ä¾¿äºå±•ç¤º
    
    print(f"âœ“ å®ç°äº† EmbedderProtocol: {check_protocol(embedder, EmbedderProtocol)}")
    print(f"âœ“ å‘é‡ç»´åº¦: {embedder.get_dimension()}")
    
    # åµŒå…¥å•ä¸ªæ–‡æœ¬
    text = "Hello, world!"
    embedding = await embedder.embed_single(text)
    print(f"\næ–‡æœ¬: '{text}'")
    print(f"å‘é‡ (å‰5ç»´): {[f'{x:.4f}' for x in embedding[:5]]}")
    
    # æ‰¹é‡åµŒå…¥
    texts = ["Python", "JavaScript", "Rust"]
    embeddings = await embedder.embed(texts)
    print(f"\næ‰¹é‡åµŒå…¥ {len(texts)} ä¸ªæ–‡æœ¬:")
    for text, emb in zip(texts, embeddings):
        print(f"  '{text}': {[f'{x:.4f}' for x in emb[:5]]}")


async def demo_runnable_protocol():
    """æ¼”ç¤º RunnableProtocol"""
    print("\n" + "=" * 60)
    print("6. RunnableProtocol æ¼”ç¤º")
    print("=" * 60)
    
    agent = SimpleAgent(name="DemoAgent")
    
    print(f"âœ“ å®ç°äº† RunnableProtocol: {check_protocol(agent, RunnableProtocol)}")
    
    # ä¸åŒç±»å‹çš„è¾“å…¥
    result1 = await agent.run("What is AI?")
    print(f"\nå­—ç¬¦ä¸²è¾“å…¥: {result1}")
    
    result2 = await agent.run({"query": "Explain Python", "context": "beginner"})
    print(f"å­—å…¸è¾“å…¥: {result2}")


async def demo_vector_store_protocol():
    """æ¼”ç¤º VectorStoreProtocol"""
    print("\n" + "=" * 60)
    print("7. VectorStoreProtocol æ¼”ç¤º")
    print("=" * 60)
    
    store = SimpleVectorStore()
    embedder = SimpleEmbedder(dimension=8)
    
    print(f"âœ“ å®ç°äº† VectorStoreProtocol: {check_protocol(store, VectorStoreProtocol)}")
    
    # å‡†å¤‡æ–‡æ¡£
    documents = [
        "Python is a programming language",
        "JavaScript is used for web development",
        "Machine learning is a subset of AI",
        "Deep learning uses neural networks"
    ]
    
    # ç”ŸæˆåµŒå…¥
    print(f"\næ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£åˆ°å‘é‡åº“...")
    embeddings = await embedder.embed(documents)
    
    await store.add(
        ids=[f"doc_{i}" for i in range(len(documents))],
        vectors=embeddings,
        metadata=[{"text": doc, "index": i} for i, doc in enumerate(documents)]
    )
    
    # æœç´¢
    query = "What is Python?"
    query_embedding = await embedder.embed_single(query)
    
    print(f"\næŸ¥è¯¢: '{query}'")
    results = await store.search(query_embedding, top_k=2)
    
    print("\næœ€ç›¸ä¼¼çš„æ–‡æ¡£:")
    for i, result in enumerate(results, 1):
        print(f"  {i}. {result['metadata']['text']} (ç›¸ä¼¼åº¦: {result['score']:.4f})")


async def demo_protocol_validation():
    """æ¼”ç¤ºåè®®éªŒè¯"""
    print("\n" + "=" * 60)
    print("8. åè®®éªŒè¯æ¼”ç¤º")
    print("=" * 60)
    
    # æœ‰æ•ˆçš„æ¨¡å‹
    valid_model = SimpleModel()
    try:
        validate_model(valid_model)
        print("âœ“ æœ‰æ•ˆæ¨¡å‹éªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"âœ— éªŒè¯å¤±è´¥: {e}")
    
    # æ— æ•ˆçš„æ¨¡å‹
    class InvalidModel:
        pass
    
    invalid_model = InvalidModel()
    try:
        validate_model(invalid_model)
        print("âœ— æ— æ•ˆæ¨¡å‹åº”è¯¥éªŒè¯å¤±è´¥")
    except TypeError as e:
        print(f"âœ“ æ— æ•ˆæ¨¡å‹æ­£ç¡®æ‹’ç»: {str(e)[:50]}...")
    
    # æ— æ•ˆçš„å·¥å…·ï¼ˆç¼ºå°‘å±æ€§ï¼‰
    class InvalidTool:
        async def execute(self, arguments):
            return "result"
    
    invalid_tool = InvalidTool()
    try:
        validate_tool(invalid_tool)
        print("âœ— æ— æ•ˆå·¥å…·åº”è¯¥éªŒè¯å¤±è´¥")
    except ValueError as e:
        print(f"âœ“ æ— æ•ˆå·¥å…·æ­£ç¡®æ‹’ç»: {str(e)[:50]}...")


# ==================== ä¸»å‡½æ•° ====================

async def main():
    """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("Gecko Protocol æ¼”ç¤º")
    print("=" * 60)
    print("\næœ¬æ¼”ç¤ºå°†å±•ç¤ºå¦‚ä½•å®ç°å’Œä½¿ç”¨ Gecko æ¡†æ¶ä¸­çš„å„ç§åè®®ã€‚")
    
    # è¿è¡Œæ‰€æœ‰æ¼”ç¤º
    await demo_model_protocol()
    await demo_streaming_model()
    await demo_storage_protocol()
    await demo_tool_protocol()
    await demo_embedder_protocol()
    await demo_runnable_protocol()
    await demo_vector_store_protocol()
    await demo_protocol_validation()
    
    print("\n" + "=" * 60)
    print("æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)
    print("\næç¤º:")
    print("- æ‰€æœ‰åè®®éƒ½ä½¿ç”¨ Protocol å®šä¹‰ï¼Œæ”¯æŒé¸­å­ç±»å‹")
    print("- ä½¿ç”¨ check_protocol() è¿›è¡Œè¿è¡Œæ—¶ç±»å‹æ£€æŸ¥")
    print("- ä½¿ç”¨ validate_*() å‡½æ•°è¿›è¡Œå®Œæ•´éªŒè¯")
    print("- å®ç°åè®®æ—¶åªéœ€å®ç°å¿…éœ€çš„æ–¹æ³•å’Œå±æ€§")
    print("\nè¯¦ç»†æ–‡æ¡£è¯·å‚è€ƒ: gecko/core/protocols.py")


if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    asyncio.run(main())
```

[14] examples/core/session_demo.py
```python
# examples/session_demo.py
import asyncio
import os
from gecko.core.session import Session, SessionManager
from gecko.plugins.storage.backends.sqlite import SQLiteStorage


async def main():
    print("=== Gecko Session ç¤ºä¾‹ ===\n")
    
    # 1. åŸºç¡€ä¼šè¯ä½¿ç”¨
    print("1. åŸºç¡€ä¼šè¯")
    session = Session(session_id="demo_session")
    
    # è®¾ç½®çŠ¶æ€
    session.set("user_name", "Alice")
    session.set("preferences", {"theme": "dark", "language": "zh"})
    
    # è·å–çŠ¶æ€
    name = session.get("user_name")
    prefs = session.get("preferences")
    print(f"   ç”¨æˆ·: {name}")
    print(f"   åå¥½: {prefs}\n")
    
    # 2. ä½¿ç”¨å­—å…¸è¯­æ³•
    print("2. å­—å…¸è¯­æ³•")
    session["score"] = 100
    session["level"] = 5
    
    print(f"   Score: {session['score']}")
    print(f"   Level: {session['level']}")
    print(f"   Keys: {session.keys()}\n")
    
    # 3. TTL å’Œè¿‡æœŸ
    print("3. TTL å’Œè¿‡æœŸ")
    temp_session = Session(session_id="temp", ttl=5)  # 5 ç§’åè¿‡æœŸ
    temp_session.set("data", "temporary")
    
    print(f"   æ˜¯å¦è¿‡æœŸ: {temp_session.is_expired()}")
    print(f"   å‰©ä½™æ—¶é—´: {temp_session.metadata.time_to_expire():.1f}s")
    
    # å»¶é•¿ TTL
    temp_session.extend_ttl(10)
    print(f"   å»¶é•¿åå‰©ä½™: {temp_session.metadata.time_to_expire():.1f}s\n")
    
    # 4. æ ‡ç­¾ç®¡ç†
    print("4. æ ‡ç­¾ç®¡ç†")
    session.add_tag("premium")
    session.add_tag("verified")
    
    print(f"   æ ‡ç­¾: {session.metadata.tags}")
    print(f"   æ˜¯å¦ premium: {session.has_tag('premium')}\n")
    
    # 5. ä¼šè¯ä¿¡æ¯
    print("5. ä¼šè¯ä¿¡æ¯")
    info = session.get_info() # type: ignore
    print(f"   è®¿é—®æ¬¡æ•°: {info['access_count']}")
    print(f"   çŠ¶æ€é”®æ•°: {info['state_keys']}")
    print(f"   åˆ›å»ºæ—¶é—´: {info['created_at']}\n")
    
    # 6. ä¼šè¯å…‹éš†
    print("6. ä¼šè¯å…‹éš†")
    cloned = session.clone(new_id="cloned_session")
    print(f"   åŸå§‹: {session.session_id}")
    print(f"   å…‹éš†: {cloned.session_id}")
    print(f"   å…‹éš†çš„æ•°æ®: {cloned.get('user_name')}\n")
    
    # 7. æŒä¹…åŒ–ä¸ä¸€è‡´æ€§æµ‹è¯• [ä¿®æ”¹]
    print("7. æŒä¹…åŒ–ä¸ä¸€è‡´æ€§æµ‹è¯•")
    
    # [ä¿®å¤] ä½¿ç”¨æ›´å¥å£®çš„æ•°æ®åº“è·¯å¾„å¤„ç†
    db_file = "session_demo.db"
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œæˆ–è€…ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•çš„ç»å¯¹è·¯å¾„
    # è¿™é‡Œä½¿ç”¨ os.getcwd() ç¡®ä¿åœ¨å½“å‰è¿è¡Œç›®å½•ä¸‹åˆ›å»º
    db_path = os.path.join(os.getcwd(), db_file)
    db_url = f"sqlite:///{db_path}"
    
    # [ä¿®å¤] å¯åŠ¨å‰æ¸…ç†æ—§æ–‡ä»¶ï¼Œé˜²æ­¢é”æ®‹ç•™
    if os.path.exists(db_path):
        try:
            os.remove(db_path)
        except OSError as e:
            print(f"âš ï¸ Warning: Could not remove old DB file: {e}")
    
    # ä½¿ç”¨ç»å¯¹è·¯å¾„ URL åˆå§‹åŒ–
    # æ³¨æ„ï¼šSQLiteSessionStorage ç±»å¯èƒ½éœ€è¦å¯¼å…¥ï¼Œæˆ–è€…ä½¿ç”¨ factory create_storage
    # å‡è®¾è¿™é‡Œä½¿ç”¨çš„æ˜¯ gecko.plugins.storage.backends.sqlite.SQLiteStorage
    from gecko.plugins.storage.backends.sqlite import SQLiteStorage
    storage = SQLiteStorage(db_url) 
    
    try:
        await storage.initialize()
        
        persistent_session = Session(
            session_id="race_test",
            storage=storage,
            auto_save=False 
        )
    
        # åˆå§‹çŠ¶æ€
        persistent_session.set("counter", 0)
        
        print("   å¯åŠ¨å¹¶å‘ä¿®æ”¹ä»»åŠ¡...")
        
        # æ¨¡æ‹Ÿï¼šä¿å­˜çš„åŒæ—¶ä¿®æ”¹æ•°æ®
        async def save_task():
            print("   [Task 1] å¼€å§‹ä¿å­˜ (Counter=0)...")
            await persistent_session.save()
            print("   [Task 1] ä¿å­˜å®Œæˆ")

        async def modify_task():
            # ç¨å¾®å»¶è¿Ÿï¼Œç¡®ä¿ save å·²ç»è¿›å…¥ IO ç­‰å¾…
            await asyncio.sleep(0.01)
            print("   [Task 2] ä¿®æ”¹æ•°æ® (Counter->999)...")
            persistent_session.set("counter", 999)

        # å¹¶å‘æ‰§è¡Œ
        await asyncio.gather(save_task(), modify_task())
        
        # éªŒè¯å­˜å‚¨ä¸­çš„æ•°æ®
        # æœŸæœ›ï¼šå­˜å‚¨ä¸­æ˜¯ä¿å­˜å¼€å§‹æ—¶çš„å¿«ç…§ (0)ï¼Œè€Œä¸æ˜¯ä¿®æ”¹åçš„ (999)
        # æ³¨æ„ï¼šç”±äºæˆ‘ä»¬æ˜¯å¹¶å‘çš„ï¼Œå¦‚æœ save å¾ˆå¿«å®Œæˆï¼Œå¯èƒ½å­˜çš„æ˜¯ 0ï¼›å¦‚æœ modify å…ˆæ‰§è¡Œï¼Œå­˜çš„æ˜¯ 999ã€‚
        # ä½†ä¼˜åŒ–åçš„ save æ–¹æ³•ä¼šå…ˆåŒæ­¥å¿«ç…§ï¼Œæ‰€ä»¥åªè¦ save å…ˆè¢«è°ƒåº¦ï¼Œå®ƒå°±ä¼šé”å®šå½“å‰çŠ¶æ€ 0ã€‚
        
        loaded_data = await storage.get("race_test")
        print(f"   å­˜å‚¨ä¸­çš„ Counter: {loaded_data['state']['counter']}") # type: ignore
        print(f"   å†…å­˜ä¸­çš„ Counter: {persistent_session.get('counter')}")
    
    finally:
        await storage.shutdown()
        if os.path.exists(db_path):
            try: os.remove(db_path)
            except: pass
    print()
    
    # 8. ä¼šè¯ç®¡ç†å™¨ [ä¿®å¤å¼€å§‹]
    print("8. ä¼šè¯ç®¡ç†å™¨")
    
    # [ä¿®å¤] é‡æ–°åˆ›å»ºä¸€ä¸ª Storage å®ä¾‹ï¼Œæˆ–è€…é‡ç”¨å˜é‡ä½†å¿…é¡»é‡æ–° initialize
    # æ—¢ç„¶æ–‡ä»¶è¢«åˆ äº†ï¼Œå¿…é¡»é‡æ–° init æ¥å»ºè¡¨
    # å»ºè®®ï¼šä¸ºäº†æ¸…æ™°ï¼Œé‡æ–°å®ä¾‹åŒ–
    
    # ä½¿ç”¨å†…å­˜æ•°æ®åº“æ¼”ç¤ºç®¡ç†å™¨åŠŸèƒ½ï¼Œé¿å…æ–‡ä»¶æ®‹ç•™é—®é¢˜
    manager_storage = SQLiteStorage("sqlite:///:memory:")
    await manager_storage.initialize() # å¿…é¡»æ˜¾å¼åˆå§‹åŒ–
    
    manager = SessionManager(
        storage=manager_storage, # ä½¿ç”¨æ–°çš„ storage å®ä¾‹
        default_ttl=3600,
        auto_cleanup=True
    )
    
    # åˆ›å»ºå¤šä¸ªä¼šè¯
    s1 = await manager.create_session(user="Alice", score=100)
    s2 = await manager.create_session(user="Bob", score=200)
    
    print(f"   æ´»è·ƒä¼šè¯æ•°: {manager.get_active_count()}")
    
    # è·å–ä¼šè¯
    retrieved = await manager.get_session(s1.session_id)
    print(f"   æ£€ç´¢åˆ°çš„ç”¨æˆ·: {retrieved.get('user')}\n") # type: ignore
    
    # 9. æ‰¹é‡æ›´æ–°
    print("9. æ‰¹é‡æ›´æ–°")
    # æ³¨æ„ï¼šè¿™é‡Œçš„ session å˜é‡æ˜¯ç¬¬ 1 éƒ¨åˆ†åˆ›å»ºçš„å†…å­˜ Sessionï¼Œ
    # å®ƒæ²¡æœ‰ç»‘å®š storageï¼Œæ‰€ä»¥ update æ˜¯å®‰å…¨çš„å†…å­˜æ“ä½œ
    session.update({
        "last_login": "2024-01-01",
        "login_count": 42,
        "status": "active"
    })
    print(f"   æ›´æ–°åçš„é”®: {session.keys()}\n")
    
    # 10. æ¸…ç†
    print("10. ä¼šè¯æ¸…ç†")
    await manager.shutdown()
    # åŒæ—¶ä¹Ÿå…³é—­åº•å±‚çš„ manager_storage
    await manager_storage.shutdown()
    print("   ç®¡ç†å™¨å·²å…³é—­ï¼Œæ‰€æœ‰ä¼šè¯å·²ä¿å­˜")


if __name__ == "__main__":
    asyncio.run(main())
```

[15] examples/core/structure_demo.py
```python
# examples/structure_demo.py
import asyncio
from pydantic import BaseModel, Field
from gecko.core.structure import StructureEngine, StructureParseError


# å®šä¹‰æ•°æ®æ¨¡å‹
class UserProfile(BaseModel):
    name: str = Field(description="ç”¨æˆ·å")
    age: int = Field(description="å¹´é¾„", ge=0, le=150)
    email: str = Field(description="é‚®ç®±åœ°å€")
    interests: list[str] = Field(default_factory=list, description="å…´è¶£çˆ±å¥½")


class SearchQuery(BaseModel):
    query: str = Field(description="æœç´¢å…³é”®è¯")
    max_results: int = Field(default=5, description="æœ€å¤§ç»“æœæ•°")
    filters: dict = Field(default_factory=dict, description="è¿‡æ»¤æ¡ä»¶")


async def main():
    print("=== Gecko ç»“æ„åŒ–è¾“å‡ºç¤ºä¾‹ ===\n")
    
    # 1. ç”Ÿæˆ OpenAI Tool Schema
    print("1. ç”Ÿæˆ OpenAI Tool Schema")
    schema = StructureEngine.to_openai_tool(SearchQuery)
    print(f"   å·¥å…·å: {schema['function']['name']}")
    print(f"   å‚æ•°: {list(schema['function']['parameters']['properties'].keys())}\n")
    
    # 2. ä» JSON æ–‡æœ¬è§£æ
    print("2. ä»çº¯ JSON æ–‡æœ¬è§£æ")
    json_text = '''
    {
        "name": "Alice",
        "age": 25,
        "email": "alice@example.com",
        "interests": ["AI", "Python", "Music"]
    }
    '''
    
    try:
        user = await StructureEngine.parse(json_text, UserProfile)
        print(f"   è§£ææˆåŠŸ: {user.name}, {user.age} å²")
        print(f"   å…´è¶£: {', '.join(user.interests)}\n")
    except StructureParseError as e:
        print(f"   è§£æå¤±è´¥: {e}\n")
    
    # 3. ä» Markdown ä»£ç å—è§£æ
    print("3. ä» Markdown ä»£ç å—è§£æ")
    markdown_text = '''
    è¿™æ˜¯ç”¨æˆ·ä¿¡æ¯ï¼š
    
    ```json
    {
        "name": "Bob",
        "age": 30,
        "email": "bob@example.com"
    }
    ```
    
    ä»¥ä¸Šæ˜¯æå–çš„æ•°æ®ã€‚
    '''
    
    try:
        user = await StructureEngine.parse(markdown_text, UserProfile)
        print(f"   è§£ææˆåŠŸ: {user.name}\n")
    except StructureParseError as e:
        print(f"   è§£æå¤±è´¥: {e}\n")
    
    # 4. ä»å·¥å…·è°ƒç”¨è§£æ
    print("4. ä»å·¥å…·è°ƒç”¨è§£æ")
    tool_calls = [
        {
            "id": "call_123",
            "function": {
                "name": "search",
                "arguments": '{"query": "Python tutorials", "max_results": 10}'
            }
        }
    ]
    
    try:
        query = await StructureEngine.parse(
            content="",
            model_class=SearchQuery,
            raw_tool_calls=tool_calls
        )
        print(f"   æŸ¥è¯¢: {query.query}")
        print(f"   æœ€å¤§ç»“æœæ•°: {query.max_results}\n")
    except StructureParseError as e:
        print(f"   è§£æå¤±è´¥: {e}\n")
    
    # 5. å¤„ç†æ ¼å¼é—®é¢˜ï¼ˆè‡ªåŠ¨æ¸…ç†ï¼‰
    print("5. å¤„ç†æ ¼å¼é—®é¢˜ï¼ˆè‡ªåŠ¨æ¸…ç†ï¼‰")
    dirty_json = '''
    {
        "name": "Charlie",
        "age": 35,
        "email": "charlie@example.com",  // è¿™æ˜¯æ³¨é‡Š
        "interests": ["reading", "coding",],  // å°¾éƒ¨é€—å·
    }
    '''
    
    try:
        user = await StructureEngine.parse(
            dirty_json,
            UserProfile,
            auto_fix=True
        )
        print(f"   æ¸…ç†åè§£ææˆåŠŸ: {user.name}\n")
    except StructureParseError as e:
        print(f"   è§£æå¤±è´¥: {e.get_detailed_error()}\n")
    
    # 6. éªŒè¯æ•°æ®
    print("6. éªŒè¯æ•°æ®")
    data = {
        "name": "David",
        "age": 28,
        "email": "david@example.com"
    }
    
    try:
        user = StructureEngine.validate(data, UserProfile)
        print(f"   éªŒè¯æˆåŠŸ: {user}\n")
    except Exception as e:
        print(f"   éªŒè¯å¤±è´¥: {e}\n")
    
    # 7. Schema å·®å¼‚æ£€æŸ¥
    print("7. Schema å·®å¼‚æ£€æŸ¥")
    incomplete_data = {
        "name": "Eve",
        # ç¼ºå°‘ age å’Œ email
        "extra_field": "should not be here"
    }
    
    diff = StructureEngine.get_schema_diff(incomplete_data, UserProfile)
    print(f"   ç¼ºå°‘å­—æ®µ: {diff['missing_required']}")
    print(f"   é¢å¤–å­—æ®µ: {diff['extra_fields']}\n")
    
    # 8. è¯¦ç»†é”™è¯¯ä¿¡æ¯
    print("8. è¯¦ç»†é”™è¯¯ä¿¡æ¯")
    invalid_text = "This is not JSON at all, just plain text."
    
    try:
        user = await StructureEngine.parse(invalid_text, UserProfile)
    except StructureParseError as e:
        print("   æ•è·åˆ°è¯¦ç»†é”™è¯¯:")
        print(e.get_detailed_error())


if __name__ == "__main__":
    asyncio.run(main())
```

[16] examples/core/toolbox_demo.py
```python
# examples/toolbox_demo.py
import asyncio
from gecko.core.toolbox import ToolBox
from gecko.plugins.tools.standard.calculator import CalculatorTool
from gecko.plugins.tools.standard.duckduckgo import DuckDuckGoSearch


async def main():
    # 1. åˆ›å»ºå·¥å…·ç®±
    toolbox = ToolBox(
        tools=[CalculatorTool(), DuckDuckGoSearch()],
        max_concurrent=3,
        default_timeout=10.0,
        enable_retry=True,
        max_retries=2,
    )
    
    print(f"å·¥å…·ç®±åˆå§‹åŒ–å®Œæˆ: {toolbox}")
    print(f"å·²æ³¨å†Œå·¥å…·: {[t.name for t in toolbox.list_tools()]}\n")
    
    # 2. å•ä¸ªå·¥å…·æ‰§è¡Œ
    print("=== å•ä¸ªå·¥å…·æ‰§è¡Œ ===")
    try:
        result = await toolbox.execute(
            "calculator",
            {"expression": "(10 + 5) * 2"},
            call_id="calc_001"
        )
        print(f"è®¡ç®—ç»“æœ: {result}\n")
    except Exception as e:
        print(f"æ‰§è¡Œå¤±è´¥: {e}\n")
    
    # 3. æ‰¹é‡å¹¶å‘æ‰§è¡Œ
    print("=== æ‰¹é‡å¹¶å‘æ‰§è¡Œ ===")
    tool_calls = [
        {
            "id": "call_1",
            "name": "calculator",
            "arguments": {"expression": "2 + 2"}
        },
        {
            "id": "call_2",
            "name": "duckduckgo_search",
            "arguments": {"query": "Python asyncio"}
        },
        {
            "id": "call_3",
            "name": "calculator",
            "arguments": {"expression": "100 / 5"}
        },
    ]
    
    results = await toolbox.execute_many(tool_calls)
    
    for r in results:
        status = "âŒ" if r.is_error else "âœ…"
        print(f"{status} {r.tool_name} ({r.call_id})")
        print(f"   ç»“æœ: {r.result[:100]}")
        print(f"   è€—æ—¶: {r.duration:.3f}s\n")
    
    # 4. æŸ¥çœ‹ç»Ÿè®¡
    print("=== æ‰§è¡Œç»Ÿè®¡ ===")
    toolbox.print_stats()
    
    # 5. è·å–æ‘˜è¦
    summary = toolbox.get_summary()
    print("å…¨å±€æ‘˜è¦:")
    print(f"  æ€»æ‰§è¡Œæ¬¡æ•°: {summary['total_executions']}")
    print(f"  æ€»é”™è¯¯æ¬¡æ•°: {summary['total_errors']}")
    print(f"  æ•´ä½“æˆåŠŸç‡: {summary['overall_success_rate']:.1%}")
    print(f"  å¹³å‡è€—æ—¶: {summary['avg_time_per_call']:.3f}s")


if __name__ == "__main__":
    asyncio.run(main())
```

[17] examples/core/utils_demo.py
```python
# examples/utils_demo.py
import asyncio
from gecko.core.utils import (
    ensure_awaitable,
    retry,
    safe_dict,
    merge_dicts,
    truncate,
    format_size,
    format_duration,
    Timer,
    timing,
    chunk_list,
    deduplicate,
)


# ç¤ºä¾‹å‡½æ•°
def sync_function(x):
    return x * 2


async def async_function(x):
    await asyncio.sleep(0.1)
    return x * 3


@retry(max_attempts=3, delay=0.5)
async def unstable_function(fail_count=0):
    """æ¨¡æ‹Ÿä¸ç¨³å®šçš„å‡½æ•°"""
    if fail_count > 0:
        raise ValueError("Intentional failure")
    return "Success"


@timing
async def slow_function():
    """å¸¦è®¡æ—¶çš„å‡½æ•°"""
    await asyncio.sleep(1)
    return "Done"


async def main():
    print("=== Gecko Utils ç¤ºä¾‹ ===\n")
    
    # 1. ensure_awaitable
    print("1. ç»Ÿä¸€å¼‚æ­¥/åŒæ­¥è°ƒç”¨")
    result1 = await ensure_awaitable(sync_function, 5)
    result2 = await ensure_awaitable(async_function, 5)
    print(f"   åŒæ­¥å‡½æ•°ç»“æœ: {result1}")
    print(f"   å¼‚æ­¥å‡½æ•°ç»“æœ: {result2}\n")
    
    # 2. é‡è¯•æœºåˆ¶
    print("2. é‡è¯•æœºåˆ¶")
    try:
        result = await unstable_function(fail_count=0)
        print(f"   æˆåŠŸ: {result}\n")
    except Exception as e:
        print(f"   å¤±è´¥: {e}\n")
    
    # 3. æ•°æ®è½¬æ¢
    print("3. æ•°æ®è½¬æ¢")
    class TestClass:
        def __init__(self):
            self.name = "test"
            self.value = 123
    
    obj = TestClass()
    data = safe_dict(obj)
    print(f"   å¯¹è±¡è½¬å­—å…¸: {data}\n")
    
    # 4. å­—å…¸åˆå¹¶
    print("4. å­—å…¸åˆå¹¶")
    d1 = {"a": 1, "b": {"x": 1}}
    d2 = {"b": {"y": 2}, "c": 3}
    merged = merge_dicts(d1, d2, deep=True)
    print(f"   æ·±åº¦åˆå¹¶: {merged}\n")
    
    # 5. å­—ç¬¦ä¸²å¤„ç†
    print("5. å­—ç¬¦ä¸²å¤„ç†")
    long_text = "A" * 200
    truncated = truncate(long_text, max_length=50)
    print(f"   æˆªæ–­æ–‡æœ¬: {truncated}\n")
    
    print(f"   æ–‡ä»¶å¤§å°: {format_size(1048576)}")
    print(f"   æ—¶é•¿: {format_duration(3665)}\n")
    
    # 6. è®¡æ—¶å™¨
    print("6. è®¡æ—¶å™¨")
    with Timer("æµ‹è¯•æ“ä½œ") as t:
        await asyncio.sleep(0.5)
    print(f"   è€—æ—¶: {t.elapsed:.2f}s\n")
    
    # 7. è®¡æ—¶è£…é¥°å™¨
    print("7. è®¡æ—¶è£…é¥°å™¨")
    result = await slow_function()
    print(f"   ç»“æœ: {result}\n")
    
    # 8. åˆ—è¡¨å·¥å…·
    print("8. åˆ—è¡¨å·¥å…·")
    chunks = chunk_list([1, 2, 3, 4, 5, 6, 7], chunk_size=3)
    print(f"   åˆ†å—: {chunks}")
    
    unique = deduplicate([1, 2, 2, 3, 1, 4, 3])
    print(f"   å»é‡: {unique}\n")


if __name__ == "__main__":
    asyncio.run(main())
```

[18] examples/fast_dev_demo.py
```python
# examples/fast_dev_demo.py
import asyncio
from gecko.core.builder import AgentBuilder
from gecko.core.message import Message
from gecko.plugins.models.zhipu import glm_4_5_air
from gecko.plugins.storage.sqlite import SQLiteSessionStorage # [æ–°å¢] æ˜¾å¼å¼•å…¥å­˜å‚¨åç«¯

async def main():
    # [ä¿®æ”¹] åˆå§‹åŒ–å­˜å‚¨å®ä¾‹ (ä¸å†åªä¼  URL å­—ç¬¦ä¸²)
    storage = SQLiteSessionStorage("sqlite://./dev_sessions.db")

    agent = (AgentBuilder()
             .with_model(glm_4_5_air(temperature=0.3))
             .with_session_id("user_123")              # [æ–°å¢] æŒ‡å®šä¼šè¯ ID
             .with_storage(storage)                    # [ä¿®æ”¹] æ³¨å…¥å­˜å‚¨å®ä¾‹
             # .with_tools([KnowledgeTool(...)])       # [è¯´æ˜] Vector RAG ç°åœ¨å»ºè®®ä½œä¸º Tool æ³¨å…¥
             .build())

    # ç¬¬ä¸€æ¬¡è¿è¡Œï¼šè®°ä½åå­—
    print("--- Round 1 ---")
    output1 = await agent.run([Message(role="user", content="æˆ‘å«å¼ ä¸‰ï¼Œä»¥åå«æˆ‘è€å¼ ")])
    print("AI:", output1.content)

    # ç¬¬äºŒæ¬¡è¿è¡Œï¼šéªŒè¯è®°å¿†æ¢å¤ (TokenMemory ä¼šè‡ªåŠ¨ä» SQLite åŠ è½½å†å²)
    print("\n--- Round 2 ---")
    output2 = await agent.run([Message(role="user", content="æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ")])
    print("AI:", output2.content)

if __name__ == "__main__":
    asyncio.run(main())
```

[19] examples/full_tool_test.py
```python
# examples/full_tool_test.py
import asyncio
from gecko.core.builder import AgentBuilder
from gecko.core.message import Message
from gecko.plugins.models.zhipu import glm_4_5_air

# è‡ªåŠ¨åŠ è½½æ‰€æœ‰å·¥å…·ï¼ˆåªéœ€ importï¼‰
from gecko.plugins.tools.standard.calculator import CalculatorTool  # noqa: F401
from gecko.plugins.tools.standard.duckduckgo import DuckDuckGoSearchTool  # noqa: F401

async def main():
    agent = AgentBuilder()\
        .with_model(glm_4_5_air(temperature=0.3))\
        .build()

    output = await agent.run([
        Message(role="user", content="è¯·åŒæ—¶å®Œæˆä¸¤ä»¶äº‹ï¼š"
                 "1. è®¡ç®— (12345 + 67890) * 2.5"
                 "2. æœç´¢ä»Šå¤©åŒ—äº¬çš„å¤©æ°”é¢„æŠ¥"
                 "æœ€åç”¨ä¸­æ–‡æ€»ç»“")
    ])
    print("\n=== æœ€ç»ˆå›ç­” ===\n")
    print(output.content)

if __name__ == "__main__":
    asyncio.run(main())
```

[20] examples/models/models_demo.py
```python
# examples/models/models_demo.py
import asyncio
import os
import sys
from dotenv import load_dotenv

# ç¡®ä¿ gecko åŒ…å¯å¯¼å…¥
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..")))

from gecko.plugins.models.presets.zhipu import ZhipuChat
from gecko.plugins.models.config import ModelConfig
from gecko.plugins.models.factory import create_model
from gecko.core.message import Message

load_dotenv()

async def demo_mock():
    """æ¼”ç¤ºï¼šMock æ¨¡å¼"""
    print("\n--- Mock Demo ---")
    # [ä¿®å¤] ä½¿ç”¨æ ‡å‡†çš„æ¨¡å‹åç§°ï¼Œä»¥ä¾¿ LiteLLM è¯†åˆ« Provider (å³ä¾¿æ˜¯åœ¨ Mock æ¨¡å¼ä¸‹)
    config = ModelConfig(
        model_name="gpt-3.5-turbo",  # æ”¹ä¸ºæ ‡å‡†åç§°
        api_key="mock",
        extra_kwargs={"mock_response": "This is a mocked response."}
    )
    # ä½¿ç”¨å·¥å‚åˆ›å»º
    model = create_model(config)
    
    resp = await model.acompletion([{"role": "user", "content": "hi"}])
    print(f"AI: {resp.choices[0].message['content']}")

async def demo_zhipu():
    """æ¼”ç¤ºï¼šæ™ºè°±çœŸå®è°ƒç”¨"""
    print("\n--- Zhipu Live Demo ---")
    key = os.getenv("ZHIPU_API_KEY")
    if not key:
        print("Skipping: No ZHIPU_API_KEY found.")
        return

    model = ZhipuChat(api_key=key, model="glm-4-flash")
    
    # 1. æ–‡æœ¬
    msg = Message.user("ç®€è¿°AIæ™ºèƒ½ä½“çš„ä¼˜åŠ¿")
    resp = await model.acompletion([msg.to_openai_format()])
    # æ³¨æ„ï¼šLiteLLM æœ‰æ—¶è¿”å› content ä¸º None (å¦‚æœè¢«è¿‡æ»¤)ï¼Œéœ€é˜²å¾¡
    content = resp.choices[0].message.get("content", "") or ""
    print(f"AI: {content[:50]}...")

    # 2. æµå¼
    print("Streaming: ", end="")
    async for chunk in model.astream([msg.to_openai_format()]):
        if chunk.content:
            print(chunk.content, end="", flush=True)
    print()

async def main():
    await demo_mock()
    await demo_zhipu()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
```

[21] examples/storage/custom_storage_demo.py
```python
# examples/storage/custom_storage_demo.py
import asyncio
import json
import os
from typing import Any, Dict, Optional

# å¯¼å…¥ Gecko çš„åŸºç±»å’Œ Mixin
from gecko.plugins.storage.abc import AbstractStorage
from gecko.plugins.storage.interfaces import SessionInterface
from gecko.plugins.storage.mixins import (
    ThreadOffloadMixin,
    AtomicWriteMixin,
    JSONSerializerMixin
)
from gecko.plugins.storage.registry import register_storage

# ================= è‡ªå®šä¹‰å®ç° =================

@register_storage("myjson")
class SimpleJsonStorage(
    AbstractStorage,
    SessionInterface,
    ThreadOffloadMixin,  # 1. è‡ªåŠ¨å°† IO æ”¾å…¥çº¿ç¨‹æ± 
    AtomicWriteMixin,    # 2. è‡ªåŠ¨æä¾› FileLock å’Œ AsyncLock
    JSONSerializerMixin  # 3. æä¾› _serialize/_deserialize
):
    """
    ä¸€ä¸ªæå…¶ç®€å•ä½†å¥å£®çš„ JSON æ–‡ä»¶å­˜å‚¨
    URL: myjson://./data.json
    """
    
    def __init__(self, url: str, **kwargs):
        super().__init__(url, **kwargs)
        # è§£æè·¯å¾„: myjson://./data.json -> ./data.json
        self.file_path = url.replace("myjson://", "")
        
        # [å…³é”®] é…ç½® FileLockï¼Œè¿™æ ·å³ä½¿å¤šä¸ªè¿›ç¨‹åŒæ—¶æ“ä½œè¿™ä¸ªæ–‡ä»¶ä¹Ÿä¸ä¼šå
        self.setup_multiprocess_lock(self.file_path)

    async def initialize(self) -> None:
        """åˆå§‹åŒ–ï¼šç¡®ä¿æ–‡ä»¶å­˜åœ¨"""
        if not os.path.exists(self.file_path):
            # ä½¿ç”¨ run_sync åœ¨çº¿ç¨‹ä¸­æ‰§è¡Œæ–‡ä»¶å†™å…¥
            await self._run_sync(self._write_file, {})
        self._is_initialized = True
        print(f"[Init] Storage ready at {self.file_path}")

    async def shutdown(self) -> None:
        self._is_initialized = False

    # --- æ ¸å¿ƒé€»è¾‘ (å…¨éƒ¨æ˜¯åŒæ­¥å†™æ³•ï¼Œç”± Mixin å¤„ç†å¼‚æ­¥) ---

    def _read_file(self) -> Dict[str, Any]:
        try:
            with open(self.file_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            return {}

    def _write_file(self, data: Dict[str, Any]):
        with open(self.file_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    # --- æ¥å£å®ç° ---

    async def get(self, session_id: str) -> Optional[Dict[str, Any]]:
        # è¯»æ“ä½œï¼šåªéœ€è¦å¸è½½åˆ°çº¿ç¨‹æ± ï¼Œä¸éœ€è¦åŠ å†™é”
        data = await self._run_sync(self._read_file)
        return data.get(session_id)

    async def set(self, session_id: str, state: Dict[str, Any]) -> None:
        # å†™æ“ä½œé€»è¾‘
        def _do_update():
            data = self._read_file()
            data[session_id] = state
            self._write_file(data)
            return len(data)

        # [å…³é”®] ä½¿ç”¨ write_guard ä¿æŠ¤ä¸´ç•ŒåŒº (åŒ…å« FileLock)
        async with self.write_guard():
            count = await self._run_sync(_do_update)
            print(f"   [Write] Saved session {session_id}. Total sessions: {count}")

    async def delete(self, session_id: str) -> None:
        def _do_delete():
            data = self._read_file()
            if session_id in data:
                del data[session_id]
                self._write_file(data)

        async with self.write_guard():
            await self._run_sync(_do_delete)

# ================= æµ‹è¯•æµç¨‹ =================

async def main():
    db_file = "demo_custom.json"
    url = f"myjson://{db_file}"
    
    # æ¸…ç†ç¯å¢ƒ
    if os.path.exists(db_file): os.remove(db_file)
    if os.path.exists(db_file + ".lock"): os.remove(db_file + ".lock")

    print(f"ğŸš€ Testing Custom Storage: {url}")
    
    # 1. å®ä¾‹åŒ– (æ— éœ€å·¥å‚ï¼Œç›´æ¥ç”¨ç±»æ¼”ç¤ºï¼Œæˆ–é€šè¿‡ create_storage ä¹Ÿå¯ä»¥)
    storage = SimpleJsonStorage(url)
    await storage.initialize()

    try:
        # 2. å¹¶å‘å†™å…¥æµ‹è¯•
        print("\nâš¡ Starting Concurrent Write Test...")
        
        async def worker(idx):
            # æ¨¡æ‹Ÿå¹¶å‘ Agent å†™å…¥
            await storage.set(f"user_{idx}", {"score": idx * 10}) # type: ignore
        
        # å¯åŠ¨ 10 ä¸ªå¹¶å‘ä»»åŠ¡
        # å¦‚æœæ²¡æœ‰ AtomicWriteMixinï¼Œè¿™é‡Œå¤§æ¦‚ç‡ä¼šæŠ¥ JSONDecodeError æˆ–å†…å®¹æŸå
        await asyncio.gather(*[worker(i) for i in range(10)])
        
        # 3. éªŒè¯ç»“æœ
        print("\nğŸ” Verifying Data...")
        all_data = await storage._run_sync(storage._read_file) # type: ignore
        print(f"   Total Records: {len(all_data)}")
        
        assert len(all_data) == 10
        assert all_data["user_9"]["score"] == 90
        print("âœ… Data integrity check passed!")

    finally:
        await storage.shutdown()
        # æ¸…ç†
        if os.path.exists(db_file): os.remove(db_file)
        if os.path.exists(db_file + ".lock"): os.remove(db_file + ".lock")

if __name__ == "__main__":
    asyncio.run(main())
```

[22] examples/storage/redis_storage_demo.py
```python
# examples/storage/redis_storage_demo.py
import asyncio
import os
from gecko.plugins.storage.factory import create_storage
from gecko.core.exceptions import StorageError, ConfigurationError

# éœ€è¦è¿è¡ŒçœŸå®çš„ Redisï¼Œå¦åˆ™æ¼”ç¤ºè¿æ¥å¤±è´¥
# export GECKO_REDIS_URL="redis://localhost:6379/0"
REDIS_URL = os.getenv("GECKO_REDIS_URL", "redis://localhost:6379/0")

async def main():
    print(f"ğŸ”Œ Connecting to {REDIS_URL} with TTL=10s...")
    
    # 1. æ­£å¸¸æµç¨‹
    try:
        # é™„åŠ å‚æ•°æ¼”ç¤º
        url_with_ttl = f"{REDIS_URL}?ttl=10"
        storage = await create_storage(url_with_ttl)
        
        session_id = "demo_user_007"
        
        print("ğŸ’¾ Writing data (with 10s TTL)...")
        await storage.set(session_id, { # type: ignore
            "user": "Bond",
            "mission": "Secret"
        })
        
        data = await storage.get(session_id) # type: ignore
        print(f"ğŸ“– Read success: {data}")
        
        await storage.shutdown()
        
    except ImportError:
        print("âš ï¸  Redis client not installed. Run: pip install redis")
        return
    except (ConnectionError, StorageError) as e:
        print(f"âš ï¸  Redis not available: {e}")
        print("   (Skipping normal test, proceeding to error handling demo)")

    # 2. [æ–°ç‰¹æ€§] é”™è¯¯å¤„ç†æ¼”ç¤º
    print("\nğŸ›¡ï¸  Error Handling Demo (Invalid Host)")
    try:
        # æ•…æ„ä½¿ç”¨ä¸å¯è¾¾çš„åœ°å€
        bad_url = "redis://non-existent-host:6379/0"
        print(f"   Attempting to connect to {bad_url}...")
        
        # å·¥å‚åº”è¯¥æŠ›å‡º StorageError
        bad_storage = await create_storage(bad_url)
        
    except StorageError as e:
        print(f"âœ… Caught expected StorageError: {e}")
        print("   The application handled the connection failure gracefully.")
    except Exception as e:
        print(f"âŒ Caught unexpected exception: {type(e).__name__}: {e}")

if __name__ == "__main__":
    asyncio.run(main())
```

[23] examples/storage/sqlite_storage_demo.py
```python
# examples/storage/sqlite_storage_demo.py
import asyncio
import os
import random
import time
from gecko.plugins.storage.factory import create_storage
from gecko.core.exceptions import StorageError

DB_PATH = "./demo_sqlite.db"
DB_URL = f"sqlite:///{DB_PATH}"

async def main():
    # æ¸…ç†æ—§æ•°æ®
    if os.path.exists(DB_PATH):
        os.remove(DB_PATH)
    if os.path.exists(DB_PATH + ".lock"):
        os.remove(DB_PATH + ".lock")

    print(f"ğŸš€ Initializing SQLite Storage at {DB_URL}")
    
    # 1. åˆ›å»ºå®ä¾‹ (ä¼šè‡ªåŠ¨å¯ç”¨ WAL å’Œ FileLock)
    storage = await create_storage(DB_URL)
    
    try:
        # 2. åŸºç¡€æ“ä½œ
        session_id = "user_123"
        await storage.set(session_id, {"name": "Alice", "balance": 100}) # type: ignore
        print("âœ… Basic CRUD operational.")

        # 3. [æ–°ç‰¹æ€§] å¹¶å‘å‹åŠ›æµ‹è¯• (éªŒè¯é”æœºåˆ¶)
        # æ¨¡æ‹Ÿå¤šä¸ªåç¨‹åŒæ—¶è¯»å–å¹¶æ›´æ–°åŒä¸€ä¸ª Key
        # å¦‚æœæ²¡æœ‰é”ï¼Œå¯èƒ½ä¼šé‡åˆ° "database is locked" æˆ–è€…æ›´æ–°ä¸¢å¤±
        print("\nâš¡ Starting Concurrency Stress Test (10 concurrent updates)...")
        
        concurrency_level = 10
        target_session = "counter_session"
        await storage.set(target_session, {"count": 0}) # type: ignore
        
        async def worker(idx):
            # æ¨¡æ‹Ÿéšæœºå»¶è¿Ÿ
            await asyncio.sleep(random.uniform(0.001, 0.01))
            
            # è¯»-æ”¹-å†™ (æ³¨æ„ï¼šåº”ç”¨å±‚çš„åŸå­æ€§ä»éœ€åˆ†å¸ƒå¼é”ï¼Œä½†è¿™é‡Œæµ‹è¯•çš„æ˜¯ DB å±‚ä¸å´©)
            # æˆ‘ä»¬ä½¿ç”¨ AtomicWriteMixin çš„ write_guard ä¹Ÿå¯ä»¥åœ¨åº”ç”¨å±‚åŠ é”ï¼Œ
            # ä½† storage.set å†…éƒ¨å·²ç»åŠ äº†é”ï¼Œä¿è¯å•æ¬¡ set æ˜¯å®‰å…¨çš„ã€‚
            # ä¸ºäº†æµ‹è¯• storage çš„å¥å£®æ€§ï¼Œæˆ‘ä»¬åªå•çº¯ç–¯ç‹‚å†™å…¥ã€‚
            try:
                # è·å–å½“å‰å€¼ï¼ˆä¸ºäº†æ¨¡æ‹Ÿè´Ÿè½½ï¼‰
                await storage.get(target_session) # type: ignore
                # å†™å…¥æ–°å€¼
                await storage.set(f"worker_{idx}", {"data": "x" * 100}) # type: ignore
                return True
            except StorageError as e:
                print(f"âŒ Worker {idx} failed: {e}")
                return False

        start_time = time.time()
        results = await asyncio.gather(*[worker(i) for i in range(concurrency_level)])
        duration = time.time() - start_time
        
        success_count = sum(results)
        print(f"âœ… Finished in {duration:.3f}s. Success: {success_count}/{concurrency_level}")
        
        if success_count == concurrency_level:
            print("ğŸ‰ Concurrency test PASSED (No locking errors)")
        else:
            print("âš ï¸ Some writes failed (Check logs)")

    finally:
        await storage.shutdown()
        # æ¸…ç†
        if os.path.exists(DB_PATH): os.remove(DB_PATH)
        if os.path.exists(DB_PATH + ".lock"): os.remove(DB_PATH + ".lock")
        # WAL æ–‡ä»¶
        if os.path.exists(DB_PATH + "-wal"): os.remove(DB_PATH + "-wal")
        if os.path.exists(DB_PATH + "-shm"): os.remove(DB_PATH + "-shm")

if __name__ == "__main__":
    asyncio.run(main())
```

[24] examples/storage/vector_storage_demo.py
```python
# examples/storage/vector_storage_demo.py
import asyncio
import os
import shutil
import random
from typing import List

# å¯¼å…¥ Gecko ç»„ä»¶
from gecko.plugins.storage.factory import create_storage
from gecko.core.logging import setup_logging

# å°è¯•å¯¼å…¥ Zhipu (å¯é€‰)
try:
    from gecko.plugins.models import ZhipuChat # Zhipu SDK é€šå¸¸åŒ…å« embedding èƒ½åŠ›
    ZHIPU_AVAILABLE = True
except ImportError:
    ZHIPU_AVAILABLE = False

setup_logging(level="INFO")

async def get_embeddings(texts: List[str], dim: int) -> List[List[float]]:
    """
    è·å–å‘é‡ï¼šä¼˜å…ˆä½¿ç”¨ Zhipu APIï¼Œå¦åˆ™ä½¿ç”¨éšæœºå‘é‡ï¼ˆä»…ç”¨äºæ¼”ç¤ºå­˜å‚¨åŠŸèƒ½ï¼‰
    """
    api_key = os.getenv("ZHIPU_API_KEY")
    if ZHIPU_AVAILABLE and api_key:
        try:
            # æ³¨æ„ï¼šè¿™é‡Œç®€å•æ¨¡æ‹Ÿè°ƒç”¨ Zhipu Embeddingï¼Œå®é™…åº”ä½¿ç”¨ BaseEmbedder æ¥å£
            # ä¸ºäº†æ¼”ç¤º Storage æ¨¡å—ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
            import litellm
            resp = await litellm.aembedding(
                model="zhipu/embedding-2", # å‡è®¾ä½¿ç”¨æ™ºè°± Embedding
                input=texts,
                api_key=api_key
            )
            return [d["embedding"] for d in resp.data]
        except Exception as e:
            print(f"âš ï¸ Zhipu Embedding failed: {e}, falling back to random.")
    
    # Fallback: Random vectors
    return [[random.random() for _ in range(dim)] for _ in texts]

async def run_vector_demo(url: str, name: str):
    print(f"\n{'='*20} Running {name} Demo {'='*20}")
    
    # 1. åˆå§‹åŒ–å­˜å‚¨
    # å·¥å‚æ¨¡å¼ä¼šè‡ªåŠ¨è¯†åˆ« scheme (chroma/lancedb)
    try:
        store = await create_storage(url)
    except ImportError as e:
        print(f"âŒ Skipping {name}: {e}")
        return

    try:
        # 2. å‡†å¤‡æ•°æ®
        # åŒ…å«ä¸åŒç±»åˆ«çš„æ–‡æ¡£ï¼Œä»¥åŠä¸€ä¸ªæ—  metadata çš„æ–‡æ¡£
        docs_data = [
            {"id": "doc_1", "text": "The apple is a fruit.", "metadata": {"category": "fruit", "year": 2023}},
            {"id": "doc_2", "text": "Bananas are yellow.", "metadata": {"category": "fruit", "year": 2024}},
            {"id": "doc_3", "text": "Python is a programming language.", "metadata": {"category": "tech"}},
            {"id": "doc_4", "text": "Gecko is an AI framework.", "metadata": None}, # æµ‹è¯• None Metadata å¥å£®æ€§
        ]
        
        # ç”Ÿæˆå‘é‡ (å‡è®¾ç»´åº¦ 1024)
        dim = 1024
        texts = [d["text"] for d in docs_data]
        embeddings = await get_embeddings(texts, dim)
        
        for i, doc in enumerate(docs_data):
            doc["embedding"] = embeddings[i]

        # 3. å†™å…¥æ•°æ® (Upsert)
        print(f"ğŸ’¾ Upserting {len(docs_data)} documents...")
        await store.upsert(docs_data) # type: ignore
        print("   Done.")

        # 4. åŸºç¡€æœç´¢ (æ— è¿‡æ»¤)
        query_text = "Tell me about fruits"
        query_vec = (await get_embeddings([query_text], dim))[0]
        
        print(f"\nğŸ” Basic Search: '{query_text}'")
        results = await store.search(query_vec, top_k=2) # type: ignore
        for res in results:
            print(f"   - [{res['score']:.4f}] {res['text']} (Meta: {res['metadata']})")

        # 5. [æ–°ç‰¹æ€§] å¸¦è¿‡æ»¤æœç´¢ (Metadata Filtering)
        print(f"\nğŸ” Filtered Search (category='fruit')")
        # å³ä½¿ "Python" å¯èƒ½åœ¨å‘é‡ç©ºé—´ä¸Šå¶é‡ï¼ˆéšæœºæ¨¡å¼ä¸‹ï¼‰ï¼Œä¹Ÿä¼šè¢«è¿‡æ»¤æ‰
        results_filtered = await store.search( # type: ignore
            query_vec, 
            top_k=5, 
            filters={"category": "fruit"}
        )
        for res in results_filtered:
            print(f"   - [{res['score']:.4f}] {res['text']} (Meta: {res['metadata']})")
            
        # éªŒè¯è¿‡æ»¤æ­£ç¡®æ€§
        assert all(r['metadata'].get('category') == 'fruit' for r in results_filtered)
        print("   âœ… Filtering verified.")

    except Exception as e:
        print(f"âŒ Error: {e}")
    finally:
        await store.shutdown()
        # æ¸…ç†æ–‡ä»¶
        path = url.split("://")[1].split("?")[0]
        if os.path.exists(path):
            try:
                shutil.rmtree(path)
            except:
                pass

async def main():
    # æµ‹è¯• Chroma
    await run_vector_demo("chroma://./demo_chroma_db", "ChromaDB")
    
    # æµ‹è¯• LanceDB (æŒ‡å®šç»´åº¦)
    await run_vector_demo("lancedb://./demo_lance_db?dim=1024", "LanceDB")

if __name__ == "__main__":
    asyncio.run(main())
```

[25] examples/team_of_agents.py
```python
```

[26] examples/tools/advanced_stateful_demo.py
```python
# examples/tools/advanced_stateful_demo.py
"""
é«˜çº§å·¥å…·ä½¿ç”¨ç¤ºä¾‹ï¼šæœ‰çŠ¶æ€å·¥å…·ä¸å¤æ‚å‚æ•°

æœ¬ç¤ºä¾‹å±•ç¤ºï¼š
1. Stateful Tools: å¦‚ä½•åœ¨å·¥å…·ä¸­ç»´æŠ¤çŠ¶æ€ï¼ˆæ¨¡æ‹Ÿæ•°æ®åº“ï¼‰ã€‚
2. Complex Schema: å¦‚ä½•ä½¿ç”¨åµŒå¥—çš„ Pydantic æ¨¡å‹ä½œä¸ºå·¥å…·å‚æ•°ã€‚
3. Dependency Injection: å¦‚ä½•åœ¨å·¥å…·åˆå§‹åŒ–æ—¶æ³¨å…¥å¤–éƒ¨ä¾èµ–ã€‚
"""
import asyncio
import os
import json
from typing import Dict, List, Optional, Type

from pydantic import BaseModel, Field

from gecko.core.agent import Agent
from gecko.core.builder import AgentBuilder
# [é‡è¦] é€‚é…æ–°ç‰ˆæ¨¡å‹æ¶æ„
from gecko.plugins.models import ZhipuChat
from gecko.plugins.tools.base import BaseTool, ToolResult

# ==========================================
# 1. æ¨¡æ‹Ÿå¤–éƒ¨ä¾èµ– (Mock Database)
# ==========================================

class OrderDatabase:
    """ä¸€ä¸ªç®€å•çš„å†…å­˜æ•°æ®åº“ï¼Œç”¨äºå­˜å‚¨è®¢å•"""
    def __init__(self):
        self._orders: Dict[str, Dict] = {}
        self._lock = asyncio.Lock()

    async def add_order(self, order_id: str, items: List[Dict], total: float):
        async with self._lock:
            self._orders[order_id] = {
                "items": items,
                "total": total,
                "status": "pending"
            }
            print(f"\n[Database] ğŸ’¾ Order {order_id} saved. Items: {len(items)}")

    async def get_order(self, order_id: str) -> Optional[Dict]:
        return self._orders.get(order_id)

# ==========================================
# 2. å®šä¹‰å¤æ‚å‚æ•°ç»“æ„ (Complex Schema)
# ==========================================

class OrderItem(BaseModel):
    product_name: str = Field(..., description="å•†å“åç§°")
    quantity: int = Field(..., description="æ•°é‡", ge=1)
    price: float = Field(..., description="å•ä»·")

class PlaceOrderArgs(BaseModel):
    user_id: str = Field(..., description="ç”¨æˆ·ID")
    items: List[OrderItem] = Field(..., description="è®¢å•é¡¹åˆ—è¡¨")
    notes: Optional[str] = Field(None, description="å¤‡æ³¨ä¿¡æ¯")

class QueryOrderArgs(BaseModel):
    order_id: str = Field(..., description="è®¢å•ID")

# ==========================================
# 3. å®šä¹‰æœ‰çŠ¶æ€å·¥å…· (Stateful Tools)
# ==========================================

class PlaceOrderTool(BaseTool):
    name: str = "place_order"
    description: str = "ä¸‹è®¢å•å·¥å…·ã€‚æ”¯æŒä¸€æ¬¡æ€§è´­ä¹°å¤šä¸ªå•†å“ã€‚"
    args_schema: Type[BaseModel] = PlaceOrderArgs

    def __init__(self, db: OrderDatabase):
        # å¿…é¡»æ˜¾å¼è°ƒç”¨ super().__init__ ä»¥åˆå§‹åŒ– Pydantic æ¨¡å‹
        super().__init__() # type: ignore
        # å°†æ•°æ®åº“ä¾èµ–æ³¨å…¥ä¸ºç§æœ‰å±æ€§ï¼ˆä¸å‚ä¸ Schema ç”Ÿæˆï¼‰
        object.__setattr__(self, "_db", db)

    async def _run(self, args: PlaceOrderArgs) -> ToolResult: # type: ignore
        # è®¡ç®—æ€»ä»·
        total = sum(item.quantity * item.price for item in args.items)
        
        # ç”Ÿæˆè®¢å•ID (æ¨¡æ‹Ÿ)
        import uuid
        order_id = f"ORD-{uuid.uuid4().hex[:6].upper()}"
        
        # å†™å…¥æ•°æ®åº“
        items_dict = [item.model_dump() for item in args.items]
        await self._db.add_order(order_id, items_dict, total) # type: ignore
        
        return ToolResult(
            content=json.dumps({
                "status": "success",
                "order_id": order_id,
                "total_price": total,
                "message": "è®¢å•åˆ›å»ºæˆåŠŸ"
            }, ensure_ascii=False)
        )

class QueryOrderTool(BaseTool):
    name: str = "query_order"
    description: str = "æŸ¥è¯¢è®¢å•çŠ¶æ€å’Œè¯¦æƒ…ã€‚"
    args_schema: Type[BaseModel] = QueryOrderArgs

    def __init__(self, db: OrderDatabase):
        super().__init__() # type: ignore
        object.__setattr__(self, "_db", db)

    async def _run(self, args: QueryOrderArgs) -> ToolResult: # type: ignore
        order = await self._db.get_order(args.order_id) # type: ignore
        
        if not order:
            return ToolResult(content="æœªæ‰¾åˆ°è¯¥è®¢å•", is_error=True)
            
        return ToolResult(content=json.dumps(order, ensure_ascii=False))

# ==========================================
# 4. ä¸»æµç¨‹
# ==========================================

async def main():
    print("ğŸš€ Advanced Tool Demo: Stateful & Complex Schema\n")

    # 0. å‡†å¤‡ API Key
    api_key = os.environ.get("ZHIPU_API_KEY")
    if not api_key:
        print("è¯·è®¾ç½® ZHIPU_API_KEY ç¯å¢ƒå˜é‡")
        return

    # 1. åˆå§‹åŒ–å…±äº«èµ„æº (Dependency)
    db = OrderDatabase()

    # 2. å®ä¾‹åŒ–å·¥å…·å¹¶æ³¨å…¥ä¾èµ–
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ‰‹åŠ¨å®ä¾‹åŒ–å·¥å…·ï¼Œè€Œä¸æ˜¯é€šè¿‡å­—ç¬¦ä¸²åç§°åŠ è½½ï¼Œ
    # å› ä¸ºæˆ‘ä»¬éœ€è¦ä¼ é€’ `db` å¯¹è±¡ã€‚
    tools = [
        PlaceOrderTool(db=db),
        QueryOrderTool(db=db)
    ]

    # 3. æ„å»º Agent
    model = ZhipuChat(api_key=api_key, model="glm-4-air", temperature=0.1)
    
    agent = (
        AgentBuilder()
        .with_model(model)
        .with_tools(tools) # ç›´æ¥ä¼ é€’å®ä¾‹åŒ–å¥½çš„å·¥å…·åˆ—è¡¨
        .with_system_prompt("ä½ æ˜¯ä¸€ä¸ªè®¢å•åŠ©æ‰‹ã€‚è¯·å¸®åŠ©ç”¨æˆ·ä¸‹å•æˆ–æŸ¥è¯¢ã€‚")
        .build()
    )

    # 4. åœºæ™¯æ¼”ç¤º
    
    # åœºæ™¯ A: å¤æ‚ä¸‹å• (LLM éœ€è¦ç”ŸæˆåµŒå¥— JSON)
    prompt1 = "æˆ‘è¦ä¹°ä¸¤å° MacBook Pro (å•ä»·15000) å’Œ ä¸€ä¸ªé¼ æ ‡ (å•ä»·500)ï¼Œç”¨æˆ·IDæ˜¯ user_888"
    print(f"ğŸ‘¤ User: {prompt1}")
    
    response1 = await agent.run(prompt1)
    print(f"ğŸ¤– Agent: {response1.content}\n") # type: ignore
    
    # åœºæ™¯ B: åŸºäºä¸Šä¸‹æ–‡æŸ¥è¯¢çŠ¶æ€
    # LLM éœ€è¦ä»ä¸Šä¸€æ­¥çš„å›å¤ä¸­æå– order_id
    prompt2 = "è¯·å¸®æˆ‘æŸ¥ä¸€ä¸‹åˆšåˆšé‚£ä¸ªè®¢å•çš„è¯¦æƒ…"
    print(f"ğŸ‘¤ User: {prompt2}")
    
    response2 = await agent.run(prompt2)
    print(f"ğŸ¤– Agent: {response2.content}\n") # type: ignore

if __name__ == "__main__":
    asyncio.run(main())
```

[27] examples/tools/tools_demo.py
```python
# examples/tools/tools_demo.py
"""
Gecko Tool Demo (é€‚é…æ–°ç‰ˆ Models æ¶æ„)

å±•ç¤ºå¦‚ä½•ç»“åˆ ZhipuChat æ¨¡å‹ä¸ ToolBox æ„å»ºå…·å¤‡å·¥å…·è°ƒç”¨èƒ½åŠ›çš„ Agentã€‚
"""
import asyncio
import os
import sys
from typing import Type

from pydantic import BaseModel, Field

# ç¡®ä¿å½“å‰ç›®å½•åœ¨ sys.path ä¸­
sys.path.append(os.path.join(os.path.dirname(__file__), "../../"))

from gecko.core.builder import AgentBuilder
from gecko.core.logging import setup_logging

# [ä¿®æ”¹ 1] ä»ç»Ÿä¸€çš„ models æ’ä»¶å…¥å£å¯¼å…¥ ZhipuChat
from gecko.plugins.models import ZhipuChat
from gecko.plugins.tools.base import BaseTool, ToolResult
# [ä¿®æ”¹] å¯¼å…¥ load_tool ç”¨äºå®ä¾‹åŒ–å·¥å…·
from gecko.plugins.tools.registry import register_tool, load_tool

# å¯¼å…¥æ ‡å‡†å·¥å…·åº“ä»¥è§¦å‘è‡ªåŠ¨æ³¨å†Œ
import gecko.plugins.tools.standard

setup_logging(level="INFO")


# ==========================================
# è‡ªå®šä¹‰å·¥å…·å®šä¹‰ (ä¿æŒä¸å˜)
# ==========================================

class WeatherArgs(BaseModel):
    city: str = Field(..., description="åŸå¸‚åç§°ï¼Œä¾‹å¦‚: 'Beijing', 'Shanghai'")

@register_tool("weather_query")
class WeatherTool(BaseTool):
    name: str = "weather_query"
    description: str = "æŸ¥è¯¢ç‰¹å®šåŸå¸‚çš„å½“å‰å¤©æ°”çŠ¶å†µã€‚"
    args_schema: Type[BaseModel] = WeatherArgs

    async def _run(self, args: WeatherArgs) -> ToolResult: # type: ignore
        print(f"\n[Mock API] Querying weather for {args.city}...")
        mock_data = {
            "Beijing": "Sunny, 25Â°C, Wind: NW 3km/h",
            "Shanghai": "Rainy, 22Â°C, Wind: SE 5km/h",
            "New York": "Cloudy, 18Â°C, Wind: NE 10km/h"
        }
        result = mock_data.get(args.city, "Unknown location")
        return ToolResult(content=result)


# ==========================================
# ä¸»ç¨‹åº
# ==========================================

async def main():
    print("ğŸš€ åˆå§‹åŒ– Gecko Agent...")

    # 1. è·å– API Key
    api_key = os.environ.get("ZHIPU_API_KEY")
    
    if not api_key:
        print("âŒ æœªæ£€æµ‹åˆ° ZHIPU_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·è¿è¡Œ: export ZHIPU_API_KEY='your_key_here'")
        # ä¸ºäº†æ¼”ç¤ºç»§ç»­è¿è¡Œï¼Œè¿™é‡Œå¯ä»¥æŠ›å‡ºå¼‚å¸¸æˆ–è€…ç¡¬ç¼–ç æµ‹è¯•Key(ä¸æ¨è)
        return

    print(f"âœ… æ£€æµ‹åˆ° API Key: {api_key[:6]}******")

    # 2. åˆå§‹åŒ–æ¨¡å‹ [ä¿®æ”¹ 2]
    # ä½¿ç”¨æ–°çš„ ZhipuChat ç±»ï¼Œæ˜¾å¼ä¼ å…¥ api_key å’Œ model
    try:
        llm = ZhipuChat(
            api_key=api_key,
            model="glm-4-air",
            temperature=0.1
        )
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # 3. æ„å»º Agent
    try:
        # [ä¿®æ”¹] æ˜¾å¼åŠ è½½å·¥å…·å®ä¾‹ï¼Œæ»¡è¶³ AgentBuilder çš„ä¸¥æ ¼ç±»å‹æ£€æŸ¥
        tools_list = [
            load_tool("calculator"),        # ä»æ³¨å†Œè¡¨åŠ è½½æ ‡å‡†å·¥å…·
            load_tool("duckduckgo_search"), # ä»æ³¨å†Œè¡¨åŠ è½½æ ‡å‡†å·¥å…·
            load_tool("weather_query")      # åŠ è½½åˆšåˆšæ³¨å†Œçš„è‡ªå®šä¹‰å·¥å…·
        ]

        agent = (
            AgentBuilder()
            .with_model(llm)
            .with_tools(tools_list)  # ç°åœ¨ä¼ å…¥çš„æ˜¯ BaseTool å®ä¾‹åˆ—è¡¨
            .with_max_tokens(4000)
            .build()
        )
    except Exception as e:
        print(f"âŒ Agent æ„å»ºå¤±è´¥: {e}")
        return

    print(f"ğŸ“¦ å·²åŠ è½½å·¥å…·: {[t.name for t in agent.toolbox.list_tools()]}")
    
    # ==========================================
    # æ‰§è¡Œæµ‹è¯•
    # ==========================================
    
    # åœºæ™¯ A: æ•°å­¦è®¡ç®—
    query_math = "è®¡ç®— (123 * 45) + sqrt(1024) çš„ç»“æœæ˜¯å¤šå°‘ï¼Ÿ"
    print(f"\nUser: {query_math}")
    try:
        response = await agent.run(query_math)
        print(f"Agent: {response.content}") # type: ignore
    except Exception as e:
        print(f"Execution failed: {e}")

    # åœºæ™¯ B: è”ç½‘æœç´¢ (å¯é€‰)
    try:
        import duckduckgo_search
        query_search = "2024å¹´å·´é»å¥¥è¿ä¼šé‡‘ç‰Œæ¦œç¬¬ä¸€åæ˜¯å“ªä¸ªå›½å®¶ï¼Ÿ"
        print(f"\nUser: {query_search}")
        response = await agent.run(query_search)
        print(f"Agent: {response.content}") # type: ignore
    except ImportError:
        print("\nâš ï¸ è·³è¿‡æœç´¢æµ‹è¯•ï¼šæœªå®‰è£… duckduckgo-search")
    except Exception as e:
        print(f"\nâš ï¸ æœç´¢æµ‹è¯•å‡ºé”™ (ç½‘ç»œé—®é¢˜?): {e}")

    # åœºæ™¯ C: è‡ªå®šä¹‰å·¥å…·
    query_weather = "åŒ—äº¬å’Œä¸Šæµ·ç°åœ¨çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
    print(f"\nUser: {query_weather}")
    await agent.run(query_weather)

if __name__ == "__main__":
    asyncio.run(main())
```

[28] examples/zhipu_agent.py
```python
import asyncio
from gecko.core.builder import AgentBuilder
from gecko.core.message import Message
from gecko.plugins.models.zhipu import glm_4_5_air  # ä¸€è¡Œå¯¼å…¥

async def main():
    agent = AgentBuilder()\
        .with_model(glm_4_5_air(temperature=0.8)).build()

    output = await agent.run([
        Message(role="user", content="ç”¨ä¸­æ–‡ä»‹ç»ä¸€ä¸‹ Gecko æ¡†æ¶çš„æ’ä»¶åŒ–è®¾è®¡ä¼˜åŠ¿")
    ])
    print(output)

if __name__ == "__main__":
    asyncio.run(main())
```

