# gecko/plugins/knowledge/pipeline.py
from typing import List, Optional
from gecko.plugins.knowledge.interfaces import EmbedderProtocol
from gecko.plugins.storage.interfaces import VectorInterface
from gecko.plugins.knowledge.splitters import RecursiveCharacterTextSplitter
from gecko.plugins.knowledge.readers import AutoReader
from gecko.core.utils import ensure_awaitable

class IngestionPipeline:
    """
    RAG æ•°æ®å…¥åº“æµæ°´çº¿
    Load -> Split -> Embed -> Store
    """
    def __init__(
        self,
        vector_store: VectorInterface,
        embedder: EmbedderProtocol,
        splitter = None
    ):
        self.vector_store = vector_store
        self.embedder = embedder
        self.splitter = splitter or RecursiveCharacterTextSplitter()

    async def run(self, file_paths: List[str], batch_size: int = 100):
        """
        æ‰§è¡Œå…¥åº“æµç¨‹
        :param file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        :param batch_size: å‘é‡åº“å†™å…¥æ‰¹æ¬¡å¤§å°
        """
        print(f"ğŸš€ å¼€å§‹å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶...")
        
        # 1. Load
        raw_docs = []
        for path in file_paths:
            try:
                docs = AutoReader.read(path)
                raw_docs.extend(docs)
            except Exception as e:
                print(f"âš ï¸ è¯»å–å¤±è´¥ {path}: {e}")

        # 2. Split
        chunks = self.splitter.split_documents(raw_docs)
        print(f"âœ‚ï¸ åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªç‰‡æ®µ")

        # 3. Embed & Store (Batch Processing)
        for i in range(0, len(chunks), batch_size):
            batch = chunks[i : i + batch_size]
            texts = [doc.text for doc in batch]
            
            # ç”Ÿæˆå‘é‡
            embeddings = await ensure_awaitable(self.embedder.embed_documents, texts)
            
            # æ³¨å…¥å‘é‡åˆ°æ–‡æ¡£å¯¹è±¡
            docs_to_upsert = []
            for doc, emb in zip(batch, embeddings):
                doc.embedding = emb
                docs_to_upsert.append(doc.to_dict())
            
            # å†™å…¥æ•°æ®åº“
            await self.vector_store.upsert(docs_to_upsert)
            print(f"ğŸ’¾ å·²å­˜å‚¨æ‰¹æ¬¡ {i} - {i+len(batch)}")
            
        print("âœ… å…¥åº“å®Œæˆ")