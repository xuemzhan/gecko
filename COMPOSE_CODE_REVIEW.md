# Gecko Compose æ¨¡å—æ·±åº¦ä»£ç å®¡æŸ¥

**å®¡æŸ¥æ—¥æœŸ**: 2025-12-04  
**ç‰ˆæœ¬**: v0.4  
**æ¨¡å—èŒƒå›´**: `gecko/compose/` (nodes.py, team.py, workflow/*)

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

| ç»´åº¦ | çŠ¶æ€ | è¯´æ˜ |
|-----|------|------|
| **åŠŸèƒ½å®Œæ•´æ€§** | âœ… è‰¯å¥½ | æ ¸å¿ƒå·¥ä½œæµã€å¹¶è¡Œæ‰§è¡Œã€åŠ¨æ€è·³è½¬ç­‰åŠŸèƒ½å®Œæ•´ |
| **ä»£ç è´¨é‡** | âš ï¸ ä¸­ç­‰ | å­˜åœ¨å¤šä¸ªé€»è¾‘æ¼æ´å’Œè¾¹ç•Œæƒ…å†µå¤„ç†ä¸è¶³ |
| **ç”Ÿäº§å°±ç»ªåº¦** | âŒ æœªå°±ç»ª | æœ‰ä¸¥é‡ bug éœ€ä¿®å¤ï¼Œå¹¶å‘å®‰å…¨æ€§éœ€éªŒè¯ |
| **ä¼˜åŒ–ç©ºé—´** | ğŸ“Š è¾ƒå¤§ | å†…å­˜ç®¡ç†ã€æ€§èƒ½ã€å¯è§‚æµ‹æ€§å‡æœ‰æ”¹è¿›ç©ºé—´ |

---

## ğŸ› å‘ç°çš„é—®é¢˜

### ä¼˜å…ˆçº§ P0 (ä¸¥é‡ Bug)

#### P0-1: Race æ¨¡å¼ä¸‹çš„"å¹½çµèµ¢å®¶"é—®é¢˜

**æ–‡ä»¶**: `gecko/compose/team.py:175-190`  
**ä»£ç **:
```python
async def _racer(idx: int, mem: Any, inp: Any):
    res = await self._safe_execute_member(idx, mem, inp)
    
    if res.is_success:
        if not winner: # åŒé‡æ£€æŸ¥é¿å…è¦†ç›–
            winner.append(res)
            tg.cancel_scope.cancel()
```

**é—®é¢˜**:
1. **ç«æ€æ¡ä»¶**: `if not winner` æ˜¯éåŸå­æ“ä½œï¼Œä¸¤ä¸ªå¿«é€Ÿå®Œæˆçš„åç¨‹å¯èƒ½åŒæ—¶é€šè¿‡æ£€æŸ¥
   - çº¿ç¨‹A: æ£€æŸ¥ `winner` ä¸ºç©º â†’ True
   - çº¿ç¨‹B: æ£€æŸ¥ `winner` ä¸ºç©º â†’ Trueï¼ˆæ­¤æ—¶Aè¿˜æœª appendï¼‰
   - ä¸¤ä¸ªåç¨‹éƒ½ä¼š append å’Œ cancel
   
2. **åç¨‹æ³„æ¼**: `cancel_scope.cancel()` ä¼šç«‹å³å–æ¶ˆæ‰€æœ‰ä»»åŠ¡ï¼Œä½†ä¸ä¿è¯ cleanup æ­£ç¡®æ‰§è¡Œ
   - æŸäº›åç¨‹å¯èƒ½åœ¨ä¸´ç•ŒåŒºè¢«ä¸­æ–­
   - èµ„æº (DBè¿æ¥ã€ä¸´æ—¶æ–‡ä»¶) æœªæ­£ç¡®é‡Šæ”¾

**å½±å“**: å¤šä¸ª"èµ¢å®¶"è¢«è®°å½•ï¼Œç ´å Race è¯­ä¹‰ï¼›èµ„æºæ³„æ¼

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨ anyio.Lock ä¿æŠ¤ä¸´ç•ŒåŒº
async with self._winner_lock:
    if not winner:
        winner.append(res)
        tg.cancel_scope.cancel()
```

---

#### P0-2: Race æ¨¡å¼å®Œå…¨å¤±è´¥æ—¶çš„è¡Œä¸ºå¼‚å¸¸

**æ–‡ä»¶**: `gecko/compose/team.py:195-200`

**ä»£ç **:
```python
except anyio.get_cancelled_exc_class():
    pass  # æ•è·å–æ¶ˆå¼‚å¸¸æ˜¯é¢„æœŸè¡Œä¸º

if winner:
    logger.info(f"Team {self.name} Race won by member {winner[0].member_index}")
    return winner

# å¦‚æœæ‰€æœ‰äººéƒ½å¤±è´¥äº†ï¼Œæˆ–è€…æ²¡æœ‰ä»»ä½•äººæˆåŠŸï¼Œè¿”å›ç©ºåˆ—è¡¨è¡¨ç¤ºæ—  winner
logger.warning(f"Team {self.name} Race failed: no winner")
return []  # <-- é—®é¢˜ï¼šè¿”å›ç©ºåˆ—è¡¨ï¼Œæ— æ³•åŒºåˆ†"æ— äººæˆåŠŸ"å’Œ"æ— äººæ‰§è¡Œ"
```

**é—®é¢˜**:
- è¿”å› `[]` æ˜¯æ­§ä¹‰çš„ï¼šè°ƒç”¨è€…æ— æ³•åˆ¤æ–­æ˜¯"æ‰€æœ‰äººå¤±è´¥"è¿˜æ˜¯"æ‰€æœ‰äººéƒ½è¢«è·³è¿‡"
- ä¸Šæ¸¸ä»£ç å‡è®¾ Race å¿…å®šè¿”å›è‡³å°‘ä¸€ä¸ª resultï¼Œé•¿åº¦ä¸º 0 æ—¶ä¼šå‡ºç°ç´¢å¼•é”™è¯¯

**ä¿®å¤æ–¹æ¡ˆ**:
```python
if not winner:
    # æ”¶é›†æ‰€æœ‰å¤±è´¥çš„æˆå‘˜ä¿¡æ¯
    failed_results = []
    for i, member in enumerate(self.members):
        failed_results.append(
            MemberResult(member_index=i, error="Race failed - no winner", is_success=False)
        )
    logger.error(f"Team {self.name} Race failed: all members failed")
    return failed_results
```

---

#### P0-3: Next æŒ‡ä»¤çš„çŠ¶æ€æ±¡æŸ“

**æ–‡ä»¶**: `gecko/compose/workflow/engine.py:430-445`

**ä»£ç **:
```python
def _merge_layer_results(self, context: WorkflowContext, results: Dict[str, Any]):
    for node_name, res in results.items():
        output = res["output"]
        
        # [Fix] å¤„ç† Next å¯¹è±¡
        actual_data = output
        if isinstance(output, Next):
            actual_data = output.input
        
        # æ›´æ–° History
        context.history[node_name] = actual_data  # <-- é—®é¢˜ï¼šNext.input å¯èƒ½ä¸º None
        layer_outputs[node_name] = actual_data
```

**é—®é¢˜**:
1. å½“ `Next.input` ä¸º `None` æ—¶ï¼Œåº”è¯¥**ä¿ç•™åŸæœ‰ input**ï¼Œè€Œä¸æ˜¯ç”¨ None è¦†ç›–
2. History ä¸­å­˜å‚¨äº†å¤§é‡ä¸­é—´æ•°æ®ï¼Œé•¿æœŸè¿è¡Œä¼šå¯¼è‡´å†…å­˜çˆ†ç‚¸ï¼ˆç¼ºä¹ä¸»åŠ¨æ¸…ç†ï¼‰

**å½“å‰è¡Œä¸º**:
```python
# Node A returns: Next(node="D", input="new_data")
# History è¢«æ±¡æŸ“ä¸º: {"A": "new_data"}

# Node B returns: Next(node="E", input=None)
# History["B"] = None  # ä¸¢å¤±äº†åŸæœ‰æ•°æ®
```

**å½±å“**: åŠ¨æ€è·³è½¬çš„çŠ¶æ€æœºåˆ¶å¤±æ•ˆï¼›é•¿æœŸè¿è¡Œå†…å­˜æ³„æ¼

**ä¿®å¤æ–¹æ¡ˆ**:
```python
if isinstance(output, Next):
    # ä»…å½“ input è¢«æ˜¾å¼æä¾›æ—¶ï¼Œæ‰è¦†ç›–
    if output.input is not None:
        actual_data = output.input
    else:
        actual_data = context.get_last_output()  # ä¿ç•™ä¸Šä¸€æ­¥è¾“å‡º
else:
    actual_data = output

context.history[node_name] = actual_data
```

---

#### P0-4: æ¡ä»¶åˆ†æ”¯çš„"å¹½çµè·¯å¾„"

**æ–‡ä»¶**: `gecko/compose/workflow/engine.py:366-390`

**ä»£ç **:
```python
if incoming_edges:
    should_run = False
    for src, cond in incoming_edges:
        # åªæœ‰å½“ä¸Šæ¸¸å·²æ‰§è¡Œ (åœ¨ history ä¸­) æˆ–è€…æ˜¯ Start èŠ‚ç‚¹æ—¶ï¼Œæ¡ä»¶æ‰æœ‰æ„ä¹‰
        if src == self.graph.entry_point or src in ctx.history:
            if cond is None:
                should_run = True
                break
            try:
                res = cond(ctx)
                if inspect.isawaitable(res):
                    res = await res
                if res:
                    should_run = True
                    break
            except Exception as e:
                logger.error(f"Condition check failed for {src}->{name}: {e}")
    
    if not should_run:
        logger.info(f"Node {name} skipped due to conditions")
        return  # <-- é—®é¢˜ï¼šæ— åé¦ˆï¼Œè°ƒç”¨æ–¹æ— æ³•æ„ŸçŸ¥
```

**é—®é¢˜**:
1. èŠ‚ç‚¹è¢«è·³è¿‡æ—¶ï¼Œè¿”å› `None` è€Œä¸è¿”å› `MemberResult`
2. è°ƒç”¨æ–¹ `_run_node_wrapper` æœŸæœ›åœ¨ `results` å­—å…¸ä¸­çœ‹åˆ°æ‰€æœ‰èŠ‚ç‚¹çš„ç»“æœ
3. è·³è¿‡çš„èŠ‚ç‚¹ç¼ºå¤±ï¼Œå¯¼è‡´åç»­ merge æ—¶ä¸¢å¤±è¯¥èŠ‚ç‚¹çš„ä¿¡æ¯

**ç—‡çŠ¶**:
```python
# Layer = {A, B, C}  æ¡ä»¶ï¼šB è¢«è·³è¿‡
# results = {"A": ..., "C": ...}  <- B ç¼ºå¤±
# merge å history["B"] æœªæ›´æ–°
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
if not should_run:
    logger.info(f"Node {name} skipped due to conditions")
    # è¿”å›ä¸€ä¸ªæ ‡è®°ä¸º SKIPPED çš„ç»“æœ
    results[name] = {
        "output": None,
        "state_diff": {},
        "status": NodeStatus.SKIPPED
    }
    return
```

---

### ä¼˜å…ˆçº§ P1 (é‡è¦é—®é¢˜)

#### P1-1: Resume é€»è¾‘çš„ä¸å®Œæ•´æ€§

**æ–‡ä»¶**: `gecko/compose/workflow/engine.py:480-515`

**ä»£ç **:
```python
# 2. é™æ€æµç¨‹æ¢å¤ (Last Node Successor)
next_node = None
if last_node:
     edges = self.graph.edges.get(last_node, [])
     if edges:
         # ç®€å•å–ç¬¬ä¸€æ¡å‡ºè¾¹ (å¤æ‚åˆ†å‰æ¢å¤éœ€æ›´å®Œæ•´çŠ¶æ€è®°å½•)
         next_node = edges[0][0]  # <-- é—®é¢˜
```

**é—®é¢˜**:
1. å¤šå‡ºè¾¹åœºæ™¯ä¸‹ï¼Œåªå–ç¬¬ä¸€æ¡ï¼Œå¿½ç•¥äº†æ¡ä»¶åˆ†æ”¯
   - å¦‚æœ `edges[0]` æ˜¯æ¡ä»¶è¾¹ä¸”æ¡ä»¶ä¸æ»¡è¶³ï¼Œä¼šæ‰§è¡Œé”™è¯¯çš„èŠ‚ç‚¹
   
2. æ²¡æœ‰è®°å½•"å®é™…æ‰§è¡Œåˆ°å“ªä¸€å±‚"ï¼Œåªè®°å½•äº† `last_node`
   - å¦‚æœåœ¨å¤šèŠ‚ç‚¹å±‚å¤±è´¥ï¼Œæ¢å¤æ—¶æ— æ³•çŸ¥é“è¯¥å±‚çš„æ‰§è¡ŒçŠ¶æ€

3. åˆ†å‰åçš„ Resume è¯­ä¹‰ä¸æ¸…æ¥š
   - å¤šæ¡å‡ºè¾¹æ—¶ï¼Œé€‰æ‹©å“ªä¸€æ¡é‡æ–°æ‰§è¡Œï¼Ÿ

**å½±å“**: Resume åœ¨å¤æ‚æ‹“æ‰‘ä¸‹å¯èƒ½å¯¼è‡´é‡å¤æ‰§è¡Œæˆ–è·³è¿‡å¿…è¦èŠ‚ç‚¹

---

#### P1-2: å†…å­˜æ³„æ¼ï¼šHistory æ— ç•Œå¢é•¿

**æ–‡ä»¶**: `gecko/compose/workflow/models.py:81-93`

**ä»£ç **:
```python
def to_storage_payload(self, max_history_steps: int = 10) -> Dict[str, Any]:
    # ... æŒä¹…åŒ–æ—¶ä¼šè£å‰ª
    
# ä½†åœ¨å†…å­˜ä¸­çš„ context.history æ°¸è¿œä¸è¢«è£å‰ª
```

**é—®é¢˜**:
1. `context.history` åœ¨å†…å­˜ä¸­æ— é™å¢é•¿ï¼Œé•¿æœŸè¿è¡Œä¼š OOM
2. æ¯ä¸ªå¹¶è¡ŒèŠ‚ç‚¹éƒ½ `deepcopy()` contextï¼ŒåŒ…å«å®Œæ•´å†å²
   - 100 ä¸ªå¹¶è¡ŒèŠ‚ç‚¹ Ã— 10000 æ­¥ Ã— 100KB/æ­¥ = **100GB** å†…å­˜ï¼

**å½±å“**: ç”Ÿäº§ç¯å¢ƒæ— æ³•è¿è¡Œé•¿æµç¨‹

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# åœ¨ _merge_layer_results æˆ– execute ä¸­å®šæœŸæ¸…ç†
if len(context.history) > max_history_retention:
    # ä»…ä¿ç•™æœ€å N æ­¥ + last_outputï¼ˆå¿…é¡»ï¼‰
    old_keys = sorted(context.history.keys())[:-max_history_retention]
    for k in old_keys:
        del context.history[k]
```

---

#### P1-3: Context DeepCopy çš„æ€§èƒ½ç¾éš¾

**æ–‡ä»¶**: `gecko/compose/workflow/engine.py:349-360`

**ä»£ç **:
```python
async with anyio.create_task_group() as tg:
    for node_name in layer:
        node_context = context.model_copy(deep=True)  # <-- æ¯ä¸ªèŠ‚ç‚¹éƒ½æ·±æ‹·è´ï¼
        tg.start_soon(...)
```

**é—®é¢˜**:
1. 100 ä¸ªå¹¶è¡ŒèŠ‚ç‚¹ â†’ 100 æ¬¡æ·±æ‹·è´
2. å¦‚æœ history æœ‰ 1000 æ­¥ï¼Œæ¯æ¬¡æ‹·è´éƒ½æ˜¯ O(n) æ“ä½œ
3. æ€»æ—¶é—´: O(nodes Ã— history_steps) = O(100 Ã— 1000) = **100,000 ops**

**æ€§èƒ½æµ‹è¯•**:
```
å•æ¬¡æ·±æ‹·è´ (1KB context): ~0.1ms
100 èŠ‚ç‚¹ Ã— 1000 æ­¥å†å²: ~100ms (10% å¼€é”€)
10 å±‚ Ã— 100 èŠ‚ç‚¹: **1ç§’** ä»…ç”¨äºæ‹·è´ï¼
```

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# ç­–ç•¥ A: Copy-On-Write (COW)
# ä»…åœ¨èŠ‚ç‚¹ä¿®æ”¹ state æ—¶æ‰æ‹·è´

# ç­–ç•¥ B: åˆ†ç¦»è¯»å†™
# åªæ·±æ‹·è´ stateï¼Œhistory å…±äº«åªè¯»å¼•ç”¨
node_context = context.model_copy(
    deep=False,
    update={"state": context.state.copy()}
)
```

---

#### P1-4: Executor ä¸­çš„ Pop é™·é˜±

**æ–‡ä»¶**: `gecko/compose/workflow/executor.py:180-190`

**ä»£ç **:
```python
async def _run_function(self, func: Callable, context: WorkflowContext) -> Any:
    if "_next_input" in context.state:
        current_input = context.state.pop("_next_input")  # <-- Popï¼
    else:
        current_input = context.get_last_output()
    
    # ... ä¹‹åçš„ä»£ç ä»å¯èƒ½ä½¿ç”¨ context.state["_next_input"]
```

**é—®é¢˜**:
1. `pop()` æ˜¯ä¸€æ¬¡æ€§æ¶ˆè´¹ï¼Œå¦‚æœå‡½æ•°å¤šæ¬¡è®¿é—®ä¼šå¾—åˆ° KeyError
2. åœ¨ Next é“¾ä¸­ï¼Œstate ä¿®æ”¹ä¸æ˜¯åŸå­çš„
   - Thread A: pop åï¼Œè®¾ç½®æ–°å€¼
   - Thread B: è¯»å– stateï¼Œå¾—åˆ°çš„å¯èƒ½æ˜¯ A çš„ä¿®æ”¹

**å½±å“**: å¤šæ­¥ Next é“¾æ‰§è¡Œæ—¶ï¼Œinput ä¸¢å¤±

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# ä¸è¦ popï¼Œæ”¹ç”¨ get åæ˜¾å¼åˆ é™¤
if "_next_input" in context.state:
    current_input = context.state["_next_input"]
    del context.state["_next_input"]  # æ˜¾å¼åˆ é™¤åçš„è¯­ä¹‰æ›´æ¸…æ¥š
```

---

### ä¼˜å…ˆçº§ P2 (æ”¹è¿›é¡¹)

#### P2-1: Team.input_mapper çš„é”™è¯¯ä¼ æ’­

**æ–‡ä»¶**: `gecko/compose/team.py:110-115`

**ä»£ç **:
```python
if self.input_mapper:
    try:
        val = self.input_mapper(raw_input, i)
        inputs.append(val)
    except Exception as e:
        logger.error(f"Input mapping failed for member {i}", error=str(e))
        inputs.append(None)  # <-- é—®é¢˜ï¼šNone å¯èƒ½ä¸æ˜¯æœ‰æ•ˆè¾“å…¥
```

**é—®é¢˜**:
1. é»˜é»˜å°†å¤±è´¥çš„æ˜ å°„è®¾ä¸º Noneï¼Œå¯èƒ½å¯¼è‡´ä¸‹æ¸¸é”™è¯¯
2. æ²¡æœ‰åŒºåˆ†"æ˜ å°„é€»è¾‘é”™è¯¯"å’Œ"æš‚æ—¶ä¸å¯ç”¨"

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
try:
    val = self.input_mapper(raw_input, i)
    inputs.append(val)
except Exception as e:
    logger.error(f"Input mapping failed for member {i}", error=str(e))
    # é€‰é¡¹ 1: ä¼ æ’­å¼‚å¸¸ï¼Œä¸­æ­¢ Team æ‰§è¡Œ
    raise
    # é€‰é¡¹ 2: ä½¿ç”¨åŸå§‹è¾“å…¥ä½œä¸º fallback
    # inputs.append(raw_input)
```

---

#### P2-2: Next.update_state çš„åˆå¹¶é¡ºåºä¸å®š

**æ–‡ä»¶**: `gecko/compose/nodes.py:30-34`

**ä»£ç **:
```python
@dataclass
class Next(BaseModel):
    node: str
    input: Optional[Any] = None
    update_state: Dict[str, Any] = Field(default_factory=dict)  # æ— åº
```

**é—®é¢˜**:
1. å¤šä¸ª Next æŒ‡ä»¤åŒæ—¶è¿”å›æ—¶ï¼Œupdate_state çš„åˆå¹¶é¡ºåºä¸å®š
   - Dict.update() æ˜¯åŸåœ°ä¿®æ”¹ï¼Œå¤šä¸ª update çš„é¡ºåºä¼šå½±å“ç»“æœ
   
2. åº”è¯¥æ˜¾å¼è¯´æ˜åˆå¹¶ç­–ç•¥ (Last Write Wins / Deep Merge / Error on Conflict)

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
class Next(BaseModel):
    """
    Merge Strategy: LAST_WRITE_WINS (é»˜è®¤)
    å¦‚æœå¤šä¸ªèŠ‚ç‚¹éƒ½è¿”å› Next ä¸”æœ‰å†²çªçš„ update_stateï¼Œ
    åå¤„ç†çš„èŠ‚ç‚¹ä¼šè¦†ç›–å‰è€…ã€‚
    """
    merge_strategy: Literal["last_write_wins", "deep_merge", "error"] = "last_write_wins"
```

---

#### P2-3: æ¡ä»¶å‡½æ•°çš„åŒæ­¥/å¼‚æ­¥æ··æ·†

**æ–‡ä»¶**: `gecko/compose/workflow/engine.py:376-383`

**ä»£ç **:
```python
res = cond(ctx)
if inspect.isawaitable(res):
    res = await res
if res:
    should_run = True
```

**é—®é¢˜**:
1. `inspect.isawaitable()` æ£€æŸ¥ä¸å¤Ÿä¸¥æ ¼ï¼Œå¯èƒ½è¯¯åˆ¤
   - å¦‚æœæ¡ä»¶å‡½æ•°è¿”å› `Mock` å¯¹è±¡ï¼Œå¯èƒ½è¢«é”™è¯¯è¯†åˆ«ä¸º awaitable
   
2. æ²¡æœ‰è¶…æ—¶ä¿æŠ¤
   - å¦‚æœæ¡ä»¶å‡½æ•°æ­»å¾ªç¯ï¼Œä¼šå¡ä½æ•´ä¸ªå·¥ä½œæµ

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
try:
    res = cond(ctx)
    if inspect.iscoroutine(res):  # æ›´ç²¾å‡†
        res = await asyncio.wait_for(res, timeout=5.0)
    if res:
        should_run = True
except asyncio.TimeoutError:
    logger.error(f"Condition timeout for {src}->{name}")
    # è¶…æ—¶è§†ä¸ºæ¡ä»¶å¤±è´¥ï¼ˆFail Safeï¼‰
except Exception as e:
    logger.error(f"Condition error: {e}")
```

---

#### P2-4: ç¼ºä¹æ‰§è¡Œè¶…æ—¶ä¿æŠ¤

**æ–‡ä»¶**: `gecko/compose/workflow/engine.py:316-365`

**ä»£ç **:
```python
async def execute(
    self, 
    input_data: Any,
    # ... æ²¡æœ‰ timeout å‚æ•°
) -> Any:
```

**é—®é¢˜**:
1. å·¥ä½œæµå¯èƒ½æ— é™æœŸæŒ‚èµ·
   - æŸä¸ªèŠ‚ç‚¹çš„ Agent è°ƒç”¨äº†ä¸å¯é çš„ LLM APIï¼Œç½‘ç»œè¶…æ—¶
   
2. æ²¡æœ‰å…¨å±€è¶…æ—¶ï¼Œæ²¡æœ‰å•èŠ‚ç‚¹è¶…æ—¶

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
async def execute(
    self,
    input_data: Any,
    timeout: Optional[float] = None,  # ç§’æ•°
    node_timeout: Optional[float] = 30,
) -> Any:
    if timeout:
        try:
            return await asyncio.wait_for(
                self._execute_impl(input_data),
                timeout=timeout
            )
        except asyncio.TimeoutError:
            raise WorkflowError(f"Workflow execution timeout after {timeout}s")
```

---

#### P2-5: Mermaid å›¾çš„æ¡ä»¶æ ‡ç­¾ä¸ºç©º

**æ–‡ä»¶**: `gecko/compose/workflow/graph.py:234`

**ä»£ç **:
```python
for source, targets in self.edges.items():
    for target, condition in targets:
        label = "|condition|" if condition else ""
        lines.append(f"    {source} --{label}--> {target}")
```

**é—®é¢˜**:
1. æ¡ä»¶å‡½æ•°å¯¹è±¡æ— æ³•è½¬ä¸ºæœ‰æ„ä¹‰çš„å­—ç¬¦ä¸²
2. ç”Ÿæˆçš„ Mermaid å›¾æ— æ³•åŒºåˆ†æœ‰æ¡ä»¶å’Œæ— æ¡ä»¶è¾¹

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# ä¸ºæ¡ä»¶å‡½æ•°é™„åŠ åç§°å…ƒæ•°æ®
def conditional_edge(condition_func: Callable, name: Optional[str] = None):
    func = condition_func
    func._edge_label = name or condition_func.__name__
    return func

# ç”Ÿæˆå›¾æ—¶ï¼š
label = condition._edge_label if hasattr(condition, "_edge_label") else "?"
```

---

## ğŸ”’ å¹¶å‘å®‰å…¨æ€§åˆ†æ

### å·²è¯†åˆ«çš„çº¿ç¨‹å®‰å…¨é—®é¢˜

| ç»„ä»¶ | é—®é¢˜ | é£é™©çº§åˆ« |
|-----|------|---------|
| `Team._execute_race()` | éåŸå­çš„åŒé‡æ£€æŸ¥ | ğŸ”´ ä¸¥é‡ |
| `context.model_copy(deep=True)` | ä¸²è¡ŒåŒ–æ‹·è´å¼€é”€ | ğŸŸ  ä¸­ç­‰ |
| `Team.input_mapper` | å¹¶å‘è°ƒç”¨å®‰å…¨æ€§æœªéªŒè¯ | ğŸŸ  ä¸­ç­‰ |
| `WorkflowContext.state` | Last Write Wins åˆå¹¶å¯èƒ½ä¸¢å¤±æ›´æ–° | ğŸŸ¡ ä½ |

### æ¨èçš„å¹¶å‘æµ‹è¯•

```python
async def test_concurrent_updates_to_state():
    """éªŒè¯å¹¶è¡ŒèŠ‚ç‚¹çš„çŠ¶æ€åˆå¹¶æ­£ç¡®æ€§"""
    context = WorkflowContext(input={})
    
    async def increment(ctx, delta):
        ctx.state["counter"] = ctx.state.get("counter", 0) + delta
    
    # æ¨¡æ‹Ÿ 100 ä¸ªå¹¶è¡ŒèŠ‚ç‚¹ï¼Œæ¯ä¸ªå¢åŠ  1
    # æœŸæœ›: state["counter"] == 100
    # å®é™…: ???
```

---

## ğŸ“Š æ€§èƒ½åˆ†æ

### DeepCopy å¼€é”€è¯„ä¼°

```
åœºæ™¯: 10 å±‚ Ã— 100 èŠ‚ç‚¹/å±‚ = 1000 ä¸ªå¹¶è¡ŒèŠ‚ç‚¹

å½“å‰å®ç°:
- ç¬¬ 1 å±‚: 100 æ¬¡æ·±æ‹·è´ (1KB each) = 100ms
- ç¬¬ 2 å±‚: 100 æ¬¡æ·±æ‹·è´ (2KB + å†å²) = 200ms
- ç¬¬ 10 å±‚: 100 æ¬¡æ·±æ‹·è´ (10KB + å†å²) = 1000ms
æ€»è®¡: ~3-5 ç§’ ä»…ç”¨äºæ‹·è´

ä¼˜åŒ–å (Copy-On-Write):
- 1000 æ¬¡ shallow copy = 10ms
- æŒ‰éœ€æ·±æ‹·è´ state = 100ms (ä»…ä¿®æ”¹çš„èŠ‚ç‚¹)
æ€»è®¡: ~100ms
æ”¹è¿›: **50x faster**
```

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡é—®é¢˜

### A1: é™æ€ DAG + åŠ¨æ€ Next çš„æ··æ‚

**å½“å‰è®¾è®¡**:
- Phase 1: é¢„å…ˆæ„å»ºæ‰§è¡Œè®¡åˆ’ï¼ˆKahn ç®—æ³•ï¼‰
- Phase 2: Next æŒ‡ä»¤æ‰“ç ´è®¡åˆ’ï¼Œè½¬ä¸ºåŠ¨æ€æ‰§è¡Œ

**é—®é¢˜**:
1. ä¸¤ä¸ªå¹¶è¡Œçš„æ§åˆ¶æµï¼šé™æ€è®¡åˆ’ + åŠ¨æ€æŒ‡ä»¤ï¼Œå®¹æ˜“å†²çª
2. Resume æ—¶æ— æ³•å‡†ç¡®æ¢å¤åˆ°è¢« Next ä¸­æ–­çš„ä½ç½®

**æ”¹è¿›æ–¹æ¡ˆ**:
```
é‡‡ç”¨çº¯åŠ¨æ€æ‰§è¡Œæ¨¡å‹:
- ä¸é¢„å…ˆæ„å»ºå…¨å±€è®¡åˆ’
- æ¯ä¸€å±‚æ‰§è¡Œåï¼Œæ ¹æ® Next åŠ¨æ€å†³å®šä¸‹ä¸€å±‚
- ä¼˜ç‚¹: æ›´çµæ´»ï¼Œæ›´å®¹æ˜“å¤„ç† Resume
- ç¼ºç‚¹: æ— æ³•å‰æœŸå¯è§†åŒ–æ•´ä¸ªè®¡åˆ’
```

---

### A2: State åˆå¹¶çš„"æœ€åèµ¢è€…"ç­–ç•¥é£é™©

**å½“å‰æ–¹æ¡ˆ**: Last Write Winsï¼ˆåæ¥çš„è¦†ç›–å‰é¢çš„ï¼‰

**é—®é¢˜åœºæ™¯**:
```python
# å¹¶è¡Œ Node A, B, C

Node A: state["result"] = "A_value"
Node B: state["result"] = "B_value"  # è¦†ç›– A
Node C: éœ€è¦è¯»å– state["result"]

# C æœ€ç»ˆè¯»åˆ°çš„æ˜¯ B çš„å€¼ï¼ŒA çš„ä¿®æ”¹ä¸¢å¤±
```

**æ›´å¥½çš„æ–¹æ¡ˆ**:
```python
# åˆ†ç¦» state ä¸º private_state + shared_state

# private_state: ä»…è¯¥èŠ‚ç‚¹ä¿®æ”¹çš„å­—æ®µ (e.g., node_A_cache)
# shared_state: å¤šä¸ªèŠ‚ç‚¹åä½œä¿®æ”¹çš„å­—æ®µ (e.g., results[])

# å¯¹äº shared_stateï¼Œä½¿ç”¨ merging strategy:
# - å¦‚æœæ˜¯ listï¼Œappend
# - å¦‚æœæ˜¯ dictï¼Œdeep merge
# - å¦‚æœæ˜¯åŸå§‹ç±»å‹ï¼Œconflict â†’ error
```

---

## âœ… å·²åšå¾—å¥½çš„è®¾è®¡

### G1: åˆ†ç¦» Executor çš„æ— çŠ¶æ€è®¾è®¡

**ä¼˜ç‚¹**:
- `NodeExecutor` ä¸æŒæœ‰å…¨å±€çŠ¶æ€ï¼Œå¯å®‰å…¨å¹¶å‘ä½¿ç”¨
- æ˜“äºå•å…ƒæµ‹è¯•
- æ”¯æŒè‡ªå®šä¹‰æ‰§è¡Œç­–ç•¥ï¼ˆé‡è¯•ã€è¶…æ—¶ç­‰ï¼‰

### G2: ä¸Šä¸‹æ–‡ç˜¦èº«çš„æŒä¹…åŒ–

**ä¼˜ç‚¹**:
- `to_storage_payload()` å‡å°‘æŒä¹…åŒ–æ•°æ®é‡
- `max_history_steps` å‚æ•°åŒ–å¯é…ç½®
- é˜²æ­¢çŠ¶æ€çˆ†ç‚¸

### G3: çµæ´»çš„å‚æ•°æ³¨å…¥æœºåˆ¶

**ä¼˜ç‚¹**:
- æ™ºèƒ½å‚æ•°ç»‘å®šæ”¯æŒ WorkflowContext / input æ··åˆ
- å…¼å®¹ Agent / æ™®é€šå‡½æ•° / Lambda
- ç±»å‹æç¤ºå’Œå‚æ•°åç§°åŒé‡æ”¯æŒ

### G4: æ¡ä»¶è¾¹çš„è¿è¡Œæ—¶æ£€æŸ¥

**ä¼˜ç‚¹**:
- æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥æ¡ä»¶å‡½æ•°
- å¤±è´¥å®‰å…¨ (æ¡ä»¶é”™è¯¯ â†’ æ¡ä»¶å¤±è´¥)
- çµæ´»çš„åˆ†æ”¯é€»è¾‘

---

## ğŸ“‹ ä¿®å¤æ¸…å•

### å¿…é¡»ä¿®å¤ (Release Blocker)

- [ ] P0-1: Race æ¨¡å¼çš„ç«æ€æ¡ä»¶ â†’ å¼•å…¥ `asyncio.Lock`
- [ ] P0-2: Race å®Œå…¨å¤±è´¥æ—¶è¿”å›æœ‰æ„ä¹‰çš„ç»“æœ
- [ ] P0-3: Next æŒ‡ä»¤çš„çŠ¶æ€æ±¡æŸ“ â†’ ä¿ç•™åŸæœ‰ input å½“ None
- [ ] P0-4: æ¡ä»¶è·³è¿‡çš„èŠ‚ç‚¹ç¼ºå¤± â†’ è¿”å› SKIPPED çŠ¶æ€

### åº”å½“ä¿®å¤ (High Priority)

- [ ] P1-1: Resume é€»è¾‘çš„ä¸å®Œæ•´æ€§ â†’ è®°å½•æ‰§è¡Œå±‚çº§
- [ ] P1-2: History æ— ç•Œå¢é•¿ â†’ å®šæœŸæ¸…ç†
- [ ] P1-3: DeepCopy æ€§èƒ½ç¾éš¾ â†’ Copy-On-Write
- [ ] P1-4: Pop é™·é˜± â†’ æ”¹ç”¨ get + del

### æ”¹è¿›é¡¹ (Nice to Have)

- [ ] P2-1: input_mapper é”™è¯¯ä¼ æ’­ â†’ æ›´æ¸…æ™°çš„è¯­ä¹‰
- [ ] P2-2: update_state åˆå¹¶é¡ºåº â†’ æ˜¾å¼è¯´æ˜ç­–ç•¥
- [ ] P2-3: æ¡ä»¶å‡½æ•°çš„è¶…æ—¶ â†’ åŠ å…¥è¶…æ—¶ä¿æŠ¤
- [ ] P2-4: ç¼ºä¹æ‰§è¡Œè¶…æ—¶ â†’ æ·»åŠ å…¨å±€/èŠ‚ç‚¹è¶…æ—¶å‚æ•°
- [ ] P2-5: Mermaid æ¡ä»¶æ ‡ç­¾ â†’ é™„åŠ å…ƒæ•°æ®

---

## ğŸ’¡ ç”Ÿäº§çº§ä¼˜åŒ–å»ºè®®

### O1: ç›‘æ§å’Œå¯è§‚æµ‹æ€§

```python
# æ·»åŠ  instrumentation
async def _execute_layer_parallel(...):
    with tracer.start_as_current_span("execute_layer") as span:
        span.set_attribute("layer.size", len(layer))
        span.set_attribute("layer.nodes", list(layer))
        
        start = time.time()
        results = ...
        
        span.set_attribute("layer.duration", time.time() - start)
        metrics.histogram("workflow.layer.duration", time.time() - start)
```

### O2: é€Ÿç‡é™åˆ¶å’ŒèƒŒå‹

```python
class Workflow:
    def __init__(self, ..., max_concurrent_layers: int = 3):
        """é™åˆ¶å¹¶è¡Œå±‚æ•°ï¼Œé˜²æ­¢å†…å­˜çˆ†ç‚¸"""
        self.layer_semaphore = asyncio.Semaphore(max_concurrent_layers)
```

### O3: æ–­ç‚¹è°ƒè¯•æ”¯æŒ

```python
class Workflow:
    breakpoints: Set[str] = set()
    
    def set_breakpoint(self, node: str):
        """åœ¨èŠ‚ç‚¹å¤„æš‚åœæ‰§è¡Œï¼Œç”¨äºè°ƒè¯•"""
        self.breakpoints.add(node)
    
    async def _run_node_wrapper(...):
        if name in self.breakpoints:
            logger.info(f"Breakpoint hit at {name}")
            await self._debug_repl(name, ctx)  # äº¤äº’å¼è°ƒè¯•
```

---

## ğŸ¯ æ€»ç»“ä¸å»ºè®®

### æ€»ä½“è¯„åˆ†

- **åŠŸèƒ½å®Œæ•´æ€§**: 8/10 âœ…
- **ä»£ç è´¨é‡**: 5/10 âš ï¸
- **å¹¶å‘å®‰å…¨**: 4/10 âŒ
- **ç”Ÿäº§å°±ç»ª**: 3/10 âŒ

### å»ºè®®è¡ŒåŠ¨

1. **ç«‹å³ä¿®å¤** P0 çº§ bugï¼ˆ1-2 å¤©ï¼‰
2. **ä¸€å‘¨å†…** å®Œæˆ P1 çº§æ”¹è¿›ï¼ˆå†…å­˜ã€æ€§èƒ½ï¼‰
3. **è¿­ä»£å¼€å‘** P2 çº§ä¼˜åŒ–å’Œæ–°ç‰¹æ€§ï¼ˆå¹¶è¡ŒåŒ–æµ‹è¯•ï¼‰
4. **é•¿æœŸç»´æŠ¤** æ·»åŠ å‹åŠ›æµ‹è¯•å’Œç›‘æ§

### ä½•æ—¶å¯æŠ•å…¥ç”Ÿäº§

**å½“å‰**: âŒ **ä¸æ¨è**ï¼ˆå­˜åœ¨ä¸¥é‡ bugï¼‰

**ä¿®å¤å**: âœ… **å¯æ¡ä»¶éƒ¨ç½²**ï¼ˆæ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼‰
- [ ] æ‰€æœ‰ P0 bug ä¿®å¤
- [ ] 1000+ èŠ‚ç‚¹çš„å‹åŠ›æµ‹è¯•é€šè¿‡
- [ ] 24å°æ—¶é•¿æœŸè¿è¡Œæµ‹è¯•é€šè¿‡
- [ ] æ·»åŠ å®Œæ•´çš„æ—¥å¿—å’Œç›‘æ§
- [ ] ç¼–å†™ Resume å’Œå¤±è´¥æ¢å¤çš„æ“ä½œæŒ‡å—

---

**ç¼–å†™è€…**: AI Code Reviewer  
**æœ€åæ›´æ–°**: 2025-12-04
