[1] docs/best_practices.md
```markdown
# 最佳实践

## 1. 并发安全

在自定义 Storage 或 Tool 时，请注意 Gecko 是异步并发环境。
*   **不要阻塞 Event Loop**: 如果有耗时的同步 I/O（如文件读写），请继承 `ThreadOffloadMixin` 并使用 `self._run_sync()`。
*   **使用锁**: 如果需要修改共享状态，使用 `asyncio.Lock`。如果涉及跨进程文件写入，参考 `AtomicWriteMixin`。

## 2. 错误处理

Gecko 提倡显式的错误处理。
*   **Workflow**: 节点抛出的异常会中断流程。如果希望容错，请在节点内部 try-catch 并返回特定的 `Next` 指令，或者开启 `Workflow(enable_retry=True)`。
*   **Team**: `Team` 引擎默认捕获单个成员的异常，返回 `MemberResult(is_success=False)`，不会中断整个团队的执行。

## 3. 性能优化

*   **SQLite**: 默认启用了 WAL 模式，并发读写性能很好。但在极高并发下建议切换到 Redis。
*   **Token 计数**: `TokenMemory` 内部有 LRU 缓存。对于批量消息处理，确保开启缓存以减少 `tiktoken` 计算开销。

## 4. 调试与日志

Gecko 使用结构化日志。
*   推荐安装 `structlog` 以获得更好的 JSON 日志格式。
*   设置环境变量 `GECKO_LOG_LEVEL=DEBUG` 可以查看详细的 Prompt 和 Token 消耗。
```

[2] docs/configuration.md
```markdown
# 配置详解

Gecko 使用 `pydantic-settings` 管理配置。你可以通过 `.env` 文件或系统环境变量来覆盖默认值。

## 基础配置

| 环境变量 | 默认值 | 说明 |
| :--- | :--- | :--- |
| `GECKO_LOG_LEVEL` | `INFO` | 日志级别 (DEBUG, INFO, WARNING, ERROR) |
| `GECKO_LOG_FORMAT` | `text` | 日志格式，生产环境建议设为 `json` 以配合 ELK/Splunk |
| `GECKO_DEFAULT_MODEL` | `gpt-3.5-turbo` | `AgentBuilder` 未指定模型时的默认值 |
| `GECKO_DEFAULT_TIMEOUT` | `30.0` | 工具执行的默认超时时间（秒） |

## 安全与限制

| 环境变量 | 默认值 | 说明 |
| :--- | :--- | :--- |
| `GECKO_MAX_TURNS` | `5` | ReAct 循环的最大思考轮数，防止死循环消耗 Token |
| `GECKO_MAX_CONTEXT_TOKENS` | `4000` | Memory 的最大 Token 窗口限制 |

## 存储连接

| 环境变量 | 默认值 | 说明 |
| :--- | :--- | :--- |
| `GECKO_DEFAULT_STORAGE_URL` | `sqlite://./gecko_data.db` | 默认的持久化存储地址 |

## Model Provider 凭证

Gecko 底层依赖 `LiteLLM`，支持其所有标准环境变量：

*   `OPENAI_API_KEY`
*   `ZHIPU_API_KEY`
*   `ANTHROPIC_API_KEY`
*   `AZURE_API_KEY` / `AZURE_API_BASE`
*   ... (更多请参考 LiteLLM 文档)
```

[3] docs/core_concepts.md
```markdown
# 核心概念

## Agent (智能体)

`Agent` 是 Gecko 的原子执行单元。它封装了以下三个核心组件：
1.  **Model**: 负责生成文本和决策。
2.  **Memory**: 负责管理上下文历史。
3.  **ToolBox**: 负责执行外部工具。

## Cognitive Engine (认知引擎)

Gecko 将推理逻辑从 Agent 中剥离，称为 `Engine`。目前内置了 **ReActEngine**。

### ReAct Engine 特性
*   **死循环检测**: 基于 Hash 自动检测重复的工具调用参数，防止 Agent 陷入死循环。
*   **观测值截断**: 自动截断过长的工具输出（如爬虫抓取了 10MB 文本），防止 Context Window 溢出。
*   **结构化重试**: 如果 LLM 返回的 JSON 格式错误，Engine 会自动将错误信息反馈给 LLM 进行自我修正。

## Memory (记忆)

`TokenMemory` 是 Gecko 的默认记忆实现。

*   **滑动窗口**: 自动计算 Token 数，当超出 `max_tokens` 时，保留 System Prompt，并移除最早的历史消息。
*   **自动摘要**: 使用 `SummaryTokenMemory` 可以在移除历史消息前自动生成摘要并注入 Context。

## ToolBox (工具箱)

`ToolBox` 负责工具的注册、执行和并发控制。

*   **并发安全**: 内置线程锁，保证统计数据的安全性。
*   **Schema 生成**: 自动从 Pydantic 的 `args_schema` 生成 OpenAI 兼容的 JSON Schema。
*   **批量执行**: 支持 `execute_many`，利用 `anyio.TaskGroup` 并发执行多个工具调用。
```

[4] docs/deployment.md
```markdown
# 生产环境部署指南

Gecko 是为高并发环境设计的。以下是将 Gecko 应用部署到生产环境的最佳实践。

## 1. 并发模型选择

Gecko 核心是异步的 (`async/await`)。在部署 Web 服务（如 FastAPI 封装 Agent）时，**必须使用异步 Worker**。

### ❌ 不要使用
*   同步的 Gunicorn Worker (`sync`)
*   Flask 自带的开发服务器

### ✅ 推荐使用
*   **Uvicorn**: 单进程高性能。
*   **Gunicorn + Uvicorn Workers**: 多进程管理 + 异步处理。

```bash
# 安装依赖
pip install gunicorn uvicorn

# 启动命令 (假设你的应用入口在 main.py 的 app 对象)
# -k uvicorn.workers.UvicornWorker 是关键！
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

## 2. 存储后端选择

虽然 Gecko 对 SQLite 做了大量优化（WAL 模式 + 文件锁），但在极高并发或容器化环境下，建议切换后端。

### 单机 / 少量并发
*   **推荐**: SQLite (`sqlite:///./data.db`)
*   **注意**: Gecko 内置的 `FileLock` 可以保证 Gunicorn 多 Worker 写入 SQLite 时不损坏数据库，但会牺牲部分性能。

### 集群 / 高并发
*   **推荐**: Redis (`redis://host:6379`)
*   **优势**: 无锁竞争，极高的读写吞吐，天生支持 TTL（会话过期）。

## 3. Docker 部署示例

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# 1. 安装系统依赖 (如果需要编译库)
RUN apt-get update && apt-get install -y build-essential curl

# 2. 安装 Python 依赖
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt "gecko-ai[redis]"

# 3. 复制源码
COPY . .

# 4. 设置环境变量
ENV GECKO_LOG_FORMAT=json
ENV GECKO_LOG_LEVEL=INFO

# 5. 启动服务
CMD ["gunicorn", "main:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "-b", "0.0.0.0:8000"]
```
```

[5] docs/gecko-core-api-v1.0.md
```markdown
# Gecko 核心 API v1.0 稳定接口规范（草案）

> 文件路径建议：`docs/core-api-v1.0.md`  
> 本文档用于声明 Gecko v1.0 版本对外 **承诺稳定** 的核心接口范围，以及配套的版本管理与演进策略。

---

## 0. 前言

- **目标读者**：  
  - 使用 Gecko 构建智能体 / 工作流应用的业务开发者  
  - 基于 Gecko 扩展模型、工具、存储后端的插件开发者  
- **文档目的**：  
  - 明确 v1.0 中的「稳定 API」边界  
  - 区分应用层 API（L1）、扩展层 API（L2）与内部实现（L3）  
  - 为后续版本演进提供兼容性约束依据

> ⚠️ 注意：本文件为 v1.0 规范草案，正式发布前请与 CHANGELOG、源码注释保持一致。

---

## 1. API 分级与范围

### 1.1 API 分级说明

- **L1：应用开发者 API（强稳定）**
  - 面向：直接使用 Gecko 搭建智能体 / 工作流 / 多智能体应用的开发者
  - 要求：v1.x 生命周期内不做破坏性变更，必要变更需经过 deprecate 过渡期

- **L2：扩展开发者 API（相对稳定）**
  - 面向：开发模型适配器、Memory 策略、存储后端、工具插件等的扩展开发者
  - 要求：尽量保持兼容，重要变更需在文档和 CHANGELOG 中提前说明

- **L3：内部实现 / 实验性 API（不承诺稳定）**
  - 面向：框架内部演进与实验性特性
  - 要求：可在小版本中发生破坏性调整，不建议外部直接依赖

### 1.2 v1.0 稳定 API 范围概览

- L1（应用开发者）：
  - 顶层导出：`gecko.__version__`、`Agent`、`AgentBuilder`、`Message`、`Role`、`AgentOutput`、`TokenUsage`、`TokenMemory`、`SummaryTokenMemory`、`StructureEngine`、`Workflow`、`step`、`Next`、`Team`
- L2（扩展开发者）：
  - 模型扩展基类 / 协议
  - Memory 扩展基类
  - Storage 后端扩展基类
  - Tool 定义装饰器 / 结构
- L3（内部 / 实验性）：
  - Telemetry、Tracing、Events、Guardrails、Knowledge 等尚在演进中的模块

---

## 2. L1 应用开发者 API

### 2.1 顶层导出（`gecko` 包）

#### 2.1.1 顶层符号一览

自 v1.0 起，`gecko/__init__.py` 至少导出以下符号：

- `__version__: str`
- `Agent`
- `AgentBuilder`
- `Message`
- `Role`
- `AgentOutput`
- `TokenUsage`
- `TokenMemory`
- `SummaryTokenMemory`
- `StructureEngine`
- `Workflow`
- `step`
- `Next`
- `Team`

#### 2.1.2 使用示例（示意）

```python
from gecko import AgentBuilder, Message, Workflow, step, Next

async def main():
    agent = (
        AgentBuilder()
        .with_model(...)
        .with_system_prompt("You are a helpful assistant.")
        .build()
    )

    output = await agent.run("Hello Gecko!")
    print(output.content)
````

> TODO：补充完整的最小可运行示例。

---

### 2.2 Agent & Builder（`gecko.core.agent` / `gecko.core.builder`）

#### 2.2.1 Agent（`gecko.core.agent.Agent`）

**职责**：封装单智能体的推理流程，统一对外提供 `run()` / 流式接口。

* 核心方法（签名以实现为准，语义需稳定）：

  * `async def run(self, input, **kwargs) -> AgentOutput`
  * 可选：`async def astream(self, input, **kwargs) -> AsyncIterator[AgentOutput]`
* 关键属性（对外可见但建议只读）：

  * `model`
  * `memory`
  * `tools`

> TODO：在这里列出正式的方法签名与参数说明表格。

#### 2.2.2 AgentBuilder（`gecko.core.builder.AgentBuilder`）

**职责**：按 Builder 模式配置并构建 `Agent` 实例。

* 稳定链式方法：

  * `with_model(model)`
  * `with_prompt(prompt)`
  * `with_system_prompt(text: str)`
  * `with_memory(memory)`
  * `with_tools(tools | *tools)`
  * `with_events(event_bus | callbacks)`（如有）
  * `build() -> Agent`

```python
from gecko import AgentBuilder

agent = (
    AgentBuilder()
    .with_model(my_model)
    .with_system_prompt("You are a code assistant.")
    .with_memory(TokenMemory(max_tokens=2048))
    .with_tools([search_tool])
    .build()
)
```

---

### 2.3 消息与 Prompt（`gecko.core.message` / `gecko.core.prompt`）

#### 2.3.1 Message & Role（`gecko.core.message`）

* `class Message`

  * 典型字段：

    * `role: str`
    * `content: str | list | dict`
    * `name: str | None`
    * `tool_call_id: str | None`
  * 常用构造方法（如已实现）：

    * `Message.user(content)`
    * `Message.assistant(content)`
    * `Message.system(content)`

* `Role`（Enum 或常量集合）

  * `Role.USER`
  * `Role.ASSISTANT`
  * `Role.SYSTEM`
  * `Role.TOOL`
  * ...

```python
from gecko import Message, Role

msg = Message(role=Role.USER, content="Hello")
```

#### 2.3.2 Prompt 模板（`gecko.core.prompt`）

> ⚠️ 该小节为骨架，具体类名与方法需要与实际实现对齐。

* 主力类（示例名）：`PromptTemplate`

  * 功能：

    * 变量插值（`format` / `render`）
    * 条件判断（if/else）
    * 循环块（for）
    * 部分填充（partial）
  * 典型方法：

    * `render(**kwargs) -> str`
    * `format_safe(**kwargs) -> str`
    * `partial(**preset) -> PromptTemplate`

```python
from gecko.core.prompt import PromptTemplate

tmpl = PromptTemplate("Hello, {{ name }}!")
print(tmpl.render(name="Gecko"))
```

---

### 2.4 Memory（`gecko.core.memory`）

#### 2.4.1 TokenMemory

* 模块：`gecko.core.memory`
* 类：`TokenMemory`

  * 责任：在给定 `max_tokens` 约束下维护与裁剪会话上下文
  * 核心方法：

    * `append(message: Message) -> None`
    * `get_context() -> list[Message]`
    * `reset() -> None`

#### 2.4.2 SummaryTokenMemory

* 类：`SummaryTokenMemory`

  * 在 TokenMemory 基础上引入「自动摘要」机制，用于长会话压缩。

```python
from gecko import TokenMemory, Message

memory = TokenMemory(max_tokens=2048)
memory.append(Message.user("你好"))
context = memory.get_context()
```

> TODO：补充摘要策略相关的行为说明。

---

### 2.5 输出封装（`gecko.core.output`）

#### 2.5.1 AgentOutput

* 模块：`gecko.core.output`
* 类：`AgentOutput`

  * 典型字段：

    * `content`
    * `messages`
    * `tool_calls`
    * `usage: TokenUsage | None`
  * 方法：

    * `has_content() -> bool`
    * `is_empty() -> bool`

#### 2.5.2 TokenUsage

* 类：`TokenUsage`

  * 字段：

    * `prompt_tokens: int`
    * `completion_tokens: int`
    * `total_tokens: int`

#### 2.5.3 工具函数

* `create_text_output(content: str, *, usage: TokenUsage | None = None) -> AgentOutput`
* `create_tool_output(tool_name: str, arguments: dict, *, usage: TokenUsage | None = None) -> AgentOutput`
* `merge_outputs(*outputs: AgentOutput) -> AgentOutput`

```python
from gecko.core.output import AgentOutput, TokenUsage

usage = TokenUsage(prompt_tokens=10, completion_tokens=20, total_tokens=30)
output = AgentOutput(content="OK", usage=usage)
```

---

### 2.6 结构化输出（`gecko.core.structure`）

* 模块：`gecko.core.structure`
* 类：`StructureEngine`

  * 典型接口（示意）：

    * `@staticmethod to_openai_tool(model_cls: type[BaseModel]) -> dict`
    * `@classmethod async parse(model_cls, raw) -> BaseModel`

```python
from pydantic import BaseModel, Field
from gecko import StructureEngine

class UserProfile(BaseModel):
    name: str = Field(description="用户名")
    age: int = Field(ge=0, le=150)

schema = StructureEngine.to_openai_tool(UserProfile)
```

> TODO：补充解析示例与错误处理说明。

---

### 2.7 Workflow & Team（`gecko.compose.workflow` / `gecko.compose.team`）

#### 2.7.1 Workflow / step / Next

* 模块：`gecko.compose.workflow`

  * `class Workflow`

    * `async def run(self, input, **kwargs) -> Any`
  * `def step(func) -> func`

    * 标记 Workflow 节点
  * `class Next`

    * 字段示意：`target: str`, `data: Any | None`, `terminate: bool = False`

```python
from gecko import Workflow, step, Next

wf = Workflow()

@step
async def start(ctx, data):
    # ...
    return Next(target="end", data=data)

@step
async def end(ctx, data):
    return data

result = await wf.run(input="hello")
```

#### 2.7.2 Team

* 模块：`gecko.compose.team`

  * `class Team`

    * `async def run(self, input, **kwargs) -> AgentOutput | dict[str, AgentOutput]`

```python
from gecko import Team, AgentBuilder

team = Team(
    experts=[
        AgentBuilder().with_model(...).build(),
        AgentBuilder().with_model(...).build(),
    ]
)

result = await team.run("分析一下这个需求")
```

> TODO：根据实际实现补充 Team 构造参数与协作策略说明。

---

## 3. L2 扩展开发者 API

> 本节列出 v1.0 中建议对外开放、相对稳定的扩展接口，适合开发模型适配器、Memory 策略、存储后端、工具插件等。

### 3.1 模型扩展接口（`gecko.plugins.models`）

* 抽象基类 / 协议（示意）：

  * `BaseChatModel` 或 `ModelProtocol`
  * 关键抽象方法：

    * `async def acompletion(self, messages: list[Message], **kwargs) -> AgentOutput | ModelRawOutput`

> TODO：贴出正式的抽象类定义与最小适配器示例（如 ZhipuChat）。

---

### 3.2 Memory 扩展接口（`gecko.core.memory.base`）

* `class BaseMemory`

  * 抽象方法：

    * `append(message: Message) -> None`
    * `get_context() -> list[Message]`
    * `reset() -> None`

> TODO：给出一个自定义 Memory（如 RedisMemory）的示例骨架。

---

### 3.3 Storage 扩展接口（`gecko.plugins.storage`）

* `class BaseStorageBackend`

  * 典型抽象方法：

    * `save_session(session_id: str, data: dict) -> None`
    * `load_session(session_id: str) -> dict | None`
    * `delete_session(session_id: str) -> None`

> TODO：补充 SQLite / 内存后端的参考实现说明。

---

### 3.4 Tool 定义接口（`gecko.plugins.tools` / `gecko.core.tools`）

* `@tool` 装饰器（示意）
* `class Tool` / `ToolSpec`

```python
from gecko.plugins.tools import tool

@tool
def search(query: str, max_results: int = 5) -> list[dict]:
    """搜索工具"""
    ...
```

> TODO：说明参数映射、返回值约定以及与 LLM Tool Schema 的关系。

---

## 4. L3 内部与实验性 API（不承诺稳定）

> 下列模块在 v1.0 中视为 **internal / experimental**，可能在小版本内发生破坏性变更，不建议外部直接依赖。

* `gecko.core.telemetry`

  * `GeckoTelemetry`, `TelemetryConfig`, 各种 exporter / 集成
* `gecko.core.tracing`

  * trace_id/span_id 上下文、Span 封装等
* `gecko.core.events`

  * `EventBus`, `BaseEvent`, `AgentRunEvent` 等
* `gecko.plugins.guardrails.*`

  * PII 过滤、内容安全策略等
* `gecko.plugins.knowledge.*`

  * RAG / 知识库相关插件框架
* 其它未在 L1 / L2 清单中出现的模块和符号

示例注释建议：

```python
# NOTE: Internal API. Behavior and signature may change without notice.
```

---

## 5. 版本管理与兼容性策略

### 5.1 版本号规范

* 采用语义化版本号：`MAJOR.MINOR.PATCH`

  * `1.0.0`：核心 API v1.0 首次发布
  * `1.x.y`：在保持 L1 兼容前提下的功能增强与修复
  * `2.0.0`：允许对 L1 做破坏性调整

### 5.2 兼容性承诺

* 对 **L1 API**：

  * v1.x 内不做破坏性改动；
  * 如必须调整，先标记 `@deprecated` 或在文档中标明弃用周期，并提供迁移方案。

* 对 **L2 API**：

  * 尽量保持兼容；
  * 发生变更时，在 CHANGELOG 中明确说明，并给出升级指引。

* 对 **L3 API**：

  * 不提供兼容性承诺；
  * 可以在任何小版本中调整或移除。

### 5.3 文档与测试要求

* 每个 L1 API 对应：

  * 文档示例（本文件 + API Reference）
  * 至少 1 个回归测试用例（import + 基础行为）
* CI 中至少包含：

  * `test_imports`：覆盖所有 `gecko.*` 模块可导入；
  * 核心工作流/多智能体 end-to-end 测试；
  * 结构化输出、Memory 裁剪、输出封装等关键路径测试。

---

## 6. 附录：示例工程与最佳实践（预留）

> TODO：本节可放置一个「最小可运行工程」示例结构，帮助新用户快速上手。

示例目录结构（草案）：

```text
examples/
  ├─ quickstart/
  │   ├─ simple_agent.py
  │   ├─ workflow_demo.py
  │   └─ team_demo.py
  └─ advanced/
      ├─ zhipu_agent.py
      ├─ structured_output_demo.py
      └─ memory_summary_demo.py
```
```

[6] docs/gecko_v0.3_analysis.md
```markdown
# Gecko v0.3 多智能体框架 - 正式系统分析报告

> 文档版本：v0.3 分析正式版  
> 面向对象：Gecko 核心研发团队 / 架构委员会  
> 目标：评估 v0.3 核心代码的稳定性、可维护性与生产可用性，并给出迭代路线建议。

---

## 0. 执行摘要（Executive Summary）

- **总体评价**  
  Gecko v0.3 在整体架构上已经形成较清晰的分层与模块边界：  
  `core` 负责 Agent/Memory/Message/Output 等内核；  
  `compose` 负责 Workflow/Team 编排；  
  `plugins` 提供模型、工具、存储等扩展点。  
  从“实验框架”向“可工程化使用的多智能体内核”迈出了重要一步。

- **关键结论**  
  1. 当前 v0.3 **仍不宜直接标记为生产级版本**：  
     - 存在若干 **阻塞级问题（P0）**，包括部分模块语法错误、Telemetry 导入失败导致相关能力完全不可用。  
  2. 核心业务路径（Agent → Model → Memory → Workflow/Team）整体设计是可行的，但在 **并发一致性、错误处理、类型安全** 上还有改进空间。  
  3. 如果以 v1.0 为目标，在不推翻现有架构的前提下，可以通过 **3 个迭代波次（0.3.1 / 0.3.2 / 1.0）** 有序演进到生产可用状态。

- **建议优先级**  
  - **P0（立即修复）**：语法错误模块、Telemetry 导入失败、部分核心逻辑的潜在一致性问题。  
  - **P1（尽快规划）**：Workflow/Team 行为语义清晰化、Session 并发一致性保护、工具调用错误显式反馈。  
  - **P2（中期演进）**：协议验证统一、Memory 策略优化、工具与插件生态完善、工程化工具链（lint/type-check/CI）。

---

## 一、架构概览

### 1.1 系统定位

Gecko 是一个面向多智能体应用的 Python 框架，目标能力包括：

- 单 Agent 能力封装与统一调用；
- 多步骤工作流（Workflow）与多智能体团队（Team）编排；
- 统一的消息模型（Message）、记忆机制（Memory）、结构化输出（StructureEngine）；
- 扩展友好的模型适配层与工具插件机制；
- 日志、追踪、遥测（Telemetry）与事件（EventBus）体系。

### 1.2 分层架构（逻辑视图）

**1）核心层（Core Layer, `gecko.core`）**

- `agent` / `builder`：Agent 构建与执行内核；
- `message`：统一消息模型（role/content 等）；
- `memory`：Token/摘要记忆机制；
- `output`：AgentOutput/TokenUsage 封装；
- `structure`：结构化输出与 Tool Schema 生成；
- `logging` / `tracing` / `telemetry`：日志与分布式追踪能力；
- `events`：事件总线与框架内部 hook。

**2）编排层（Compose Layer, `gecko.compose`）**

- `workflow`：多步骤流程编排，支持 step/Next 等控制流；
- `team`：多智能体协作策略（如专家组、map-reduce）。

**3）插件层（Plugins Layer, `gecko.plugins`）**

- `models`：模型适配（如 ZhipuChat 等）；
- `tools`：工具声明与封装；
- `storage`：会话、记忆等存储后端；
- `guardrails`：安全与风控；
- `knowledge`：知识/检索相关能力（RAG 等）。

**4）Examples & Tests**

- `examples/` 提供典型用法范例；
- `tests/` 提供单元测试与集成测试（当前覆盖度仍有限）。

---

## 二、问题与风险分析

本节按照严重程度分为：**P0（阻塞级）/ P1（高优先级）/ P2（中低优先级）**。

### 2.1 P0 阻塞级问题（必须在 0.3.1 修复）

#### P0-1：部分模块为非法 Python / 导入即失败

在 v0.3 源码中，存在若干模块内容异常（例如只残留 Markdown 代码块标记 ``` 或文档截断），导致 **`import` 时直接抛出 SyntaxError / unterminated string**。典型包括：

- `gecko/core/telemetry.py`：  
  - 类 `GeckoTelemetry` 的文档字符串中嵌入了示例代码块，但未正确闭合 `"""`；  
  - 部分示例代码疑似以普通 Python 代码形式混入类体中；  
  - 结果是 **整个 telemetry 模块无法导入**，依赖其的任何功能全部失效。

- 部分 `__init__.py` 和插件模块：  
  - 部分模块（例如 plugins 下 guardrails/knowledge/backends 的部分入口）内容仅为残留的 Markdown 代码块标记，无有效 Python 代码；  
  - 一经导入即抛出语法错误。

> 影响：  
> - **Telemetry 能力实际不可用**，与文档描述不一致；  
> - `import gecko` 或导入相关插件时会直接中断，框架整体“观感”明显不稳定；  
> - 任何依赖这些模块的上层功能均无法正常工作。

> 建议：  
> - 在 0.3.1 中补全上述模块内容，至少保证为 **合法 Python + 明确 no-op 行为**；  
> - 示例代码应放入 docstring 文本或 `examples/` 目录，而非混入类体；  
> - 增加 `tests/test_imports.py`，对所有 `gecko.*` 模块做一次 `importlib.import_module` 回归测试，将此作为 CI 守门人。

---

### 2.2 P1 高优先级问题（短期内需规划修复）

#### P1-1：Workflow 首步指针清理逻辑语义不清

**问题描述（简化版）**：

- `_execute_loop` 中使用 `is_first_step` + `clear_pointer_after_first_step` 控制首步执行后是否清除 `next_pointer`；
- 当前实现仅在 `clear_pointer_after_first_step=True` 时将 `is_first_step` 置为 False，逻辑语义混合在一起；
- 条件配置稍有变化就容易产生“首步状态被多次认为是 True”的理解困惑。

**风险**：

- 行为本身未必立刻出错，但对后续维护、扩展（尤其是增加恢复/回放能力）非常不友好；
- 一旦未来引入“中断恢复”的场景，首步逻辑不清晰会成为隐藏坑点。

**建议**：

- 将“首步”与“是否清理指针”的逻辑拆开：
  - 始终在首次循环后 `is_first_step = False`；
  - `clear_pointer_after_first_step` 仅控制是否清理 `next_pointer`，而不影响“首步”的定义；
- 对首步逻辑补充单元测试，覆盖不同配置组合。

---

#### P1-2：Team._resolve_input 类型判断过于宽松（Duck Typing 风险）

**现状**：

- `Team._resolve_input` 通过 `hasattr(x, "state")` + `isinstance(x, dict)` 等组合判断来识别 “看起来像 WorkflowContext 的对象”；
- 这种纯 Duck Typing 方式在短期内好用，但从长期看：

  - 容易误判其他业务对象（只要碰巧有类似属性）；
  - 当 WorkflowContext 后续演变时，这里不易被及时更新和保护。

**风险**：

- 框架使用者如果传入了其他自定义上下文对象，可能被误判为 WorkflowContext，导致行为异常且难以排查。

**建议**：

- 在允许的前提下，直接使用 `isinstance(obj, WorkflowContext)` 进行类型判断；
- 如果为了避免循环依赖，可以把“上下文协议”抽象为一个 Protocol / ABC：
  - 例如 `class ContextLike(Protocol): state: dict; ...`；
  - Team 在内部显式依赖该协议而不是“任意 dict + 任意属性”。

---

#### P1-3：Session.save 的并发一致性存在潜在风险

**现状简化**：

- `Session.save()` 内部会：
  1. 对当前 state 做 snapshot；
  2. 调用 storage.set 进行持久化；
  3. 将 `_dirty` 标记为 False；
- `set()` / `delete()` 等方法在修改 state 时：
  - 会将 `_dirty` 置为 True；
  - 触发异步 auto-save 任务；
  - 但与 `save()` 使用的锁不完全统一，且 `_dirty` 状态存在竞态覆盖风险。

**潜在问题**（典型时序）：

1. T1：调用 `save()`，snapshot 完成，并进入 `await storage.set(...)`；
2. T2：在 storage 写入过程中，另一个协程调用 `set()` 修改 state，设置 `_dirty = True`；
3. T3：`storage.set` 完成后，`save()` 把 `_dirty = False`；
4. 若 auto-save 调度未及时触发，T2 的修改可能不会被持久化。

**建议**：

- 在 Session 内引入版本号或 snapshot compare 机制：
  - `save()` 只在“保存版本仍是最新”时才将 `_dirty` 清零；
  - 或者通过统一锁/队列机制，保证 `set()` / `save()` 串行化执行；
- 增加并发场景的单元测试，利用 asyncio 并发模拟上述时序。

---

#### P1-4：ReActEngine 工具调用错误处理不够显式

**现状**：

- 在工具调用 JSON 解析失败、类型不匹配等场景下，当前实现通常会将错误信息塞入参数（如 `__gecko_parse_error__`），期待工具层或模型层处理；
- 对框架使用者而言：
  - 不容易在日志中直观看到“工具调用参数解析失败”的原因；
  - 问题表现为“工具运行异常/结果怪异”，排查成本较高。

**建议**：

- 在 Tool 调度层增加显式错误分支：
  - 若检测到 `__gecko_parse_error__` 或明显的 JSON/类型错误，直接生成一个结构化的错误 AgentOutput；
  - 日志中输出明确的错误消息、原始参数、对应的 Tool 名称等信息；
- 对该错误路径增加单元测试，以确保后续改动不会“吞掉错误”。

---

#### P1-5：Workflow.validate 在并行模式下完全跳过歧义检测

**现状**：

- 当 `enable_parallel=True` 时，当前 `validate()` 会跳过“多条无条件边冲突”的检测；
- 这可以理解为“并行模式允许 fan-out”，但从用户体验和安全性上看：
  - 用户可能并不明确知道自己配置了多个无条件并行边；
  - 问题只在运行时才体现（例如多节点同时执行、状态写冲突等）。

**建议**：

- 即便在 `enable_parallel=True` 时，也至少：
  - 识别出“多个无条件出边”的情况；
  - 在日志或验证结果中输出 WARNING 级提示；
- 如有必要，可以增加一个更细粒度的配置：  
  - `allow_unconditional_fanout: bool = False`，默认关闭，避免误用。

---

### 2.3 P2 中低优先级问题（建议中期演进）

此类问题不会立刻造成严重错误，但会影响长期演进和维护效率。

#### P2-1：协议验证逻辑分散

- `validate_model`、`validate_storage`、`validate_tool` 等验证逻辑当前分布在不同模块；
- 验证策略和错误信息风格不统一，不利于：
  - 对外文档和错误排查；
  - 后续扩展新的协议类型。

**建议**：

- 在 `gecko/core/protocols` 或类似位置集中设计一个 `ProtocolValidator`：
  - `validate_model(obj)` / `validate_storage(obj)` / `validate_tool(obj)` 统一出口；
  - 错误信息带上 protocol 名称、对象类型、缺失方法列表等。

---

#### P2-2：Memory 策略可配置性与可观测性有提升空间

- TokenMemory / SummaryTokenMemory 已经提供基础的 Token 裁剪与摘要能力；
- 但策略部分（固定保留系统消息、最近 N 轮对话、优先保留工具结果等）尚未结构化配置；
- 当前缺少“裁剪决策”的可观测性（例如日志中看不到被丢弃/保留了哪些消息）。

**建议**：

- 将 Memory 策略参数化，例如：
  - `preserve_system_messages=True`
  - `preserve_recent_rounds=N`
  - `tool_result_weight` 等；
- 在 debug/trace 模式下记录 Memory 裁剪决策，便于调优。

---

#### P2-3：ToolBox / utils 等基础模块缺少系统化测试与文档

- **说明**：与早期分析中“文件缺失”的结论不同，当前 v0.3 源码中 `gecko/core/toolbox.py` 与 `gecko/core/utils.py` 均已存在并可导入；
- 但由于这两个模块是许多功能的基础依赖，其稳定性和行为语义目前依赖阅读代码而非文档/测试。

**建议**：

- 为 ToolBox / utils 编写系统化单元测试：
  - ToolBox：工具注册、参数映射、执行、错误处理等；
  - utils：如 `ensure_awaitable`, `safe_serialize_context` 等关键函数；
- 在文档中明确这些模块的角色与典型用法，以便未来纳入核心公共 API。

---

## 三、优化方向与设计建议

### 3.1 架构层面

1. **核心路径清晰化**  
   - 正式确认以下作为“核心执行路径”：  
     `Agent → ModelAdapter → Memory → Workflow/Team → Output → Telemetry/Logging`  
   - 对这些路径中的模块进行 L1/L2 API 分级管理（核心 API 文档已单独设计，可复用）。

2. **插件边界明确化**  
   - 对 `plugins.models` / `plugins.storage` / `plugins.tools` / `plugins.guardrails` / `plugins.knowledge` 进行角色与稳定性标注；
   - 区分：
     - 对内部服务使用的“内部插件”；
     - 将来可能对外开放的“公共插件接口”。

---

### 3.2 模块层面

**1）Agent & Builder**

- 现有设计基本合理，建议：
  - 明确 `Agent.run` 输入类型（str / Message / list[Message]），避免过度隐式转换；
  - Builder 中链式方法在文档中标记为 v1.0 核心 API，后续尽量保持签名稳定。

**2）Workflow & Team**

- 对 `step` / `Next` 的行为进行正式规范（单独文档章节）；
- 补充对异常传播、取消策略（fail-fast / fail-soft）的描述和实现；
- 对并行执行中的状态读写冲突进行规则约束（例如只允许“读同写不同 key”）。

**3）Telemetry / Tracing / Logging**

- 在 0.3.1 中优先修复 Telemetry 导入问题，使之至少可以启用/关闭而不崩溃；
- 在 0.3.2 中：
  - 明确启用条件（配置/环境变量）；
  - 统一在日志中注入 trace_id / span_id；
  - 对未安装 OpenTelemetry 的环境提供 no-op 实现。

---

### 3.3 工程化层面

- 引入/完善以下工具链：
  - `ruff` + `black`：格式与静态检查；
  - `mypy` / `pyright`：类型检查（当前 type hints 已较丰富，性价比高）；
  - `pre-commit`：本地提交前强制运行基本检查；
  - CI 中增加：
    - `tests/test_imports.py`：所有模块可导入性检查；
    - 核心路径的端到端测试（Agent / Workflow / Team / Memory / StructureEngine）。

---

## 四、生产级版本迭代路线建议

以 **v0.3 → v0.3.1 → v0.3.2 → v1.0.0** 为参考规划。

### 4.1 v0.3.1：阻塞问题修复 & 可导入性保障（P0）

**目标**：保证“所有模块可导入 + 核心路径可跑通 + 缺陷可快速定位”。

关键任务：

1. 修复所有非法 Python 模块与 Telemetry 导入错误；
2. 增加 `tests/test_imports.py`，覆盖全部 `gecko.*`；
3. 梳理 Workflow 首步逻辑（P1-1）并增加测试；
4. 对 Session.save 并发一致性进行最小化修复或加警告（可以分步完成）；
5. 更新 `__version__` 与 Telemetry service_version 等元信息，保持一致。

### 4.2 v0.3.2：行为语义优化 & 工程化增强（P1/P2）

**目标**：使 Gecko 成为“内部项目可放心依赖”的框架。

关键任务：

1. 完成 Team._resolve_input 类型判断调整（改为协议/显式类型）；
2. 完成 Session 并发一致性方案并补充测试；
3. 增强 ReActEngine 错误处理，提供结构化错误输出；
4. Workflow.validate 在并行模式下增加 WARNING 提示；
5. 引入统一的 ProtocolValidator，并对模型/工具/存储验证统一处理；
6. 为 ToolBox / utils 补齐测试与文档。

### 4.3 v1.0.0：核心 API 冻结 & 插件生态起步

**目标**：对外发布稳定的 v1.0 核心 API，并具备基本可扩展生态。

关键任务：

1. 正式发布《Gecko 核心 API v1.0 稳定接口规范》（当前已有草案，可直接迭代）；
2. 将 `gecko` 顶层导出（Agent/Builder/Workflow/Team/Memory 等）标记为 L1 稳定 API；
3. 将模型适配、存储后端、工具定义基类/协议标记为 L2 相对稳定 API；
4. 完成 Telemetry/Tracing 与 Logging 的统一接入与配置；
5. 提供至少一个“生产级”示例工程（如 HTTP API 服务 + 多智能体 Workflow）。

---

## 五、结论与建议

1. **Gecko v0.3 的架构设计总体方向是正确的**：  
   Agent/Workflow/Team/Memory/Output 等核心模块划分清晰，具备演化为生产框架的良好基础。

2. **当前版本尚不具备“直接用于生产环境”的条件**：  
   - 存在阻塞导入的语法问题（Telemetry 等）；  
   - 部分核心逻辑尚未在并发与错误场景下充分验证。

3. **通过 2～3 个小版本迭代，可以平滑升级到 v1.0 稳定内核**：  
   - 0.3.1：聚焦 P0 修复与 import 守门人；  
   - 0.3.2：聚焦行为语义与工程化完善；  
   - 1.0.0：冻结核心 API，统一文档，开启对外生态建设。

> 建议：  
> - 将本报告列为 Gecko v1.0 规划的“技术基线文档”；  
> - 在 Roadmap 中明确标注每条 P0/P1/P2 对应的版本节点与负责人；  
> - 后续对每次版本发布进行回溯检查，确保核心 API 与行为逐步趋于稳定。
```

[7] docs/getting_started.md
```markdown
# 安装与快速开始

## 环境要求

*   Python 3.9+
*   (可选) Redis, ChromaDB, LanceDB 等外部服务

## 安装

Gecko 尚未发布到 PyPI，目前建议通过源码安装：

```bash
git clone https://github.com/your-repo/gecko.git
cd gecko
pip install -e .

# 安装所有可选依赖 (Redis, Vector DBs)
pip install ".[all]"
```

## 配置 API Key

Gecko 使用 `.env` 文件或环境变量管理密钥。在项目根目录创建 `.env`：

```bash
# .env
ZHIPU_API_KEY="your_api_key_here"
OPENAI_API_KEY="your_api_key_here"
# 可选配置
GECKO_LOG_LEVEL="INFO"
```

## Hello World: 你的第一个 Agent

创建一个简单的 Agent，使用智谱 AI 模型并挂载计算器工具。

```python
import asyncio
import os
from gecko.core.builder import AgentBuilder
from gecko.plugins.models import ZhipuChat
from gecko.plugins.tools.standard import CalculatorTool

async def main():
    # 1. 初始化模型
    api_key = os.getenv("ZHIPU_API_KEY")
    model = ZhipuChat(api_key=api_key, model="glm-4-flash")
    
    # 2. 构建 Agent
    agent = (AgentBuilder()
             .with_model(model)
             .with_tools([CalculatorTool()])
             .with_session_id("demo_session")
             .build())

    # 3. 运行 (自动调用计算器工具)
    response = await agent.run("计算 (123 * 45) + 99 的结果")
    print(f"🤖 Agent: {response.content}")

if __name__ == "__main__":
    asyncio.run(main())
```
```

[8] docs/index.md
```markdown
# Gecko Agent Framework 文档

欢迎使用 **Gecko** —— 一个专为生产环境设计的工业级 Python AI 智能体开发框架。

## 🦎 什么是 Gecko?

Gecko 是一个**异步优先 (Async-First)**、**协议驱动 (Protocol-Driven)** 的 Agent 框架。它不追求大而全的“胶水代码”，而是专注于提供一个高可靠、类型安全、可观测的 Agent 运行时环境。

它特别适合构建：
*   高并发的 Agent 后端服务。
*   需要长流程、断点恢复 (Resumable) 的复杂业务流。
*   对数据安全和代码可控性有严格要求的企业级应用。

## 🌟 核心特性

*   **🚀 原生异步**: 基于 `anyio` 构建，核心链路全异步，内置 I/O 线程卸载，杜绝阻塞。
*   **🛡️ 协议驱动**: 通过 Protocol 定义接口，轻松替换底层实现（如从 SQLite 切换到 Redis，从 OpenAI 切换到 Ollama）。
*   **💾 状态持久化**: 支持 Step 级别的状态快照，系统崩溃后可无缝 `resume()`。
*   **🔄 稳健的推理引擎**: 内置死循环检测、观测值智能截断、自动重试机制。
*   **🧩 插件化**: 模块化的 Model, Storage, Tool 设计，支持第三方插件自动发现。

## 🏗️ 系统架构

```mermaid
graph TD
    subgraph "Application Layer"
        WF[Workflow Engine]
        TM[Team Engine]
    end

    subgraph "Core Layer"
        Agent[Agent]
        Engine[Cognitive Engine / ReAct]
        Mem[Token Memory]
    end

    subgraph "Support Layer"
        TB[ToolBox]
        EB[Event Bus]
    end

    subgraph "Plugin Layer"
        MP[Model Protocol]
        SP[Storage Protocol]
        TP[Tool Protocol]
    end

    WF --> Agent
    Agent --> Engine
    Engine --> Mem
    Engine --> TB
    Engine --> MP
    Mem --> SP
    TB --> TP
```

## 下一步

*   👉 [快速开始](getting_started.md): 5分钟跑通第一个 Agent。
*   👉 [核心概念](core_concepts.md): 了解 Gecko 的运作机理。
*   👉 [编排与工作流](orchestration.md): 学习如何构建复杂的 DAG 任务流。
```

[9] docs/orchestration.md
```markdown
# 编排与工作流

当单一 Agent 无法满足需求时，你需要使用 `Workflow` 将多个节点编排成有向无环图 (DAG)。

## Workflow 基础

Workflow 由 **Nodes (节点)** 和 **Edges (边)** 组成。

*   **Node**: 可以是普通函数、Agent 或 Team。
*   **Edge**: 定义节点间的流转，支持条件分支。

```python
from gecko.compose.workflow import Workflow
from gecko.compose.nodes import step, Next

@step("Check")
async def check_input(ctx):
    if len(ctx.input) > 10:
        return Next(node="ProcessLong")
    return Next(node="ProcessShort")

# 定义工作流
wf = Workflow("DemoFlow")
wf.add_node("Check", check_input)
# ... 添加其他节点 ...
wf.set_entry_point("Check")
```

## 状态持久化与断点恢复 (Resumability)

Gecko 支持在系统崩溃或重启后恢复工作流的执行状态。

### Checkpoint 策略
通过 `checkpoint_strategy` 控制保存频率：
*   `ALWAYS`: 每执行完一个节点就保存（最安全，默认）。
*   `FINAL`: 仅在工作流结束时保存。
*   `MANUAL`: 不自动保存。

### 如何恢复 (Resume)

```python
from gecko.plugins.storage.factory import create_storage

# 1. 必须配置持久化存储
storage = await create_storage("sqlite:///./workflow.db")
wf = Workflow(name="ResumableFlow", storage=storage)

# 2. 首次运行 (可能会崩溃)
try:
    await wf.execute(input_data, session_id="user_123")
except Exception:
    print("系统崩溃！")

# 3. 恢复运行
# Gecko 会自动加载 user_123 的状态，跳过已完成的节点
result = await wf.resume(session_id="user_123")
```

## Team (多智能体并行)

`Team` 引擎实现了 Map-Reduce 模式，用于并发执行任务。

```python
from gecko.compose.team import Team

# 创建评审团
team = Team(
    members=[agent_coder, agent_reviewer, agent_manager],
    max_concurrent=2  # 限制并发数，防止 API Rate Limit
)

results = await team.run("评审这段代码...")
```
```

[10] docs/plugins.md
```markdown
# 插件系统

Gecko 采用插件化架构，所有外部依赖（模型、存储、工具）均通过 Protocol 接入。

## Models (模型)

支持通过 `LiteLLM` 接入 100+ 种模型。

### 初始化
```python
from gecko.plugins.models import ZhipuChat, OpenAIChat, OllamaChat

# 智谱 AI
zhipu = ZhipuChat(api_key="...", model="glm-4-air")

# 本地 Ollama
ollama = OllamaChat(model="llama3", base_url="http://localhost:11434")
```

## Storage (存储)

支持多种后端，通过 URL Scheme 自动加载。

| Scheme | Backend | 特性 |
| :--- | :--- | :--- |
| `sqlite://` | SQLite | WAL 模式，支持跨进程文件锁，无需额外服务。 |
| `redis://` | Redis | 高性能，支持 TTL 自动过期。 |
| `chroma://` | ChromaDB | 向量存储，支持 Metadata 过滤。 |
| `lancedb://` | LanceDB | 基于文件的向量库，自动建表。 |

## Tools (工具)

工具必须继承 `BaseTool` 并定义 `args_schema`。

```python
from pydantic import BaseModel, Field
from gecko.plugins.tools.base import BaseTool, ToolResult

class SearchArgs(BaseModel):
    query: str = Field(..., description="查询关键词")

class SearchTool(BaseTool):
    name = "search"
    description = "搜索引擎"
    args_schema = SearchArgs

    async def _run(self, args: SearchArgs) -> ToolResult:
        # 执行逻辑...
        return ToolResult(content="结果...")
```

## Knowledge (RAG)

目前处于预览阶段，提供基础的入库流水线。

*   `IngestionPipeline`: 负责 `Load -> Split -> Embed -> Store` 流程。
*   `RetrievalTool`: 封装了向量检索逻辑的标准工具。
```

[11] docs/system design document.md
```markdown
# Gecko AI Agent Framework 系统设计文档 (SDD)

---

## 【系统目标与边界】

### 1.1 系统概述

**Gecko** 是一个企业级 AI Agent 开发框架，提供从单智能体构建到多智能体编排的完整能力栈。框架采用分层架构设计，实现了模型调用、工具执行、记忆管理、工作流编排的解耦与协同。

### 1.2 核心目标

| 目标维度 | 描述 |
|---------|------|
| **功能目标** | 提供可组合的 Agent 构建原语，支持 ReAct 推理、Tool Use、结构化输出、多模态输入 |
| **架构目标** | 插件化设计，模型/存储/工具均可热插拔；支持本地与云端模型统一接入 |
| **性能目标** | 异步优先架构，支持流式输出、并发工具执行、Token 级延迟优化 |
| **可靠性目标** | 完善的异常体系、断点恢复、状态持久化、死循环检测 |

### 1.3 系统边界

```
┌─────────────────────────────────────────────────────────────────┐
│                        Gecko Framework                          │
├─────────────────────────────────────────────────────────────────┤
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────────┐  │
│  │  Compose    │  │    Core     │  │        Plugins          │  │
│  │  (编排层)    │  │  (核心层)   │  │       (插件层)          │  │
│  │ ─────────── │  │ ─────────── │  │ ─────────────────────── │  │
│  │ • Workflow  │  │ • Agent     │  │ • Models (LiteLLM)      │  │
│  │ • Team      │  │ • Engine    │  │ • Storage (SQLite/Redis)│  │
│  │ • Nodes     │  │ • Memory    │  │ • Tools (Calculator...) │  │
│  └─────────────┘  │ • Message   │  │ • Knowledge (RAG)       │  │
│                   │ • Session   │  └─────────────────────────┘  │
│                   │ • ToolBox   │                               │
│                   │ • Events    │                               │
│                   └─────────────┘                               │
└─────────────────────────────────────────────────────────────────┘
                              ▲
          ┌───────────────────┼───────────────────┐
          │                   │                   │
    ┌─────┴─────┐      ┌──────┴──────┐     ┌─────┴─────┐
    │ LLM APIs  │      │ Vector DBs  │     │ External  │
    │ (OpenAI,  │      │ (Chroma,    │     │  Tools    │
    │  Ollama)  │      │  LanceDB)   │     │  (HTTP)   │
    └───────────┘      └─────────────┘     └───────────┘
```

### 1.4 关键约束

| 约束类型 | 约束内容 |
|---------|---------|
| **技术约束** | Python 3.10+, asyncio 原生支持, Pydantic v2 数据校验 |
| **依赖约束** | 核心依赖: `litellm`, `pydantic`, `anyio`, `sqlmodel`; 可选: `chromadb`, `redis` |
| **协议约束** | 模型层兼容 OpenAI Chat Completion API; 存储层实现 Protocol 接口 |
| **安全约束** | 工具执行沙箱化 (AST 解析); 无远程代码执行能力 |

---

## 【系统参与者与交互】

### 2.1 主要角色

```mermaid
graph LR
    subgraph External
        U[开发者/用户]
        LLM[LLM Provider]
        VS[Vector Store]
        KV[KV Store]
        EXT[External APIs]
    end
    
    subgraph Gecko
        A[Agent]
        W[Workflow]
        T[Team]
    end
    
    U -->|构建/调用| A
    U -->|编排| W
    U -->|并行执行| T
    
    A -->|推理请求| LLM
    A -->|工具调用| EXT
    A -->|状态持久化| KV
    W -->|节点执行| A
    W -->|检索增强| VS
```

### 2.2 核心用例

| 用例ID | 用例名称 | 参与者 | 描述 |
|--------|---------|--------|------|
| UC-01 | 单轮对话 | 开发者, LLM | 构建 Agent 并执行单次问答 |
| UC-02 | 工具调用 | Agent, Tool, LLM | Agent 识别意图后调用工具获取信息 |
| UC-03 | 流式输出 | 用户, Agent | 实时返回生成 Token，降低首字延迟 |
| UC-04 | 结构化提取 | Agent, LLM | 将自然语言转换为 Pydantic 模型 |
| UC-05 | 工作流编排 | 开发者, Workflow | 定义 DAG 节点，实现多步骤任务 |
| UC-06 | 并行执行 | Team, Agents | 多 Agent 并发处理同一任务 |
| UC-07 | 断点恢复 | Workflow, Storage | 从持久化状态恢复中断的工作流 |
| UC-08 | RAG 检索 | Agent, VectorStore | 从知识库检索相关文档增强回答 |

### 2.3 关键时序图

#### UC-02: 工具调用时序

```mermaid
sequenceDiagram
    participant U as User
    participant A as Agent
    participant E as ReActEngine
    participant L as LLM
    participant TB as ToolBox
    participant T as Tool
    
    U->>A: run("今天北京天气?")
    A->>E: step(messages)
    E->>L: acompletion(messages, tools)
    L-->>E: tool_calls: [weather_search]
    E->>TB: execute_many(tool_calls)
    TB->>T: execute({city: "北京"})
    T-->>TB: ToolResult(content="晴,25°C")
    TB-->>E: [ToolExecutionResult]
    E->>L: acompletion(messages + tool_result)
    L-->>E: "北京今天天气晴朗,气温25°C"
    E-->>A: AgentOutput
    A-->>U: "北京今天天气晴朗,气温25°C"
```

---

## 【系统架构设计】

### 3.1 分层架构

```
┌────────────────────────────────────────────────────────────────────┐
│                         Application Layer                          │
│                    (用户代码 / Workflow 定义)                        │
├────────────────────────────────────────────────────────────────────┤
│                         Compose Layer                              │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────────────────┐  │
│  │   Workflow   │  │     Team     │  │     Nodes (step)         │  │
│  │  DAG 引擎    │  │  并行执行器   │  │   节点装饰器/控制流       │  │
│  └──────────────┘  └──────────────┘  └──────────────────────────┘  │
├────────────────────────────────────────────────────────────────────┤
│                          Core Layer                                │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────────┐  │
│  │  Agent  │ │ Engine  │ │ Memory  │ │ToolBox │ │   Events    │  │
│  │ 智能体  │ │ 推理引擎 │ │ 记忆管理 │ │工具箱  │ │  事件总线   │  │
│  └─────────┘ └─────────┘ └─────────┘ └─────────┘ └─────────────┘  │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────────────────────┐  │
│  │ Message │ │ Output  │ │ Session │ │      Protocols          │  │
│  │ 消息模型 │ │ 输出模型 │ │ 会话管理 │ │    接口协议定义          │  │
│  └─────────┘ └─────────┘ └─────────┘ └─────────────────────────┘  │
├────────────────────────────────────────────────────────────────────┤
│                         Plugin Layer                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌──────────┐  │
│  │   Models    │  │   Storage   │  │    Tools    │  │Knowledge │  │
│  │ LiteLLM驱动 │  │ SQLite/Redis│  │ 标准工具库   │  │ RAG管道  │  │
│  └─────────────┘  └─────────────┘  └─────────────┘  └──────────┘  │
├────────────────────────────────────────────────────────────────────┤
│                       Infrastructure Layer                         │
│          (LiteLLM / SQLAlchemy / ChromaDB / Redis Client)          │
└────────────────────────────────────────────────────────────────────┘
```

### 3.2 核心模块依赖关系

```mermaid
graph TB
    subgraph Compose
        WF[Workflow]
        TM[Team]
        ND[Nodes]
    end
    
    subgraph Core
        AG[Agent]
        BD[AgentBuilder]
        EG[CognitiveEngine]
        RE[ReActEngine]
        MM[TokenMemory]
        TB[ToolBox]
        MS[Message]
        OP[AgentOutput]
        SS[Session]
        EB[EventBus]
        ST[StructureEngine]
    end
    
    subgraph Plugins
        MD[Models/LiteLLM]
        SR[Storage/SQLite]
        TL[Tools/Standard]
        KN[Knowledge/RAG]
    end
    
    WF --> AG
    WF --> TM
    WF --> ND
    TM --> AG
    
    AG --> BD
    BD --> EG
    BD --> MM
    BD --> TB
    
    EG --> RE
    RE --> MD
    RE --> TB
    RE --> ST
    
    MM --> SR
    SS --> SR
    
    TB --> TL
    KN --> SR
```

---

## 【模块功能定义】

### 4.1 Core 层模块

#### 4.1.1 Agent (`gecko/core/agent.py`)

| 属性/方法 | 类型 | 说明 |
|-----------|------|------|
| `model` | ModelProtocol | 注入的 LLM 模型 |
| `toolbox` | ToolBox | 工具集合 |
| `memory` | TokenMemory | Token 感知记忆 |
| `engine` | CognitiveEngine | 推理引擎 (默认 ReAct) |
| `run(messages)` | async | 单次推理入口 |
| `stream(messages)` | async generator | 流式推理入口 |

**输入**: `str | Message | List[Message] | dict`
**输出**: `AgentOutput | BaseModel` (结构化)

#### 4.1.2 ReActEngine (`gecko/core/engine/react.py`)

```
核心职责:
1. Thought-Action-Observation 循环
2. 工具调用解析与执行
3. 死循环检测 (Hash-based)
4. 观测值截断 (防 Context 溢出)
5. 结构化输出解析与重试
```

| 关键参数 | 默认值 | 说明 |
|---------|--------|------|
| `max_turns` | 5 | 最大推理轮数 |
| `max_observation_length` | 2000 | 工具输出最大字符 |
| `system_prompt` | 内置模板 | 可自定义 Jinja2 模板 |

#### 4.1.3 TokenMemory (`gecko/core/memory.py`)

```python
# 核心算法: 滑动窗口 + LRU 缓存
class TokenMemory:
    def get_history(raw_messages, preserve_system) -> List[Message]:
        """
        1. 解析消息列表
        2. 分离 System Prompt
        3. 反向累积直到达到 max_tokens
        4. 返回时间正序的消息列表
        """
```

**缓存策略**: MD5(message_content) → token_count

#### 4.1.4 ToolBox (`gecko/core/toolbox.py`)

| 功能 | 实现方式 |
|------|---------|
| 工具注册 | `add_tool(tool: BaseTool \| str)` |
| 单次执行 | `execute(name, arguments)` |
| 批量并发 | `execute_many(tool_calls)` + Semaphore |
| Schema 生成 | `to_openai_schema()` |
| 执行统计 | 线程安全的计数器 |

#### 4.1.5 EventBus (`gecko/core/events/bus.py`)

```python
# 发布-订阅模式
bus.subscribe("run_completed", handler)
await bus.publish(AgentRunEvent(type="run_completed", data=...))

# 支持中间件
bus.add_middleware(logging_middleware)
```

### 4.2 Compose 层模块

#### 4.2.1 Workflow (`gecko/compose/workflow.py`)

| 核心概念 | 说明 |
|---------|------|
| Node | 可调用对象 (函数/Agent/Team) |
| Edge | 节点间连接，支持条件分支 |
| Context | 执行上下文，含 state/history |
| Next | 动态跳转指令 |

**状态持久化策略**:
```python
class CheckpointStrategy(Enum):
    ALWAYS = "always"   # 每步保存
    FINAL = "final"     # 仅结束保存
    MANUAL = "manual"   # 手动控制
```

**断点恢复流程**:
```
resume(session_id)
  ├─ 加载 saved_data
  ├─ 重建 WorkflowContext
  ├─ 检查 next_pointer (动态跳转)
  ├─ 或基于静态图推导下一节点
  └─ 继续 _execute_loop
```

#### 4.2.2 Team (`gecko/compose/team.py`)

```python
# Map-Reduce 并行模式
team = Team(members=[agent1, agent2, func], max_concurrent=3)
results: List[MemberResult] = await team.run(input_data)

# 返回结构
class MemberResult:
    result: Any
    error: Optional[str]
    member_index: int
    is_success: bool
```

### 4.3 Plugin 层模块

#### 4.3.1 Models (`gecko/plugins/models/`)

```
架构: Config → Factory → Registry → Driver

ModelConfig
    ├─ model_name: str
    ├─ driver_type: str ("litellm")
    ├─ api_key / base_url
    └─ supports_*: bool (能力标识)

LiteLLMDriver (implements ModelProtocol)
    ├─ acompletion(messages) → CompletionResponse
    ├─ astream(messages) → AsyncIterator[StreamChunk]
    └─ count_tokens(text) → int
```

**预设模型**:
- `OpenAIChat`, `OpenAIEmbedder`
- `OllamaChat`, `OllamaEmbedder`
- `ZhipuChat`

#### 4.3.2 Storage (`gecko/plugins/storage/`)

```
接口层:
├─ SessionInterface (KV 存储)
│   ├─ get(session_id) → Dict
│   ├─ set(session_id, state)
│   └─ delete(session_id)
│
└─ VectorInterface (向量存储)
    ├─ upsert(documents)
    └─ search(query_embedding, top_k, filters)

实现层:
├─ SQLiteStorage (SessionInterface)
├─ RedisStorage (SessionInterface)
├─ ChromaStorage (VectorInterface + SessionInterface)
└─ LanceDBStorage (VectorInterface)
```

**Mixin 设计**:
- `ThreadOffloadMixin`: 同步 IO 卸载到线程池
- `AtomicWriteMixin`: 协程锁 + 文件锁 (跨进程)
- `JSONSerializerMixin`: 标准序列化

#### 4.3.3 Tools (`gecko/plugins/tools/`)

```python
# 工具定义范式
class MyArgs(BaseModel):
    param: str = Field(..., description="参数说明")

@register_tool("my_tool")
class MyTool(BaseTool):
    name = "my_tool"
    description = "工具描述"
    args_schema = MyArgs
    
    async def _run(self, args: MyArgs) -> ToolResult:
        return ToolResult(content="结果")
```

**内置工具**:
| 工具名 | 功能 | 安全措施 |
|--------|------|---------|
| `calculator` | 数学计算 | AST 白名单解析 |
| `duckduckgo_search` | 网页搜索 | 输入长度限制 |

---

## 【AI模块设计】

### 5.1 模型调用链路

```mermaid
graph LR
    subgraph Application
        A[Agent.run]
    end
    
    subgraph Engine
        E[ReActEngine.step]
        S[StructureEngine.parse]
    end
    
    subgraph ModelLayer
        D[LiteLLMDriver]
        AD[LiteLLMAdapter]
    end
    
    subgraph External
        L[LiteLLM SDK]
        API[OpenAI/Ollama API]
    end
    
    A --> E
    E --> D
    D --> L
    L --> API
    API --> L
    L --> AD
    AD --> D
    D --> E
    E --> S
    S --> E
    E --> A
```

### 5.2 推理闭环设计

```
┌─────────────────────────────────────────────────────────────┐
│                    ReAct Loop (max_turns)                   │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────┐    ┌─────────┐    ┌─────────┐    ┌─────────┐  │
│  │ Context │───▶│  LLM    │───▶│ Parse   │───▶│ Decision│  │
│  │ Build   │    │ Call    │    │Response │    │         │  │
│  └─────────┘    └─────────┘    └─────────┘    └────┬────┘  │
│       ▲                                            │        │
│       │         ┌──────────────────────────────────┼────┐   │
│       │         ▼                                  ▼    │   │
│       │    ┌─────────┐                        ┌────────┐│   │
│       │    │  Tool   │◀── has_tool_calls ────│ Return ││   │
│       │    │ Execute │                        │ Output ││   │
│       │    └────┬────┘                        └────────┘│   │
│       │         │                                  ▲    │   │
│       │         ▼                                  │    │   │
│       │    ┌─────────┐                             │    │   │
│       └────│  Add    │─────── no_tool_calls ───────┘    │   │
│            │ Results │                                  │   │
│            └─────────┘                                  │   │
│                                                         │   │
│  ┌──────────────────────────────────────────────────────┘   │
│  │ Safety Checks:                                           │
│  │ • 死循环检测 (Hash 比对)                                  │
│  │ • 连续错误计数                                            │
│  │ • 观测值截断                                              │
│  └──────────────────────────────────────────────────────────┘
└─────────────────────────────────────────────────────────────┘
```

### 5.3 结构化输出策略

```python
# 策略优先级
1. Tool Call 提取 (OpenAI Function Calling)
   └─ 从 tool_calls[].function.arguments 解析 JSON

2. Markdown 代码块提取
   └─ 正则匹配 ```json ... ```

3. 暴力括号匹配
   └─ 栈匹配 {...} 块，按长度排序

4. JSON 清洗 + 重试
   └─ 移除注释、修复尾逗号
```

### 5.4 Token 管理策略

```
TokenMemory 工作流:
                                    
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│ Raw Messages│───▶│ Count Tokens│───▶│ Sliding     │
│ from Storage│    │ (LRU Cache) │    │ Window      │
└─────────────┘    └─────────────┘    └─────────────┘
                          │                   │
                          ▼                   ▼
                   ┌─────────────┐    ┌─────────────┐
                   │ tiktoken /  │    │ [System] +  │
                   │ Driver.count│    │ [Recent N]  │
                   └─────────────┘    └─────────────┘
```

---

## 【数据设计】

### 6.1 核心数据实体

```mermaid
erDiagram
    Message {
        string role
        string content
        string name
        array tool_calls
        string tool_call_id
    }
    
    AgentOutput {
        string content
        array tool_calls
        object usage
        object raw
    }
    
    WorkflowContext {
        string execution_id
        any input
        dict state
        dict history
        dict metadata
        array executions
        dict next_pointer
    }
    
    NodeExecution {
        string node_name
        enum status
        any input_data
        any output_data
        string error
        float start_time
        float end_time
    }
    
    SessionMetadata {
        string session_id
        float created_at
        float updated_at
        int access_count
        int ttl
        set tags
    }
    
    ToolResult {
        string content
        bool is_error
        dict metadata
    }
    
    WorkflowContext ||--o{ NodeExecution : contains
    Message ||--o{ ContentBlock : has
```

### 6.2 存储 Schema

#### SQLite Session 表
```sql
CREATE TABLE gecko_sessions (
    session_id TEXT PRIMARY KEY,
    state_json TEXT NOT NULL DEFAULT '{}'
);

-- 启用 WAL 模式
PRAGMA journal_mode=WAL;
PRAGMA synchronous=NORMAL;
```

#### ChromaDB Collection Schema
```python
# Vector Collection
collection.upsert(
    ids=["doc_1", "doc_2"],
    embeddings=[[0.1, 0.2, ...], [0.3, 0.4, ...]],
    metadatas=[{"source": "file.txt"}, {"source": "file2.txt"}],
    documents=["text content 1", "text content 2"]
)

# Session Collection (JSON in documents)
session_collection.upsert(
    ids=["session_123"],
    documents=['{"state": {...}, "metadata": {...}}']
)
```

### 6.3 数据流转图

```
User Input
    │
    ▼
┌───────────────────────────────────────────────────────┐
│ Agent._normalize_messages()                           │
│   str → Message.user(text)                            │
│   dict → Message(**dict) or Message.user(dict[input]) │
│   List[dict] → [Message(**d) for d in list]           │
└───────────────────────────────────────────────────────┘
    │
    ▼
┌───────────────────────────────────────────────────────┐
│ TokenMemory.get_history()                             │
│   Load from Storage → Parse → Count → Sliding Window  │
└───────────────────────────────────────────────────────┘
    │
    ▼
┌───────────────────────────────────────────────────────┐
│ ReActEngine._build_execution_context()                │
│   [System] + [History] + [Input] → ExecutionContext   │
└───────────────────────────────────────────────────────┘
    │
    ▼
┌───────────────────────────────────────────────────────┐
│ LLM Call (acompletion / astream)                      │
│   messages → LiteLLM → Response → LiteLLMAdapter      │
└───────────────────────────────────────────────────────┘
    │
    ▼
┌───────────────────────────────────────────────────────┐
│ Tool Execution (if tool_calls present)                │
│   tool_calls → ToolBox.execute_many → ToolResult[]    │
└───────────────────────────────────────────────────────┘
    │
    ▼
┌───────────────────────────────────────────────────────┐
│ AgentOutput Construction                              │
│   content + tool_calls + usage → AgentOutput          │
└───────────────────────────────────────────────────────┘
    │
    ▼
┌───────────────────────────────────────────────────────┐
│ Storage Persistence                                   │
│   Session.save() → Storage.set(session_id, state)     │
└───────────────────────────────────────────────────────┘
```

---

## 【接口设计】

### 7.1 协议接口 (Protocol)

#### ModelProtocol
```python
@runtime_checkable
class ModelProtocol(Protocol):
    async def acompletion(
        self, 
        messages: List[Dict[str, Any]], 
        **kwargs
    ) -> CompletionResponse: ...
    
    def count_tokens(
        self, 
        text_or_messages: str | List[Dict[str, Any]]
    ) -> int: ...
```

#### StreamableModelProtocol
```python
@runtime_checkable
class StreamableModelProtocol(ModelProtocol, Protocol):
    async def astream(
        self, 
        messages: List[Dict[str, Any]], 
        **kwargs
    ) -> AsyncIterator[StreamChunk]: ...
```

#### SessionInterface
```python
@runtime_checkable
class SessionInterface(Protocol):
    async def get(self, session_id: str) -> Optional[Dict[str, Any]]: ...
    async def set(self, session_id: str, state: Dict[str, Any]) -> None: ...
    async def delete(self, session_id: str) -> None: ...
```

#### VectorInterface
```python
@runtime_checkable
class VectorInterface(Protocol):
    async def upsert(self, documents: List[Dict[str, Any]]) -> None: ...
    async def search(
        self, 
        query_embedding: List[float], 
        top_k: int = 5,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]: ...
```

### 7.2 公开 API

#### Agent API
```python
# 构建
agent = (
    AgentBuilder()
    .with_model(OpenAIChat(api_key="..."))
    .with_tools([CalculatorTool(), DuckDuckGoSearchTool()])
    .with_storage(await create_storage("sqlite:///data.db"))
    .with_session_id("user_123")
    .with_system_prompt("You are a helpful assistant.")
    .build()
)

# 执行
output: AgentOutput = await agent.run("1+1等于多少?")
print(output.content)  # "1+1等于2"

# 流式
async for chunk in agent.stream("讲个故事"):
    print(chunk, end="", flush=True)

# 结构化输出
class Answer(BaseModel):
    result: int
    
output: Answer = await agent.run("1+1=?", response_model=Answer)
print(output.result)  # 2
```

#### Workflow API
```python
# 定义
workflow = Workflow(name="ReviewPipeline", storage=storage)
workflow.add_node("analyze", analyze_agent)
workflow.add_node("review", review_agent)
workflow.add_node("approve", approve_func)

workflow.add_edge("analyze", "review")
workflow.add_edge("review", "approve", condition=lambda ctx: ctx.state.get("score") > 80)

workflow.set_entry_point("analyze")

# 执行
result = await workflow.execute("Review this document", session_id="wf_001")

# 恢复
result = await workflow.resume(session_id="wf_001")
```

#### Storage API
```python
# 创建存储
storage = await create_storage("sqlite:///./data.db")
storage = await create_storage("redis://localhost:6379?ttl=3600")
storage = await create_storage("chroma:///./chroma_db?collection=docs")

# 使用
await storage.set("key", {"data": "value"})
data = await storage.get("key")
await storage.delete("key")

# 向量搜索
results = await vector_store.search(
    query_embedding=[0.1, 0.2, ...],
    top_k=5,
    filters={"source": "doc.pdf"}
)
```

### 7.3 事件接口

```python
# 订阅事件
bus = EventBus()
bus.subscribe("run_started", lambda e: print(f"Started: {e.data}"))
bus.subscribe("tool_execution_start", handle_tool_start)
bus.subscribe("*", global_logger)  # 通配符

# 事件类型
| 事件类型 | 触发时机 | 数据内容 |
|---------|---------|---------|
| run_started | Agent.run 开始 | input_count |
| run_completed | Agent.run 完成 | output |
| run_error | Agent.run 异常 | error |
| stream_started | stream 开始 | - |
| tool_execution_start | 工具执行前 | tools[] |
| tool_execution_end | 工具执行后 | result_count |
| node_started | Workflow 节点开始 | node |
| node_completed | Workflow 节点完成 | node, duration |
| workflow_completed | Workflow 完成 | summary |
```

---

## 【系统流程图】

### 8.1 Agent 执行流程

```mermaid
flowchart TD
    A[开始: Agent.run] --> B[输入标准化]
    B --> C[加载历史记录]
    C --> D[构建执行上下文]
    D --> E[调用 LLM]
    E --> F{有工具调用?}
    
    F -->|是| G[执行工具]
    G --> H[添加工具结果到上下文]
    H --> I{达到最大轮数?}
    I -->|否| E
    I -->|是| J[构建输出]
    
    F -->|否| J
    J --> K{需要结构化?}
    K -->|是| L[解析为 Pydantic]
    K -->|否| M[返回 AgentOutput]
    L --> M
    M --> N[保存上下文]
    N --> O[结束]
```

### 8.2 Workflow 执行流程

```mermaid
flowchart TD
    A[开始: Workflow.execute] --> B[验证 DAG 结构]
    B --> C[初始化 WorkflowContext]
    C --> D[Pre-Commit 持久化]
    D --> E[执行当前节点]
    
    E --> F{返回 Next?}
    F -->|是| G[处理动态跳转]
    G --> H[更新 next_pointer]
    H --> I[持久化状态]
    
    F -->|否| J[更新 history]
    J --> K[查找静态下一节点]
    K --> I
    
    I --> L{有下一节点?}
    L -->|是| M{超过 max_steps?}
    M -->|否| E
    M -->|是| N[抛出超限错误]
    
    L -->|否| O[最终持久化]
    O --> P[返回 last_output]
    P --> Q[结束]
```

### 8.3 工具执行并发流程

```mermaid
flowchart TD
    A[ToolBox.execute_many] --> B[初始化 Semaphore]
    B --> C[创建 TaskGroup]
    
    subgraph 并发执行
        C --> D1[Worker 1]
        C --> D2[Worker 2]
        C --> D3[Worker N]
        
        D1 --> E1[获取信号量]
        D2 --> E2[获取信号量]
        D3 --> E3[获取信号量]
        
        E1 --> F1[execute_with_result]
        E2 --> F2[execute_with_result]
        E3 --> F3[execute_with_result]
        
        F1 --> G1[释放信号量]
        F2 --> G2[释放信号量]
        F3 --> G3[释放信号量]
    end
    
    G1 & G2 & G3 --> H[聚合结果]
    H --> I[返回 List of ToolExecutionResult]
```

---

## 【非功能性分析】

### 9.1 性能指标

| 指标 | 目标值 | 实现方式 |
|------|-------|---------|
| **首字延迟 (TTFT)** | < 500ms | 流式输出 + 直接透传 |
| **Token 计数缓存命中率** | > 80% | LRU 缓存 + MD5 Key |
| **工具并发数** | 可配置 (默认5) | Semaphore 控制 |
| **存储 IO 阻塞** | 0 (主线程) | ThreadOffloadMixin |
| **Workflow 恢复时间** | < 1s | 增量状态 + next_pointer |

### 9.2 安全策略

| 风险点 | 缓解措施 |
|-------|---------|
| **代码注入 (Calculator)** | AST 白名单解析，禁止属性访问/下标 |
| **Prompt 注入** | 工具输出截断 (max_observation_length) |
| **API Key 泄露** | Config 对象封装，不序列化敏感字段 |
| **DoS 攻击** | 表达式长度限制、指数上限、搜索结果数限制 |
| **并发写冲突** | AtomicWriteMixin (协程锁 + 文件锁) |

### 9.3 可扩展性设计

```
扩展点:
├─ 模型扩展
│   ├─ 实现 ModelProtocol
│   └─ 使用 @register_driver 注册
│
├─ 存储扩展
│   ├─ 继承 AbstractStorage
│   ├─ 实现 SessionInterface / VectorInterface
│   └─ 使用 @register_storage 注册
│
├─ 工具扩展
│   ├─ 继承 BaseTool
│   ├─ 定义 args_schema
│   └─ 使用 @register_tool 注册
│
└─ 引擎扩展
    ├─ 继承 CognitiveEngine
    └─ 重写 step / step_stream
```

### 9.4 容错机制

| 场景 | 处理方式 |
|------|---------|
| LLM API 超时 | 可配置 timeout + 重试 (enable_retry) |
| 工具执行失败 | 返回 ToolResult(is_error=True)，反馈给 LLM |
| 连续工具错误 | 3 次后注入警告消息 |
| 推理死循环 | Hash 检测 + 强制中断 + 警告注入 |
| Workflow 中断 | Pre-Commit 持久化 + next_pointer 恢复 |
| 存储连接失败 | 初始化时抛出 StorageError |

---

## 【风险与建议】

### 10.1 已识别风险

| 风险ID | 风险描述 | 严重度 | 缓解建议 |
|--------|---------|--------|---------|
| R-01 | LiteLLM 依赖的 Pydantic 兼容性问题 | 中 | 已通过 LiteLLMAdapter 手动映射解决 |
| R-02 | SQLite 多进程并发写入冲突 | 高 | 已引入 FileLock，建议生产环境使用 PostgreSQL |
| R-03 | Token 计数与实际模型不一致 | 低 | 注入 model_driver，优先使用模型层计数 |
| R-04 | Workflow 状态序列化失败 | 中 | safe_serialize_context 处理不可序列化对象 |
| R-05 | 工具执行超时堆积 | 中 | Semaphore 限流，建议监控队列深度 |

### 10.2 架构优化建议

1. **可观测性增强**
   - 集成 OpenTelemetry Tracing
   - 添加 Prometheus Metrics 导出
   - 结构化日志增加 trace_id

2. **缓存层优化**
   - Token 计数缓存可考虑 Redis 共享
   - 工具 Schema 预编译缓存

3. **模型层增强**
   - 添加 Fallback 模型配置
   - 支持模型路由 (Router)
   - 添加请求限流 (Rate Limiter)

4. **存储层优化**
   - 添加连接池管理
   - 支持读写分离 (PostgreSQL)
   - 向量存储分片支持

---

## 【总结与交付建议】

### 11.1 设计完备性评估

| 维度 | 完备度 | 说明 |
|------|-------|------|
| 功能覆盖 | ⭐⭐⭐⭐⭐ | Agent/Workflow/RAG 完整 |
| 接口设计 | ⭐⭐⭐⭐⭐ | Protocol 清晰，扩展性强 |
| 错误处理 | ⭐⭐⭐⭐ | 异常体系完善，部分边界需加强 |
| 可测试性 | ⭐⭐⭐⭐ | 依赖注入良好，Mock 友好 |
| 文档完备 | ⭐⭐⭐ | 代码注释充分，需补充用户文档 |

### 11.2 开发优先级建议

```
Phase 1 (核心稳定):
├─ 补充单元测试覆盖率至 80%+
├─ 完善 Agent/Engine 边界测试
└─ 添加集成测试 (端到端)

Phase 2 (生产就绪):
├─ 添加 OpenTelemetry 集成
├─ PostgreSQL 存储后端
├─ 模型 Fallback 机制
└─ 用户文档 & Cookbook

Phase 3 (高级特性):
├─ 分布式 Workflow 支持
├─ Agent 记忆压缩 (Summary)
├─ 多模态工具支持
└─ GUI 编排界面
```

### 11.3 依赖项清单

```toml
[dependencies]
# 核心
python = ">=3.10"
pydantic = ">=2.0"
anyio = ">=4.0"
litellm = ">=1.40"
jinja2 = ">=3.0"

# 存储
sqlmodel = ">=0.0.14"
sqlalchemy = ">=2.0"

# 可选
redis = { version = ">=5.0", optional = true }
chromadb = { version = ">=0.4", optional = true }
lancedb = { version = ">=0.4", optional = true }
tiktoken = { version = ">=0.5", optional = true }
structlog = { version = ">=23.0", optional = true }
filelock = { version = ">=3.0", optional = true }
```
```

