[1] gecko/__init__.py
```python
# gecko/__init__.py
from __future__ import annotations

from gecko.core.agent import Agent
from gecko.core.builder import AgentBuilder
from gecko.core.message import Message

# 自动清理 LiteLLM 异步客户端，彻底消除 RuntimeWarning
import atexit
import asyncio
import litellm # type: ignore

def _cleanup_litellm():
    async def _close():
        try:
            if hasattr(litellm, "async_http_handler") and litellm.async_http_handler:
                await litellm.async_http_handler.client.close()
        except:
            pass
    try:
        asyncio.run(_close())
    except:
        pass

atexit.register(_cleanup_litellm)

__version__ = "0.1.0"
__all__ = ["Agent", "AgentBuilder", "Message"]
```

[2] gecko/compose/__init__.py
```python
# gecko/compose/__init__.py
"""
Gecko Compose 模块

提供多智能体编排能力：
- Workflow: DAG 工作流引擎
- Team: 并行多智能体执行
- step: 节点装饰器
- ensure_awaitable: 同步/异步统一调用工具
- Next: 控制流指令
"""
from gecko.compose.workflow import Workflow
from gecko.compose.team import Team
from gecko.compose.nodes import step, ensure_awaitable, Next

__all__ = ["Workflow", "Team", "step", "ensure_awaitable", "Next"]
```

[3] gecko/compose/nodes.py
```python
# gecko/compose/nodes.py
from __future__ import annotations
import asyncio
from typing import Any, Callable, List, Optional
from pydantic import BaseModel

# [新增] 控制流指令
class Next(BaseModel):
    """
    节点返回值指令：明确指示 Workflow 跳转到下一个节点
    """
    node: str
    input: Optional[Any] = None  # 可选：修改传递给下个节点的输入

# [保留] 辅助函数
async def ensure_awaitable(func: Callable, *args, **kwargs) -> Any:
    if asyncio.iscoroutinefunction(func):
        return await func(*args, **kwargs)
    result = func(*args, **kwargs)
    if asyncio.iscoroutine(result):
        return await result
    return result

# [保留] 装饰器 (略微简化，适配新机制)
def step(name: Optional[str] = None):
    def decorator(func: Callable):
        func._is_step = True
        func._step_name = name or func.__name__
        return func
    return decorator

# Loop 和 Parallel 可以暂时保留，但在新引擎中可能不再作为特殊节点，
# 而是作为普通节点内部的逻辑，或者通过 Next 实现循环。
# 为了兼容性，我们暂且保留原定义，但建议后续通过 Next 实现循环。
```

[4] gecko/compose/team.py
```python
# gecko/compose/team.py
from __future__ import annotations
import asyncio
import anyio
from typing import List, Any, Dict, Union
from gecko.core.agent import Agent
# 假设 WorkflowContext 在运行时作为 Any 传入，这里做 duck typing

class Team:
    """
    并行执行多个 Agent，聚合结果
    """
    def __init__(self, members: List[Agent]):
        self.members = members

    # [新增] __call__ 方法，使 Team 实例可被直接调用，满足 Workflow 节点协议
    async def __call__(self, context_or_input: Any) -> List[Any]:
        """
        允许 Team 实例像函数一样被调用：await team(context)
        """
        return await self.execute(context_or_input)

    async def execute(self, context_or_input: Any) -> List[Any]:
        """
        执行 Team 逻辑
        """
        # 解析输入：兼容直接传值或 WorkflowContext 对象
        # 使用 getattr 避免循环导入 WorkflowContext 定义
        if hasattr(context_or_input, "history") and hasattr(context_or_input, "input"):
            # 是 WorkflowContext，尝试获取上一步输出，否则取全局 input
            history = getattr(context_or_input, "history", {})
            inp = history.get("last_output", getattr(context_or_input, "input", None))
        else:
            inp = context_or_input

        results = [None] * len(self.members)

        async def _run_one(idx, agent):
            # Agent.run 现在健壮地处理 str 或 Message
            res = await agent.run(inp)
            results[idx] = res.content

        # 并发执行
        async with anyio.create_task_group() as tg:
            for idx, agent in enumerate(self.members):
                tg.start_soon(_run_one, idx, agent)

        return results
```

[5] gecko/compose/workflow.py
```python
# gecko/compose/workflow.py  
"""  
Workflow 引擎（优化版）  
  
核心改进：  
1. 节点执行结果统一标准化，避免下游/持久化因类型不一致出错  
2. `Next` 控制流可携带自定义输入，自动注入到下一个节点  
3. 工作流上下文持久化使用安全序列化方法（pydantic_encoder）  
4. Agent / Team / 普通函数节点统一接收 WorkflowContext，行为更一致  
5. 状态持久化抽象成独立方法，捕获异常以免影响主流程  
"""  
  
from __future__ import annotations  
  
import asyncio  
import inspect  
import time  
from dataclasses import dataclass, field  
from enum import Enum  
from typing import Any, Callable, Dict, List, Optional, Set, Tuple  
  
from pydantic import BaseModel  
from pydantic.json import pydantic_encoder  
  
from gecko.compose.nodes import Next  
from gecko.core.agent import Agent  
from gecko.core.events import BaseEvent, EventBus  
from gecko.core.exceptions import WorkflowCycleError, WorkflowError  
from gecko.core.logging import get_logger  
from gecko.core.message import Message  
from gecko.core.utils import ensure_awaitable  
from gecko.plugins.storage.interfaces import SessionInterface  
  
logger = get_logger(__name__)  
  
  
# ========================= 事件定义 =========================  
class WorkflowEvent(BaseEvent):  
    """Workflow 专用事件对象，可被外部订阅"""  
    pass  
  
  
# ========================= 节点执行记录 =========================  
class NodeStatus(Enum):  
    PENDING = "pending"  
    RUNNING = "running"  
    SUCCESS = "success"  
    FAILED = "failed"  
    SKIPPED = "skipped"  
  
  
@dataclass  
class NodeExecution:  
    """单个节点的执行记录（方便追踪和可视化）"""  
    node_name: str  
    status: NodeStatus = NodeStatus.PENDING  
    input_data: Any = None  
    output_data: Any = None  
    error: Optional[str] = None  
    start_time: float = 0.0  
    end_time: float = 0.0  
  
    @property  
    def duration(self) -> float:  
        return max(0.0, self.end_time - self.start_time)  
  
  
# ========================= 工作流上下文 =========================  
@dataclass  
class WorkflowContext:  
    """  
    工作流执行过程中共享的上下文对象  
    - input: 初始输入  
    - state: 节点之间共享的状态（开发者可自由使用）  
    - history: 每个节点的输出以及 last_output  
    - metadata: 附加信息（如 session_id、external trace id 等）  
    - executions: 节点执行详情列表  
    """  
    input: Any  
    state: Dict[str, Any] = field(default_factory=dict)  
    history: Dict[str, Any] = field(default_factory=dict)  
    metadata: Dict[str, Any] = field(default_factory=dict)  
    executions: List[NodeExecution] = field(default_factory=list)  
  
    def add_execution(self, execution: NodeExecution):  
        self.executions.append(execution)  
  
    def get_execution_summary(self) -> Dict[str, Any]:  
        total_time = sum(e.duration for e in self.executions)  
        status_counts = {  
            status.value: sum(1 for e in self.executions if e.status == status)  
            for status in NodeStatus  
        }  
        return {  
            "total_nodes": len(self.executions),  
            "total_time": total_time,  
            "status_counts": status_counts,  
            "node_details": [  
                {  
                    "name": e.node_name,  
                    "status": e.status.value,  
                    "duration": e.duration,  
                    "error": e.error,  
                }  
                for e in self.executions  
            ],  
        }  
  
    def to_dict(self) -> Dict[str, Any]:  
        """  
        安全序列化上下文，以便持久化  
        - 使用 pydantic_encoder 处理 Message / BaseModel 等复杂对象  
        - history 仅保留字符串或 JSON 友好格式，防止过大或不可序列化  
        """  
        def _safe(value: Any) -> Any:  
            try:  
                return pydantic_encoder(value)  
            except Exception:  
                return str(value)[:200]  
  
        history_dump = {  
            k: _safe(v)  
            for k, v in self.history.items()  
            if k == "last_output" or isinstance(k, str)  
        }  
  
        return {  
            "input": _safe(self.input),  
            "state": {k: _safe(v) for k, v in self.state.items()},  
            "history": history_dump,  
            "metadata": {k: _safe(v) for k, v in self.metadata.items()},  
        }  
  
  
# ========================= 工作流引擎 =========================  
class Workflow:  
    def __init__(  
        self,  
        name: str = "Workflow",  
        event_bus: Optional[EventBus] = None,  
        storage: Optional[SessionInterface] = None,  
        max_steps: int = 100,  
        enable_retry: bool = False,  
        max_retries: int = 3,  
    ):  
        self.name = name  
        self.event_bus = event_bus or EventBus()  
        self.storage = storage  
        self.max_steps = max_steps  
        self.enable_retry = enable_retry  
        self.max_retries = max_retries  
  
        self.nodes: Dict[str, Callable] = {}  
        self.edges: Dict[str, List[Tuple[str, Optional[Callable]]]] = {}  
        self.entry_point: Optional[str] = None  
  
        self._validated = False  
        self._validation_errors: List[str] = []  
  
    # ---------- DAG 构建 API ----------  
    def add_node(self, name: str, func: Callable) -> "Workflow":  
        if name in self.nodes:  
            raise ValueError(f"Node '{name}' already exists")  
        self.nodes[name] = func  
        self._validated = False  
        logger.debug("Node added", node=name)  
        return self  
  
    def add_edge(  
        self,  
        source: str,  
        target: str,  
        condition: Optional[Callable[[WorkflowContext], bool]] = None,  
    ) -> "Workflow":  
        if source not in self.nodes:  
            raise ValueError(f"Source node '{source}' not found")  
        if target not in self.nodes:  
            raise ValueError(f"Target node '{target}' not found")  
  
        self.edges.setdefault(source, []).append((target, condition))  
        self._validated = False  
        logger.debug("Edge added", source=source, target=target)  
        return self  
  
    def set_entry_point(self, name: str) -> "Workflow":  
        if name not in self.nodes:  
            raise ValueError(f"Node '{name}' not found")  
        self.entry_point = name  
        self._validated = False  
        return self  
  
    # ---------- DAG 验证 ----------  
    def validate(self) -> bool:  
        if self._validated:  
            return len(self._validation_errors) == 0  
  
        self._validation_errors.clear()  
  
        if not self.entry_point:  
            self._validation_errors.append("No entry point defined")  
        elif self.entry_point not in self.nodes:  
            self._validation_errors.append(f"Entry point '{self.entry_point}' not in nodes")  
  
        try:  
            self._detect_cycles()  
        except WorkflowCycleError as e:  
            self._validation_errors.append(str(e))  
  
        unreachable = self._find_unreachable_nodes()  
        if unreachable:  
            logger.warning("Workflow has unreachable nodes", nodes=list(unreachable))  
  
        dead_nodes = self._find_dead_nodes()  
        if dead_nodes:  
            logger.warning("Workflow has dead-end nodes", nodes=list(dead_nodes))  
  
        self._validated = True  
        if self._validation_errors:  
            logger.error("Workflow validation failed", errors=self._validation_errors)  
            return False  
  
        logger.info("Workflow validation passed", name=self.name)  
        return True  
  
    def _detect_cycles(self):  
        visited: Set[str] = set()  
        rec_stack: Set[str] = set()  
  
        def dfs(node: str, path: List[str]):  
            visited.add(node)  
            rec_stack.add(node)  
            path.append(node)  
  
            for neighbor, _ in self.edges.get(node, []):  
                if neighbor not in visited:  
                    dfs(neighbor, path)  
                elif neighbor in rec_stack:  
                    cycle_start = path.index(neighbor)  
                    cycle = " → ".join(path[cycle_start:] + [neighbor])  
                    raise WorkflowCycleError(f"Cycle detected: {cycle}")  
  
            rec_stack.remove(node)  
            path.pop()  
  
        for node in self.nodes:  
            if node not in visited:  
                dfs(node, [])  
  
    def _find_unreachable_nodes(self) -> Set[str]:  
        if not self.entry_point:  
            return set(self.nodes.keys())  
  
        reachable: Set[str] = set()  
        queue = [self.entry_point]  
  
        while queue:  
            current = queue.pop(0)  
            if current in reachable:  
                continue  
            reachable.add(current)  
            for neighbor, _ in self.edges.get(current, []):  
                if neighbor not in reachable:  
                    queue.append(neighbor)  
  
        return set(self.nodes.keys()) - reachable  
  
    def _find_dead_nodes(self) -> Set[str]:  
        """简单检测：没有出边且不是入口的节点"""  
        dead = set()  
        for node in self.nodes:  
            if not self.edges.get(node) and node != self.entry_point:  
                dead.add(node)  
        return dead  
  
    def get_validation_errors(self) -> List[str]:  
        return self._validation_errors.copy()  
  
    # ---------- 执行入口 ----------  
    async def execute(self, input_data: Any, session_id: Optional[str] = None) -> Any:  
        if not self.validate():  
            errors = "\n".join(self._validation_errors)  
            raise WorkflowError(f"Workflow validation failed:\n{errors}")  
  
        context = WorkflowContext(input=input_data)  
        if session_id:  
            context.metadata["session_id"] = session_id  
  
        await self.event_bus.publish(  
            WorkflowEvent(type="workflow_started", data={"name": self.name, "input": str(input_data)[:100]})  
        )  
  
        try:  
            result = await self._execute_loop(context, session_id)  
            await self.event_bus.publish(  
                WorkflowEvent(  
                    type="workflow_completed",  
                    data={"name": self.name, "summary": context.get_execution_summary()},  
                )  
            )  
            return result  
        except Exception as e:  
            await self.event_bus.publish(  
                WorkflowEvent(type="workflow_error", error=str(e), data={"name": self.name})  
            )  
            raise  
  
    async def _execute_loop(self, context: WorkflowContext, session_id: Optional[str]) -> Any:  
        current_node = self.entry_point  
        steps = 0  
  
        while current_node and steps < self.max_steps:  
            steps += 1  
            node_name = current_node  
  
            logger.debug("Executing node", node=node_name, step=steps)  
            result = await self._execute_node(node_name, context)  
  
            normalized = self._normalize_result(result)  
            context.history[node_name] = normalized  
            context.history["last_output"] = normalized  
  
            if isinstance(result, Next):  
                current_node = result.node  
                if result.input is not None:  
                    normalized_input = self._normalize_result(result.input)  
                    context.history["last_output"] = normalized_input  
                    context.state["_next_input"] = normalized_input  
            else:  
                current_node = await self._find_next_node(node_name, context)  
  
            if self.storage and session_id:  
                await self._persist_state(session_id, steps, node_name, context)  
  
        if steps >= self.max_steps:  
            raise WorkflowError(  
                f"Workflow exceeded max steps: {self.max_steps}",  
                context={"steps": steps, "last_node": current_node},  
            )  
  
        return context.history.get("last_output") 
    
    async def _persist_state(  
        self,  
        session_id: str,  
        steps: int,  
        last_node: Optional[str],  
        context: WorkflowContext,  
    ):  
        """状态持久化统一入口"""  
        try:  
            await self.storage.set(  
                f"workflow:{session_id}",  
                {  
                    "step": steps,  
                    "last_node": last_node,  
                    "context": context.to_dict(),  
                },  
            )  
        except Exception as e:  
            logger.warning("Failed to persist workflow state", error=str(e)) 
  
    async def _execute_node(self, node_name: str, context: WorkflowContext) -> Any:  
        execution = NodeExecution(node_name=node_name, status=NodeStatus.RUNNING, start_time=time.time())  
        await self.event_bus.publish(WorkflowEvent(type="node_started", data={"node": node_name}))  
  
        node_callable = self.nodes[node_name]  
  
        try:  
            if self.enable_retry:  
                result = await self._execute_with_retry(node_callable, context)  
            else:  
                result = await self._execute_once(node_callable, context)  
  
            execution.status = NodeStatus.SUCCESS  
            execution.output_data = self._normalize_result(result)  
            execution.end_time = time.time()  
  
            await self.event_bus.publish(  
                WorkflowEvent(  
                    type="node_completed",  
                    data={"node": node_name, "duration": execution.duration, "result": str(result)[:100]},  
                )  
            )  
            return result  
  
        except Exception as e:  
            execution.status = NodeStatus.FAILED  
            execution.error = str(e)  
            execution.end_time = time.time()  
  
            await self.event_bus.publish(  
                WorkflowEvent(type="node_error", error=str(e), data={"node": node_name})  
            )  
            raise WorkflowError(f"Node '{node_name}' execution failed: {e}", context={"node": node_name}) from e  
  
        finally:  
            context.add_execution(execution)
    
    async def _run_agent_node(self, agent: Agent, context: WorkflowContext) -> Any:  
        """  
        Agent 节点默认读取 last_output 作为输入；  
        如果上一节点通过 Next.input 传递了自定义输入，则优先使用  
        """  
        user_input = context.state.pop("_next_input", None) or context.history.get("last_output", context.input)  
  
        if isinstance(user_input, str):  
            user_input = Message.user(user_input)  
        elif isinstance(user_input, dict):  
            user_input = Message(**user_input)  
        elif isinstance(user_input, list) and user_input and isinstance(user_input[0], dict):  
            user_input = [Message(**msg) for msg in user_input]  
  
        output = await agent.run(user_input)  
        return output.model_dump() if hasattr(output, "model_dump") else output  
  
    async def _find_next_node(self, current: str, context: WorkflowContext) -> Optional[str]:  
        edges = self.edges.get(current, [])  
        for target, condition in edges:  
            if condition is None:  
                return target  
            try:  
                if inspect.iscoroutinefunction(condition):  
                    if await condition(context):  
                        return target  
                else:  
                    if condition(context):  
                        return target  
            except Exception as e:  
                logger.error("Condition evaluation failed", source=current, target=target, error=str(e))  
        return None  
  
    # 在 Workflow 类里增加一个通用执行方法  
    async def _execute_once(self, node_callable: Callable, context: WorkflowContext) -> Any:  
        if isinstance(node_callable, Agent):  
            return await self._run_agent_node(node_callable, context)  
        if callable(node_callable):  
            return await ensure_awaitable(node_callable, context)  
        raise WorkflowError(f"Node '{node_callable}' is not callable")  
    
    async def _execute_with_retry(self, func: Callable, context: WorkflowContext) -> Any:  
        last_error = None  
        for attempt in range(self.max_retries):  
            try:  
                return await self._execute_once(func, context)  
            except Exception as e:  
                last_error = e  
                logger.warning(  
                    "Node execution failed, retrying",  
                    attempt=attempt + 1,  
                    max_retries=self.max_retries,  
                    error=str(e),  
                )  
                if attempt < self.max_retries - 1:  
                    await asyncio.sleep(2 ** attempt)  
        # 所有重试都失败  
        raise last_error    
  
    def _normalize_result(self, result: Any) -> Any:  
        """  
        将节点输出转换为可序列化/可在历史中保存的格式  
        - BaseModel -> dict  
        - AgentOutput -> content/dict  
        - Message -> OpenAI 字典  
        - 原生类型保持不变  
        - 其他对象转为字符串（并截断）  
        """  
        if isinstance(result, BaseModel):  
            return result.model_dump()  
        if hasattr(result, "model_dump"):  
            data = result.model_dump()  
            return data.get("content", data)  
        if isinstance(result, Message):  
            return result.to_openai_format()  
        if isinstance(result, (str, int, float, bool, type(None))):  
            return result  
        if isinstance(result, (list, dict)):  
            return result  
        return str(result)[:500]  
  
    async def _persist_state(  
        self,  
        session_id: str,  
        steps: int,  
        current_node: Optional[str],  
        context: WorkflowContext,  
    ):  
        """状态持久化的统一入口，使用 try/except 避免影响主流程"""  
        try:  
            await self.storage.set(  
                f"workflow:{session_id}",  
                {  
                    "step": steps,  
                    "last_node": current_node,  
                    "context": context.to_dict(),  
                },  
            )  
        except Exception as e:  
            logger.warning("Failed to persist workflow state", error=str(e))  
  
    # ---------- 可视化/调试 ----------  
    def to_mermaid(self) -> str:  
        lines = ["graph TD"]  
        for node in self.nodes:  
            label = f"[{node}]" if node == self.entry_point else f"({node})"  
            lines.append(f"    {node}{label}")  
        for source, targets in self.edges.items():  
            for target, condition in targets:  
                label = f"|condition|" if condition else ""  
                lines.append(f"    {source} --{label}--> {target}")  
        return "\n".join(lines)  
  
    def print_structure(self):  
        print(f"\n=== Workflow: {self.name} ===")  
        print(f"Entry Point: {self.entry_point}")  
        print(f"\nNodes ({len(self.nodes)}):")  
        for node in self.nodes:  
            print(f"  - {node}")  
  
        print(f"\nEdges ({sum(len(v) for v in self.edges.values())}):")  
        for source, targets in self.edges.items():  
            for target, condition in targets:  
                cond_str = " [conditional]" if condition else ""  
                print(f"  - {source} → {target}{cond_str}")  
        print()  
```

[6] gecko/config.py
```python
# gecko/config.py  
"""  
配置系统（改进版）  
  
- 增加 configure_settings / reset_settings，便于测试重载  
- 使用 Lazy 初始化，防止导入 config 时立刻读取 .env  
- Docstring 更新，避免示例与 Agent API 不匹配  
"""  
  
from __future__ import annotations  
  
from typing import Optional  
  
from pydantic import Field, field_validator  
from pydantic_settings import BaseSettings, SettingsConfigDict  
  
  
class GeckoSettings(BaseSettings):  
    default_model: str = Field(default="gpt-3.5-turbo")  
    default_api_key: str = Field(default="")  
    default_base_url: Optional[str] = None  
    default_temperature: float = Field(default=0.7, ge=0.0, le=2.0)  
  
    max_turns: int = Field(default=5, ge=1, le=50)  
    max_context_tokens: int = Field(default=4000, ge=100)  
  
    default_storage_url: str = Field(default="sqlite://./gecko_data.db")  
    log_level: str = Field(default="INFO")  
    log_format: str = Field(default="text")  
  
    enable_cache: bool = True  
    tool_execution_timeout: float = Field(default=30.0, ge=1.0)  
  
    model_config = SettingsConfigDict(  
        env_prefix="GECKO_",  
        env_file=".env",  
        env_file_encoding="utf-8",  
        case_sensitive=False,  
        extra="ignore",  
    )  
  
    @field_validator("log_level")  
    @classmethod  
    def validate_log_level(cls, v: str) -> str:  
        valid = {"DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"}  
        if v.upper() not in valid:  
            raise ValueError(f"log_level must be one of {valid}")  
        return v.upper()  
  
    @field_validator("log_format")  
    @classmethod  
    def validate_log_format(cls, v: str) -> str:  
        if v not in {"text", "json"}:  
            raise ValueError("log_format must be 'text' or 'json'")  
        return v  
  
  
_default_settings: Optional[GeckoSettings] = None  
  
  
def get_settings(force_reload: bool = False) -> GeckoSettings:  
    global _default_settings  
    if _default_settings is None or force_reload:  
        _default_settings = GeckoSettings()  
    return _default_settings  
  
  
def configure_settings(**overrides) -> GeckoSettings:  
    """  
    允许测试/脚本传入覆盖参数，例如：  
        configure_settings(default_model="gpt-4")  
    """  
    global _default_settings  
    _default_settings = GeckoSettings(**overrides)  
    return _default_settings  
  
  
def reset_settings():  
    global _default_settings  
    _default_settings = None  
  
  
settings = get_settings()  
```

[7] gecko/core/__init__.py
```python
```

[8] gecko/core/agent.py
```python
# gecko/core/agent.py  
from __future__ import annotations  
  
from typing import Any, Iterable, List, Optional, Type, Union  
  
from pydantic import BaseModel  
  
from gecko.core.events import AgentRunEvent, EventBus  
from gecko.core.message import Message  
from gecko.core.output import AgentOutput  
from gecko.core.toolbox import ToolBox  
from gecko.core.memory import TokenMemory  
from gecko.core.engine.base import CognitiveEngine  
from gecko.core.engine.react import ReActEngine  
from gecko.core.logging import get_logger  
from gecko.core.exceptions import AgentError  
  
logger = get_logger(__name__)  
  
  
class Agent:  
    """  
    Agent 对象负责在模型、工具箱、记忆之间协调一次推理任务。  
    """  
  
    def __init__(  
        self,  
        model: Any,  
        toolbox: ToolBox,  
        memory: TokenMemory,  
        engine_cls: Type[CognitiveEngine] = ReActEngine,  
        event_bus: Optional[EventBus] = None,  
        **engine_kwargs: Any,  
    ):  
        self.event_bus = event_bus or EventBus()  
        self.toolbox = toolbox  
        self.memory = memory  
        self.engine = engine_cls(  
            model=model,  
            toolbox=toolbox,  
            memory=memory,  
            **engine_kwargs  
        )  
  
    async def run(  
        self,  
        messages: str | Message | List[Message] | List[dict] | dict,  
        response_model: Optional[Type[BaseModel]] = None  
    ) -> AgentOutput | BaseModel:  
        """  
        单次推理入口：对多种输入格式统一转换为 Message 列表  
        """  
        input_msgs = self._normalize_messages(messages)  
  
        await self.event_bus.publish(  
            AgentRunEvent(type="run_started", data={"input_count": len(input_msgs)})  
        )  
  
        try:  
            output = await self.engine.step(input_msgs, response_model=response_model)  
            payload = self._serialize_output(output)  
  
            await self.event_bus.publish(  
                AgentRunEvent(type="run_completed", data={"output": payload})  
            )  
            return output  
  
        except Exception as e:  
            logger.exception("Agent run failed")  
            await self.event_bus.publish(  
                AgentRunEvent(type="run_error", error=str(e))  
            )  
            raise  
  
    async def stream(self, messages: str | Message | List[Message] | List[dict] | dict):  
        """  
        流式推理：共用同一套输入标准化逻辑  
        """  
        input_msgs = self._normalize_messages(messages)  
  
        await self.event_bus.publish(AgentRunEvent(type="stream_started"))  
        try:  
            async for chunk in self.engine.step_stream(input_msgs):  
                yield chunk  
            await self.event_bus.publish(AgentRunEvent(type="stream_completed"))  
        except Exception as e:  
            logger.exception("Agent stream failed")  
            await self.event_bus.publish(AgentRunEvent(type="stream_error", error=str(e)))  
            raise  
  
    # ---------------- 辅助方法 ----------------  
    def _normalize_messages(  
        self,  
        messages: str | Message | List[Message] | List[dict] | dict  
    ) -> List[Message]:  
        """  
        支持以下输入：  
        1. 字符串 -> 单条 user 消息  
        2. Message -> [Message]  
        3. List[Message] -> 原样返回  
        4. dict -> 若包含 role/content 则构建 Message，否则视为 {"input": "..."}  
        5. List[dict] -> 每个 dict 转为 Message  
        """  
        if isinstance(messages, Message):  
            return [messages]  
  
        if isinstance(messages, str):  
            return [Message.user(messages)]  
  
        if isinstance(messages, dict):  
            if "role" in messages:  
                return [Message(**messages)]  
            text = messages.get("input") or str(messages)  
            return [Message.user(text)]  
  
        if isinstance(messages, list):  
            if not messages:  
                raise AgentError("消息列表为空")  
            if isinstance(messages[0], Message):  
                return messages  # 已经是标准 Message  
            normalized = []  
            for item in messages:  
                if isinstance(item, Message):  
                    normalized.append(item)  
                elif isinstance(item, dict):  
                    normalized.append(Message(**item))  
                else:  
                    raise AgentError(f"无法识别的消息元素类型: {type(item)}")  
            return normalized  
  
        raise AgentError(f"不支持的消息类型: {type(messages)}")  
  
    def _serialize_output(self, output: AgentOutput | BaseModel) -> dict:  
        if hasattr(output, "model_dump"):  
            return output.model_dump()  
        return {"content": str(output)}  
```

[9] gecko/core/builder.py
```python
# gecko/core/builder.py  
from __future__ import annotations  
  
from typing import Any, Sequence, Type  
  
from gecko.core.agent import Agent  
from gecko.core.memory import TokenMemory  
from gecko.core.toolbox import ToolBox  
from gecko.core.engine.base import CognitiveEngine  
from gecko.core.engine.react import ReActEngine  
from gecko.plugins.storage.interfaces import SessionInterface  
from gecko.plugins.tools.base import BaseTool  
from gecko.core.exceptions import ConfigurationError  
  
  
class AgentBuilder:  
    """  
    Agent 构建器（改进版）  
    关键改进：  
    1. system_prompt 等引擎参数统一通过 engine_kwargs 传递，避免与 Agent.__init__ 不匹配  
    2. 工具列表自动去重并校验是否继承 BaseTool  
    3. storage 必须实现 SessionInterface，否则在 TokenMemory 中使用会报错  
    4. 支持自定义 Engine 类 & 额外参数  
    """  
  
    def __init__(self):  
        self._model: Any | None = None  
        self._tools: list[BaseTool] = []  
        self._storage: SessionInterface | None = None  
        self._session_id: str = "default"  
        self._max_tokens: int = 4000  
        self._engine_cls: Type[CognitiveEngine] = ReActEngine  
        self._engine_kwargs: dict[str, Any] = {}  # 统一放置系统 Prompt、Hook 等  
        self._toolbox_config: dict[str, Any] = {}  
  
    # ---------------- 基础配置 ----------------  
    def with_model(self, model: Any) -> "AgentBuilder":  
        # 检查模型是否实现必要方法  
        missing = [m for m in ("acompletion",) if not hasattr(model, m)]  
        if missing:  
            raise ConfigurationError(  
                f"Model 缺少必要方法: {', '.join(missing)}",  
                context={"model": repr(model)}  
            )  
        self._model = model  
        return self  
  
    def with_tools(self, tools: Sequence[BaseTool]) -> "AgentBuilder":  
        for tool in tools:  
            if not isinstance(tool, BaseTool):  
                raise TypeError(f"Tool 必须继承 BaseTool，收到 {type(tool)}")  
            self._tools.append(tool)  
        return self  
  
    def with_storage(self, storage: SessionInterface | None) -> "AgentBuilder":  
        if storage and not isinstance(storage, SessionInterface):  
            raise TypeError(  
                "storage 必须实现 SessionInterface，用于 TokenMemory 持久化"  
            )  
        self._storage = storage  
        return self  
  
    def with_session_id(self, session_id: str) -> "AgentBuilder":  
        self._session_id = session_id  
        return self  
  
    def with_max_tokens(self, max_tokens: int) -> "AgentBuilder":  
        self._max_tokens = max_tokens  
        return self  
  
    def with_engine(  
        self,  
        engine_cls: Type[CognitiveEngine],  
        **engine_kwargs: Any  
    ) -> "AgentBuilder":  
        if not issubclass(engine_cls, CognitiveEngine):  
            raise TypeError("engine_cls 必须继承 CognitiveEngine")  
        self._engine_cls = engine_cls  
        self._engine_kwargs.update(engine_kwargs)  
        return self  
  
    def with_system_prompt(self, prompt: str) -> "AgentBuilder":  
        # 统一放入 engine_kwargs，确保 Engine 可接收  
        self._engine_kwargs["system_prompt"] = prompt  
        return self  
  
    def with_toolbox_config(self, **config: Any) -> "AgentBuilder":  
        """  
        允许调用者自定义 ToolBox 的并发/超时等参数  
        """  
        self._toolbox_config.update(config)  
        return self  
  
    # ---------------- 构建流程 ----------------  
    def build(self) -> Agent:  
        if not self._model:  
            raise ConfigurationError("构建 Agent 前必须调用 with_model 指定模型")  
  
        toolbox = self._build_toolbox()  
        memory = self._build_memory()  
  
        return Agent(  
            model=self._model,  
            toolbox=toolbox,  
            memory=memory,  
            engine_cls=self._engine_cls,  
            event_bus=self._engine_kwargs.pop("event_bus", None),  
            **self._engine_kwargs  # 其余参数直接传给 Engine  
        )  
  
    def _build_toolbox(self) -> ToolBox:  
        # 根据工具名称去重，后注册的同名工具会覆盖前者  
        deduped: dict[str, BaseTool] = {}  
        for tool in self._tools:  
            deduped[tool.name] = tool  
  
        return ToolBox(  
            tools=list(deduped.values()),  
            **self._toolbox_config  
        )  
  
    def _build_memory(self) -> TokenMemory:  
        return TokenMemory(  
            session_id=self._session_id,  
            storage=self._storage,  
            max_tokens=self._max_tokens  
        )  
```

[10] gecko/core/engine/base.py
```python
# gecko/core/engine/base.py
from abc import ABC, abstractmethod
from typing import List, Optional
from gecko.core.message import Message
from gecko.core.output import AgentOutput
from gecko.core.toolbox import ToolBox
from gecko.core.memory import TokenMemory

class CognitiveEngine(ABC):
    """
    认知引擎基类：定义 Agent 如何'思考'和'执行'
    """
    def __init__(self, model, toolbox: ToolBox, memory: TokenMemory):
        self.model = model
        self.toolbox = toolbox
        self.memory = memory

    @abstractmethod
    async def step(self, input_messages: List[Message]) -> AgentOutput:
        """
        执行单次或多轮推理步骤
        :param input_messages: 当前输入的消息（通常是 User Message）
        :return: 最终产出的 AgentOutput
        """
        pass
```

[11] gecko/core/engine/react.py
```python
# gecko/core/engine/react.py  
"""  
ReActEngine（增强版）  
  
核心能力：  
1. 模型能力自适应：检测是否支持 function calling / stream，自动降级或提示  
2. 工具执行更健壮：校验字段、捕获错误、反馈给 LLM，防止死循环  
3. 结构化输出解析与带反馈重试  
4. 流式/非流式路径统一管理上下文  
5. Hook 机制完善，异常不影响主流程  
"""  
  
from __future__ import annotations  
  
import asyncio  
import json  
from typing import (  
    Any,  
    AsyncIterator,  
    Callable,  
    Dict,  
    List,  
    Optional,  
    Tuple,  
    Type,  
    TypeVar,  
)  
  
from pydantic import BaseModel  
  
from gecko.core.engine.base import CognitiveEngine  
from gecko.core.exceptions import AgentError, ModelError  
from gecko.core.logging import get_logger  
from gecko.core.message import Message  
from gecko.core.output import AgentOutput  
from gecko.core.prompt import PromptTemplate  
from gecko.core.structure import StructureEngine  
from gecko.core.toolbox import ToolBox  
from gecko.core.utils import ensure_awaitable  
from gecko.core.memory import TokenMemory  
  
logger = get_logger(__name__)  
  
T = TypeVar("T", bound=BaseModel)  
  
DEFAULT_REACT_TEMPLATE = """You are a helpful AI assistant.  
Available Tools:  
{% for tool in tools %}  
- {{ tool.function.name }}: {{ tool.function.description }}  
{% endfor %}  
  
Answer the user's request. Use tools if necessary.  
"""  
  
  
class ExecutionContext:  
    """  
    执行上下文：  
    - messages：当前对话（包含历史和用户输入）  
    - turn：已经执行的轮数  
    - metadata：可存储 last_response 等额外信息  
    """  
  
    def __init__(self, messages: List[Message]):  
        self.messages = messages  
        self.turn = 0  
        self.metadata: Dict[str, Any] = {}  
  
    def add_message(self, message: Message):  
        self.messages.append(message)  
  
    def get_last_message(self) -> Optional[Message]:  
        return self.messages[-1] if self.messages else None  
  
  
class ReActEngine(CognitiveEngine):  
    """  
    ReAct 引擎（完整实现）  
    """  
  
    def __init__(  
        self,  
        model: Any,  
        toolbox: ToolBox,  
        memory: TokenMemory,  
        max_turns: int = 5,  
        system_prompt: str | PromptTemplate | None = None,  
        on_turn_start: Optional[Callable[[ExecutionContext], Any]] = None,  
        on_turn_end: Optional[Callable[[ExecutionContext], Any]] = None,  
        on_tool_execute: Optional[Callable[[str, Dict[str, Any]], Any]] = None,  
        supports_functions: Optional[bool] = None,  
        supports_stream: Optional[bool] = None,  
    ):  
        super().__init__(model, toolbox, memory)  
        self.max_turns = max_turns  
        self.on_turn_start = on_turn_start  
        self.on_turn_end = on_turn_end  
        self.on_tool_execute = on_tool_execute  
  
        # 模型能力检测：若未显式声明，则根据方法/属性推断  
        self.supports_functions = (  
            supports_functions  
            if supports_functions is not None  
            else hasattr(model, "acompletion")  
        )  
        self.supports_stream = (  
            supports_stream  
            if supports_stream is not None  
            else hasattr(model, "astream")  
        )  
  
        if system_prompt is None:  
            self.prompt_template = PromptTemplate(template=DEFAULT_REACT_TEMPLATE)  
        elif isinstance(system_prompt, str):  
            self.prompt_template = PromptTemplate(template=system_prompt)  
        else:  
            self.prompt_template = system_prompt  
  
    # ===================== 对外 API =====================  
    async def step(  
        self,  
        input_messages: List[Message],  
        response_model: Optional[Type[T]] = None,  
        strategy: str = "auto",  
        max_retries: int = 2,  
    ) -> AgentOutput | T:  
        """  
        核心推理入口。  
        1. 构建上下文（包含历史和 system prompt）  
        2. 构造模型调用参数（function calling / json mode 等）  
        3. 运行 ReAct 循环  
        4. 如需结构化输出，执行解析与带反馈重试  
        """  
        logger.info(  
            "ReAct execution started",  
            input_count=len(input_messages),  
            has_structure=response_model is not None,  
        )  
  
        try:  
            context = await self._build_execution_context(input_messages)  
            llm_params = self._build_llm_params(response_model, strategy)  
  
            final_output = await self._run_reasoning_loop(  
                context,  
                llm_params,  
                response_model,  
                strategy,  
            )  
  
            if response_model:  
                structured = await self._extract_and_retry(  
                    final_output,  
                    response_model,  
                    context,  
                    llm_params,  
                    max_retries,  
                )  
                await self._save_context(context)  
                return structured  
  
            await self._save_context(context)  
            logger.info("ReAct execution completed")  
            return final_output  
  
        except Exception as e:  
            logger.exception("ReAct execution failed")  
            if isinstance(e, AgentError):  
                raise  
            raise AgentError(f"ReAct execution failed: {e}") from e  
  
    async def step_stream(self, input_messages: List[Message]) -> AsyncIterator[str]:  
        """  
        流式执行入口：  
        1. 先尝试快速判断是否需要工具，若需要则走常规 ReAct  
        2. 若不需要，直接流式输出最终回复（仅在模型支持 stream 时）  
        """  
        if not self.supports_stream:  
            raise AgentError("当前模型不支持流式输出")  
  
        context = await self._build_execution_context(input_messages)  
        llm_params = self._build_llm_params(None, "auto")  
  
        turn = 0  
        while turn < self.max_turns:  
            turn += 1  
  
            needs_tools, peek_response = await self._check_needs_tools(context, llm_params)  
            if needs_tools:  
                await self._execute_one_turn(context, llm_params, None, "auto")  
                continue  
  
            if peek_response:  
                msg = self._parse_llm_response(peek_response)  
                context.add_message(msg)  
                for chunk in msg.content or []:  
                    yield chunk  
                break  
  
            async for chunk in self._stream_final_response(context, llm_params):  
                yield chunk  
            break  
  
        await self._save_context(context)  
  
    # ===================== 上下文构建 =====================  
    async def _build_execution_context(self, input_messages: List[Message]) -> ExecutionContext:  
        history = await self._load_history()  
  
        # 若历史中不存在 system prompt，则插入  
        if not any(m.role == "system" for m in history):  
            system_msg = self._create_system_message()  
            history.insert(0, system_msg)  
  
        # 用户输入中若包含 system 也应该去重/放到开头  
        user_system = [m for m in input_messages if m.role == "system"]  
        normal_inputs = [m for m in input_messages if m.role != "system"]  
        all_messages = history + user_system + normal_inputs  
  
        return ExecutionContext(all_messages)  
  
    async def _load_history(self) -> List[Message]:  
        if not self.memory.storage or not self.memory.session_id:  
            return []  
  
        try:  
            raw = await self.memory.storage.get(self.memory.session_id)  
            if not raw:  
                return []  
            history_raw = raw.get("messages", [])  
            return await self.memory.get_history(history_raw)  
        except Exception as e:  
            logger.warning("Failed to load history", session_id=self.memory.session_id, error=str(e))  
            return []  
  
    def _create_system_message(self) -> Message:  
        tools_schema = self.toolbox.to_openai_schema()  
        content = self.prompt_template.format(tools=tools_schema)  
        return Message.system(content)  
  
    # ===================== LLM 参数构建 =====================  
    def _build_llm_params(self, response_model: Optional[Type[T]], strategy: str) -> Dict[str, Any]:  
        params: Dict[str, Any] = {}  
  
        tools_schema = self.toolbox.to_openai_schema()  
        if tools_schema and self.supports_functions:  
            params["tools"] = tools_schema  
            params["tool_choice"] = "auto"  
  
        if response_model:  
            if strategy in {"auto", "function_calling"} and self.supports_functions:  
                self._add_structure_params(params, response_model)  
            else:  
                params["response_format"] = {"type": "json_object"}  
                if not self.supports_functions:  
                    logger.warning("模型不支持 function calling，已降级为 JSON Mode")  
  
        return params  
  
    def _add_structure_params(self, params: Dict[str, Any], response_model: Type[T]):  
        structure_tool = StructureEngine.to_openai_tool(response_model)  
        params.setdefault("tools", []).append(structure_tool)  
        params["tool_choice"] = {  
            "type": "function",  
            "function": {"name": structure_tool["function"]["name"]},  
        }  
  
    # ===================== 主推理循环 =====================  
    async def _run_reasoning_loop(  
        self,  
        context: ExecutionContext,  
        llm_params: Dict[str, Any],  
        response_model: Optional[Type[T]],  
        strategy: str,  
    ) -> AgentOutput:  
        while context.turn < self.max_turns:  
            context.turn += 1  
  
            if self.on_turn_start:  
                await self._safe_call_hook(self.on_turn_start, context)  
  
            should_continue = await self._execute_one_turn(  
                context,  
                llm_params,  
                response_model,  
                strategy,  
            )  
  
            if self.on_turn_end:  
                await self._safe_call_hook(self.on_turn_end, context)  
  
            if not should_continue:  
                break  
  
        last_msg = context.get_last_message()  
        if last_msg and last_msg.role == "assistant":  
            tool_calls = getattr(last_msg, "tool_calls", None) or []  
            return AgentOutput(  
                content=last_msg.content or "",  
                raw=context.metadata.get("last_response"),  
                tool_calls=tool_calls,  
            )  
  
        logger.warning("Max turns reached", max_turns=self.max_turns)  
        return AgentOutput(content="Max iterations reached.")  
  
    async def _execute_one_turn(  
        self,  
        context: ExecutionContext,  
        llm_params: Dict[str, Any],  
        response_model: Optional[Type[T]],  
        strategy: str,  
    ) -> bool:  
        response = await self._call_llm(context, llm_params)  
        assistant_msg = self._parse_llm_response(response)  
        context.add_message(assistant_msg)  
        context.metadata["last_response"] = response  
  
        # 结构化提取完成则无需继续  
        if (  
            response_model  
            and strategy in {"auto", "function_calling"}  
            and self._is_structure_extraction(assistant_msg, response_model)  
        ):  
            return False  
  
        if assistant_msg.tool_calls:  
            executed = await self._execute_tools(assistant_msg.tool_calls, context, response_model)  
            return executed  
  
        # 无工具调用，则视为最终回复  
        return False  
  
    # ===================== LLM 调用/解析 =====================  
    async def _call_llm(self, context: ExecutionContext, params: Dict[str, Any]) -> Any:  
        messages_payload = [m.to_openai_format() for m in context.messages]  
        logger.debug("Calling LLM", message_count=len(messages_payload))  
  
        try:  
            response = await ensure_awaitable(self.model.acompletion, messages=messages_payload, **params)  
            return response  
        except Exception as e:  
            logger.error("LLM call failed", error=str(e))  
            raise ModelError(f"LLM API call failed: {e}") from e  
  
    def _parse_llm_response(self, response: Any) -> Message:  
        choice = response.choices[0]  
        raw_msg = choice.message  
  
        if hasattr(raw_msg, "model_dump"):  
            try:  
                msg_data = raw_msg.model_dump()  
            except Exception:  
                msg_data = {}  
        else:  
            msg_data = {}  
  
        if not msg_data:  
            msg_data = {  
                "content": getattr(raw_msg, "content", ""),  
                "tool_calls": getattr(raw_msg, "tool_calls", None),  
            }  
  
        if not msg_data.get("role"):  
            logger.warning("Missing role in LLM response")  
            msg_data["role"] = "assistant"  
  
        return Message(**msg_data)  
  
    # ===================== 工具调用 =====================  
    async def _execute_tools(  
        self,  
        tool_calls: List[Dict[str, Any]],  
        context: ExecutionContext,  
        response_model: Optional[Type[T]],  
    ) -> bool:  
        extraction_name = None  
        if response_model and self.supports_functions:  
            extraction_name = StructureEngine.to_openai_tool(response_model)["function"]["name"]  
  
        executed_successfully = False  
  
        for tool_call in tool_calls:  
            func_info = tool_call.get("function") or {}  
            func_name = func_info.get("name")  
            arguments = func_info.get("arguments")  
  
            if not func_name:  
                logger.error("Tool call missing name", tool_call=tool_call)  
                continue  
  
            if func_name == extraction_name:  
                # 结构化提取工具由结构化流程处理，此处跳过  
                continue  
  
            if not isinstance(arguments, (str, dict)):  
                logger.warning("Tool call arguments invalid", tool=func_name)  
                continue  
  
            result = await self._execute_single_tool(func_name, arguments, tool_call.get("id") or "")  
  
            tool_msg = Message.tool_result(  
                tool_call_id=tool_call.get("id") or "",  
                content=result["content"],  
                tool_name=func_name,  
            )  
            context.add_message(tool_msg)  
  
            if result["is_error"]:  
                # 反馈给 LLM，促使其重新规划  
                context.add_message(Message.user(f"工具 {func_name} 执行失败：{result['content']}"))  
            else:  
                executed_successfully = True  
  
        return executed_successfully  
  
    async def _execute_single_tool(self, func_name: str, args_payload: str | dict, call_id: str) -> Dict[str, str]:  
        try:  
            args = json.loads(args_payload) if isinstance(args_payload, str) else args_payload  
        except json.JSONDecodeError as e:  
            logger.error("Tool arguments JSON decode failed", tool=func_name, error=str(e))  
            return {"content": f"参数解析失败：{e}", "is_error": True}  
  
        try:  
            if self.on_tool_execute:  
                await self._safe_call_hook(self.on_tool_execute, func_name, args)  
  
            result = await self.toolbox.execute(func_name, args)  
            return {"content": result if isinstance(result, str) else str(result), "is_error": False}  
        except Exception as e:  
            logger.exception("Tool execution failed", tool=func_name)  
            return {"content": f"执行异常：{e}", "is_error": True}  
  
    # ===================== 结构化输出 =====================  
    def _is_structure_extraction(self, message: Message, model_class: Type[T]) -> bool:  
        if not message.tool_calls or not self.supports_functions:  
            return False  
        extraction_name = StructureEngine.to_openai_tool(model_class)["function"]["name"]  
        return any(tc.get("function", {}).get("name") == extraction_name for tc in message.tool_calls)  
  
    async def _extract_and_retry(  
        self,  
        base_output: AgentOutput,  
        model_class: Type[T],  
        context: ExecutionContext,  
        llm_params: Dict[str, Any],  
        max_retries: int,  
    ) -> T:  
        for retry in range(max_retries + 1):  
            try:  
                tool_calls = self._extract_tool_calls(base_output)  
                result = await StructureEngine.parse(base_output.content, model_class, tool_calls)  
                logger.info("Structured output extracted", retries=retry)  
                return result  
            except ValueError as e:  
                if retry >= max_retries:  
                    logger.error("Structure extraction failed", retries=retry)  
                    raise AgentError(str(e))  
                logger.info("Retrying structure extraction", attempt=retry + 1)  
                base_output = await self._retry_with_feedback(str(e), context, llm_params)  
  
        raise AgentError("Structure extraction failed unexpectedly")  
  
    def _extract_tool_calls(self, output: AgentOutput) -> Optional[List[Dict[str, Any]]]:  
        if not output.raw:  
            return None  
        try:  
            return getattr(output.raw.choices[0].message, "tool_calls", None)  
        except (AttributeError, IndexError):  
            return None  
  
    async def _retry_with_feedback(  
        self,  
        error_message: str,  
        context: ExecutionContext,  
        llm_params: Dict[str, Any],  
    ) -> AgentOutput:  
        feedback = Message.user(f"Parsing error: {error_message}. Please format as valid JSON.")  
        context.add_message(feedback)  
  
        response = await self._call_llm(context, llm_params)  
        new_msg = self._parse_llm_response(response)  
        context.add_message(new_msg)  
  
        return AgentOutput(  
            content=new_msg.content or "",  
            raw=response,  
            tool_calls=getattr(new_msg, "tool_calls", None),  
        )  
  
    # ===================== 流式/peek =====================  
    async def _check_needs_tools(  
        self,  
        context: ExecutionContext,  
        llm_params: Dict[str, Any],  
    ) -> Tuple[bool, Optional[Any]]:  
        """  
        通过一次短输出的调用来判断是否需要工具。  
        返回 (需要工具, peek_response)，若模型已给出最终回复，则可复用 peek_response。  
        """  
        peek_params = dict(llm_params)  
        peek_params["max_tokens"] = min(50, peek_params.get("max_tokens", 50))  
  
        try:  
            response = await self._call_llm(context, peek_params)  
            msg = self._parse_llm_response(response)  
  
            if msg.tool_calls:  
                # 已经给出工具调用，则把该消息加入上下文  
                context.add_message(msg)  
                return True, None  
  
            # 无工具调用，直接返回 peek response 供上层复用  
            return False, response  
  
        except Exception as e:  
            logger.warning("Peek call failed, fallback to normal flow", error=str(e))  
            return False, None  
  
    async def _stream_final_response(  
        self,  
        context: ExecutionContext,  
        llm_params: Dict[str, Any],  
    ) -> AsyncIterator[str]:  
        messages_payload = [m.to_openai_format() for m in context.messages]  
        accumulated: List[str] = []  
  
        try:  
            async for chunk in self.model.astream(messages=messages_payload, **llm_params):  
                delta = chunk.choices[0].delta  
                if delta.content:  
                    accumulated.append(delta.content)  
                    yield delta.content  
        except Exception as e:  
            logger.error("Streaming failed", error=str(e))  
            raise  
  
        full_content = "".join(accumulated)  
        final_msg = Message.assistant(full_content)  
        context.add_message(final_msg)  
        context.metadata["last_response"] = accumulated  
  
    # ===================== 记忆保存 =====================  
    async def _save_context(self, context: ExecutionContext):  
        if not self.memory.storage or not self.memory.session_id:  
            return  
        try:  
            messages_data = [m.model_dump() for m in context.messages]  
            await self.memory.storage.set(self.memory.session_id, {"messages": messages_data})  
            logger.debug("Context saved", message_count=len(messages_data))  
        except Exception as e:  
            logger.error("Failed to save context", error=str(e))  
  
    # ===================== Hook/工具方法 =====================  
    async def _safe_call_hook(self, hook: Callable, *args, **kwargs):  
        try:  
            if asyncio.iscoroutinefunction(hook):  
                await hook(*args, **kwargs)  
            else:  
                hook(*args, **kwargs)  
        except Exception as e:  
            logger.warning("Hook execution failed", hook=getattr(hook, "__name__", str(hook)), error=str(e))  
```

[12] gecko/core/events.py
```python
# gecko/core/events.py  
"""  
事件总线（升级版）  
  
特性：  
1. BaseEvent 使用 Pydantic，所有字段默认安全可序列化  
2. Middleware 可修改事件；返回 None 表示拦截  
3. 订阅者支持异步/同步函数；错误被捕获并记录  
4. wait=False 时后台任务异常依然可追踪  
5. 支持 unsubscribe，便于测试或动态注销  
"""  
  
from __future__ import annotations  
  
import asyncio  
import inspect  
import time  
from typing import Any, Awaitable, Callable, Dict, List, Optional  
  
from pydantic import BaseModel, Field  
  
from gecko.core.logging import get_logger  
  
logger = get_logger(__name__)  
  
# ===== 事件模型 =====  
class BaseEvent(BaseModel):  
    type: str  
    timestamp: float = Field(default_factory=time.time)  
    data: Dict[str, Any] = Field(default_factory=dict)  
    error: Optional[str] = None  
  
  
EventHandler = Callable[[BaseEvent], Awaitable[None]]  
Middleware = Callable[[BaseEvent], Awaitable[BaseEvent | None]]  
  
  
class EventBus:  
    def __init__(self):  
        self._subscribers: Dict[str, List[EventHandler]] = {}  
        self._middlewares: List[Middleware] = []  
  
    # --- 订阅管理 ---  
    def subscribe(self, event_type: str, handler: EventHandler):  
        if not callable(handler):  
            raise TypeError("Event handler 必须是可调用的")  
        self._subscribers.setdefault(event_type, []).append(handler)  
        return self  
  
    def unsubscribe(self, event_type: str, handler: EventHandler):  
        handlers = self._subscribers.get(event_type, [])  
        if handler in handlers:  
            handlers.remove(handler)  
        return self  
  
    def add_middleware(self, middleware: Middleware):  
        self._middlewares.append(middleware)  
        return self  
  
    # --- 发布事件 ---  
    async def publish(self, event: BaseEvent, wait: bool = False):  
        # 1. 依次执行中间件，可修改事件或拦截  
        try:  
            for mw in self._middlewares:  
                new_event = await mw(event)  
                if new_event is None:  
                    logger.debug("Event blocked by middleware", event_type=event.type)  
                    return  
                event = new_event  
        except Exception as e:  
            logger.error("Middleware error", error=str(e))  
            return  # 中间件异常直接终止，避免传播不一致事件  
  
        # 2. 查找订阅者（支持通配符 "*")  
        handlers = self._subscribers.get(event.type) or self._subscribers.get("*", [])  
        if not handlers:  
            return  
  
        tasks = [self._safe_execute(handler, event) for handler in handlers]  
  
        if wait:  
            await asyncio.gather(*tasks, return_exceptions=True)  
        else:  
            for coro in tasks:  
                asyncio.create_task(self._log_task_exception(coro))  
  
    async def _safe_execute(self, handler: EventHandler, event: BaseEvent):  
        try:  
            if inspect.iscoroutinefunction(handler):  
                await handler(event)  
            else:  
                handler(event)  
        except Exception as e:  
            logger.exception("Event handler failed", event_type=event.type, error=str(e))  
  
    async def _log_task_exception(self, coro):  
        try:  
            await coro  
        except Exception as e:  
            logger.exception("Background event handler failed", error=str(e))  
  
  
# ==== 示例：常见事件类型 ====  
  
  
class AgentRunEvent(BaseEvent):  
    """Agent 运行过程事件"""  
    pass  
  
  
class WorkflowEvent(BaseEvent):  
    """Workflow 运行过程事件"""  
    pass  
```

[13] gecko/core/exceptions.py
```python
# gecko/core/exceptions.py
"""
Gecko 异常体系（改进版）

改进：移除装饰器，提倡显式错误处理
"""
from __future__ import annotations
from typing import Optional, Dict, Any

# ========== 异常基类 ==========

class GeckoError(Exception):
    """
    Gecko 统一异常基类
    
    设计原则：
    1. 包含结构化上下文
    2. 便于日志记录
    3. 支持异常链（from）
    """
    def __init__(
        self,
        message: str,
        *args,
        error_code: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        super().__init__(message, *args, **kwargs)
        self.message = message
        self.error_code = error_code or self.__class__.__name__
        self.context = context or {}
    
    def to_dict(self) -> Dict[str, Any]:
        """转换为字典（便于日志/API 返回）"""
        return {
            "error_type": self.__class__.__name__,
            "error_code": self.error_code,
            "message": self.message,
            "context": self.context,
        }
    
    def __str__(self) -> str:
        if self.context:
            ctx_str = ", ".join(f"{k}={v}" for k, v in self.context.items())
            return f"{self.message} [{ctx_str}]"
        return self.message

# ========== 领域异常 ==========

class AgentError(GeckoError):
    """Agent 执行异常"""
    pass

class ModelError(GeckoError):
    """模型调用异常"""
    pass

class ToolError(GeckoError):
    """工具执行异常"""
    pass

class ToolNotFoundError(ToolError):
    """工具未找到"""
    def __init__(self, tool_name: str):
        super().__init__(
            f"Tool '{tool_name}' not found in registry",
            error_code="TOOL_NOT_FOUND",
            context={"tool_name": tool_name}
        )

class ToolTimeoutError(ToolError):
    """工具超时"""
    def __init__(self, tool_name: str, timeout: float):
        super().__init__(
            f"Tool '{tool_name}' timed out after {timeout}s",
            error_code="TOOL_TIMEOUT",
            context={"tool_name": tool_name, "timeout": timeout}
        )

class WorkflowError(GeckoError):
    """工作流异常"""
    pass

class WorkflowCycleError(WorkflowError):
    """工作流循环依赖"""
    pass

class StorageError(GeckoError):
    """存储异常"""
    pass

class ConfigurationError(GeckoError):
    """配置错误"""
    pass

class ValidationError(GeckoError):
    """验证错误"""
    pass
```

[14] gecko/core/logging.py
```python
# gecko/core/logging.py
"""
Gecko 结构化日志系统（改进版）

改进：使用成熟的 structlog 库，代码减少 80%
"""
from __future__ import annotations
import logging
import sys
from typing import Any, Optional

try:
    import structlog
    STRUCTLOG_AVAILABLE = True
except ImportError:
    STRUCTLOG_AVAILABLE = False
    import warnings
    warnings.warn(
        "structlog not installed. Install with: pip install structlog\n"
        "Falling back to standard logging.",
        ImportWarning
    )

from gecko.config import settings

# ========== 日志初始化 ==========

_initialized = False

def setup_logging(
    level: Optional[str] = None,
    force: bool = False
):
    """
    初始化日志系统
    
    改进：
    1. 优先使用 structlog（如果可用）
    2. 降级到标准 logging（如果 structlog 未安装）
    """
    global _initialized
    
    if _initialized and not force:
        return
    
    level = level or settings.log_level
    log_level = getattr(logging, level.upper(), logging.INFO)
    
    if STRUCTLOG_AVAILABLE:
        _setup_structlog(log_level)
    else:
        _setup_standard_logging(log_level)
    
    # 降低第三方库日志级别
    for lib in ["httpx", "httpcore", "litellm", "openai"]:
        logging.getLogger(lib).setLevel(logging.WARNING)
    
    _initialized = True

def _setup_structlog(level: int):
    """配置 structlog"""
    structlog.configure(
        processors=[
            structlog.contextvars.merge_contextvars,
            structlog.processors.add_log_level,
            structlog.processors.StackInfoRenderer(),
            structlog.dev.set_exc_info,
            structlog.processors.TimeStamper(fmt="iso", utc=True),
            # 根据配置选择渲染器
            structlog.processors.JSONRenderer()
            if settings.log_format == "json"
            else structlog.dev.ConsoleRenderer(),
        ],
        wrapper_class=structlog.make_filtering_bound_logger(level),
        context_class=dict,
        logger_factory=structlog.PrintLoggerFactory(file=sys.stdout),
        cache_logger_on_first_use=True,
    )

def _setup_standard_logging(level: int):
    """配置标准 logging（降级方案）"""
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
        stream=sys.stdout,
    )

# ========== 获取 Logger ==========

def get_logger(name: str) -> Any:
    """
    获取 Logger 实例
    
    返回：
    - structlog.BoundLogger（如果可用）
    - logging.Logger（降级方案）
    
    使用示例:
        logger = get_logger(__name__)
        logger.info("event happened", user_id=123, action="login")
    """
    if not _initialized:
        setup_logging()
    
    if STRUCTLOG_AVAILABLE:
        return structlog.get_logger(name)
    else:
        return logging.getLogger(name)

# ========== 自动初始化 ==========

setup_logging()
```

[15] gecko/core/memory.py
```python
# gecko/core/memory.py
"""
Token Memory - 对话历史与上下文管理

核心功能：
1. Token 计数（基于 tiktoken）
2. LRU 缓存优化
3. 历史消息加载与裁剪
4. 多模态消息支持

优化点：
1. 改进缓存策略（批量计数也使用缓存）
2. 可配置的消息长度限制
3. 更安全的历史加载
4. 完善的缓存统计
5. 更好的错误处理
"""
from __future__ import annotations

import hashlib
import json
from collections import OrderedDict
from typing import Any, Dict, List, Optional

from gecko.core.logging import get_logger
from gecko.core.message import ContentBlock, Message
from gecko.plugins.storage.interfaces import SessionInterface

logger = get_logger(__name__)


class TokenMemory:
    """
    Token-aware 记忆管理器
    
    负责：
    - 计算消息的 token 数量
    - 管理对话历史（限制在 max_tokens 内）
    - 缓存 token 计数结果以提升性能
    
    示例:
        ```python
        memory = TokenMemory(
            session_id="user_123",
            storage=sqlite_storage,
            max_tokens=4000,
            model_name="gpt-4"
        )
        
        # 计算单条消息
        count = memory.count_message_tokens(Message.user("Hello"))
        print(f"Token count: {count}")
        
        # 批量计算
        messages = [Message.user("Hi"), Message.assistant("Hello")]
        counts = memory.count_messages_batch(messages)
        
        # 加载历史（自动裁剪）
        history = await memory.get_history(raw_messages)
        
        # 查看缓存统计
        stats = memory.get_cache_stats()
        print(f"Cache hit rate: {stats['hit_rate']:.1%}")
        ```
    """

    def __init__(
        self,
        session_id: str,
        storage: Optional[SessionInterface] = None,
        max_tokens: int = 4000,
        model_name: str = "gpt-3.5-turbo",
        cache_size: int = 1000,
        max_message_length: int = 10000,
        enable_cache_for_batch: bool = True,
    ):
        """
        初始化 TokenMemory
        
        参数:
            session_id: 会话唯一标识
            storage: 可选的持久化存储
            max_tokens: 上下文窗口最大 token 数
            model_name: 模型名称（用于选择 tiktoken encoder）
            cache_size: LRU 缓存大小
            max_message_length: 单条消息最大字符长度（防止极端情况）
            enable_cache_for_batch: 批量计数时是否使用缓存
        """
        if max_tokens <= 0:
            raise ValueError(f"max_tokens 必须为正数，收到: {max_tokens}")
        
        if cache_size <= 0:
            raise ValueError(f"cache_size 必须为正数，收到: {cache_size}")
        
        self.session_id = session_id
        self.storage = storage
        self.max_tokens = max_tokens
        self.model_name = model_name
        self.cache_size = cache_size
        self.max_message_length = max_message_length
        self.enable_cache_for_batch = enable_cache_for_batch
        
        # 延迟初始化的 tokenizer
        self._encoding = None
        
        # LRU 缓存（OrderedDict 实现）
        self._token_cache: OrderedDict[str, int] = OrderedDict()
        
        # 缓存统计
        self._cache_hits = 0
        self._cache_misses = 0
        self._cache_evictions = 0

    # ====================== Tokenizer（延迟加载）======================

    @property
    def tokenizer(self):
        """
        延迟加载 tiktoken encoder
        
        优势：
        1. 仅在首次使用时加载
        2. 避免不必要的依赖
        3. 支持模型名称降级
        """
        if self._encoding is None:
            try:
                import tiktoken
                
                try:
                    # 尝试按模型名称加载
                    self._encoding = tiktoken.encoding_for_model(self.model_name)
                    logger.debug("Tokenizer loaded", model=self.model_name)
                except KeyError:
                    # 模型未知，降级到 cl100k_base（GPT-4/3.5 的编码）
                    logger.warning(
                        "Unknown model for tiktoken, fallback to cl100k_base",
                        model=self.model_name
                    )
                    self._encoding = tiktoken.get_encoding("cl100k_base")
                    
            except ImportError as e:
                raise ImportError(
                    "TokenMemory 需要 tiktoken 库。请安装：pip install tiktoken"
                ) from e
            except Exception as e:
                logger.error("Failed to load tokenizer", error=str(e))
                raise RuntimeError(f"Tokenizer 加载失败: {e}") from e
        
        return self._encoding

    # ====================== 单条消息计数（带缓存）======================

    def count_message_tokens(self, message: Message) -> int:
        """
        计算单条消息的 token 数（带缓存）
        
        参数:
            message: Message 对象
        
        返回:
            token 数量
        
        缓存策略:
            - 使用 MD5 哈希作为缓存键
            - LRU 淘汰最久未使用的条目
        """
        cache_key = self._make_cache_key(message)
        
        # 检查缓存
        if cache_key in self._token_cache:
            self._cache_hits += 1
            # 移动到末尾（标记为最近使用）
            self._token_cache.move_to_end(cache_key)
            return self._token_cache[cache_key]
        
        # 缓存未命中，计算 token
        self._cache_misses += 1
        token_count = self._count_tokens_impl(message)
        
        # 存入缓存
        self._cache_token_count(cache_key, token_count)
        
        return token_count

    def _make_cache_key(self, message: Message) -> str:
        """
        生成消息的缓存键（使用 MD5 哈希）
        
        包含：
        - role
        - content（文本或多模态）
        - tool_calls（如果有）
        
        注意：使用 JSON 序列化确保一致性
        """
        # 构建键内容
        key_data = {
            "role": message.role,
            "content": self._serialize_content(message.content),
        }
        
        # 包含 tool_calls（如果存在）
        if message.tool_calls:
            # 排序确保一致性
            key_data["tool_calls"] = json.dumps(
                message.tool_calls,
                sort_keys=True,
                ensure_ascii=False
            )
        
        # 序列化并哈希
        raw = json.dumps(key_data, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(raw.encode('utf-8')).hexdigest()

    def _serialize_content(self, content: str | List[ContentBlock]) -> str | List[str]:
        """
        序列化消息内容（用于缓存键生成）
        """
        if isinstance(content, str):
            return content
        elif isinstance(content, list):
            # 多模态消息：提取文本和类型
            parts = []
            for block in content:
                if block.type == "text" and block.text:
                    parts.append(f"text:{block.text}")
                elif block.type == "image_url":
                    # 图片只记录类型和 URL（不包含 base64 数据）
                    url = ""
                    if block.image_url:
                        url = block.image_url.url or "base64_image"
                    parts.append(f"image:{url}")
            return parts
        else:
            return str(content)

    def _cache_token_count(self, key: str, count: int):
        """
        将 token 计数存入缓存（LRU 策略）
        """
        self._token_cache[key] = count
        self._token_cache.move_to_end(key)
        
        # 检查缓存大小，必要时淘汰
        if len(self._token_cache) > self.cache_size:
            # 移除最早的条目
            self._token_cache.popitem(last=False)
            self._cache_evictions += 1

    # ====================== 批量计数 ======================

    def count_messages_batch(
        self,
        messages: List[Message],
        use_cache: Optional[bool] = None
    ) -> List[int]:
        """
        批量计算消息的 token 数
        
        参数:
            messages: 消息列表
            use_cache: 是否使用缓存（None 则使用配置的默认值）
        
        返回:
            token 数量列表（与输入顺序一致）
        
        优化：
        1. 可选地复用缓存
        2. 共享 encoder 避免重复创建
        """
        if not messages:
            return []
        
        # 确定是否使用缓存
        should_use_cache = (
            use_cache
            if use_cache is not None
            else self.enable_cache_for_batch
        )
        
        if should_use_cache:
            # 使用缓存：逐个检查/计算
            return [self.count_message_tokens(msg) for msg in messages]
        else:
            # 不使用缓存：直接计算（共享 encoder）
            encode = self.tokenizer.encode
            return [self._count_tokens_impl(msg, encode=encode) for msg in messages]

    def _count_tokens_impl(
        self,
        message: Message,
        encode=None
    ) -> int:
        """
        实际的 token 计数实现
        
        参数:
            message: Message 对象
            encode: 可选的 encoder 函数（复用以提升性能）
        
        返回:
            token 数量
        
        计算规则：
        - 内容 tokens
        - 角色开销（约 4 tokens）
        - tool_calls 开销
        """
        encode = encode or self.tokenizer.encode
        content_tokens = 0
        
        # 计算内容 tokens
        if isinstance(message.content, str):
            content_tokens = len(encode(message.content))
        elif isinstance(message.content, list):
            # 多模态消息：累加文本部分
            text_parts = []
            for block in message.content:
                if block.type == "text" and block.text:
                    text_parts.append(block.text)
                elif block.type == "image_url":
                    # 图片 token 估算（OpenAI 的图片 token 计算较复杂）
                    # 这里简化为固定值（实际应根据图片分辨率）
                    text_parts.append("[image]")
            
            combined_text = " ".join(text_parts)
            content_tokens = len(encode(combined_text))
        
        # 角色开销（每条消息约 4 tokens）
        overhead = 4
        
        # tool_calls 开销
        if message.tool_calls:
            try:
                tool_calls_str = json.dumps(message.tool_calls)
                overhead += len(encode(tool_calls_str))
            except Exception as e:
                logger.warning("Failed to encode tool_calls", error=str(e))
                overhead += 50  # 估算值
        
        return content_tokens + overhead

    # ====================== 历史加载（带裁剪）======================

    async def get_history(
        self,
        raw_messages: List[dict],
        preserve_system: bool = True
    ) -> List[Message]:
        """
        加载并裁剪历史消息，确保不超过 max_tokens
        
        参数:
            raw_messages: 原始消息字典列表
            preserve_system: 是否优先保留 system 消息
        
        返回:
            Message 列表（已裁剪）
        
        策略：
        1. 解析并验证消息
        2. 限制单条消息长度
        3. 优先保留 system 消息
        4. 从最新消息开始累加，直到达到 token 限制
        """
        if not raw_messages:
            logger.debug("No history messages to load")
            return []
        
        # 1. 解析消息
        messages: List[Message] = []
        for idx, entry in enumerate(raw_messages):
            try:
                msg = Message(**entry)
                
                # 限制单条消息长度（防止极端情况）
                if isinstance(msg.content, str):
                    if len(msg.content) > self.max_message_length:
                        logger.warning(
                            "Message content truncated",
                            original_length=len(msg.content),
                            max_length=self.max_message_length
                        )
                        msg.content = msg.content[:self.max_message_length]
                
                messages.append(msg)
                
            except Exception as e:
                logger.warning(
                    "Invalid history message, skipping",
                    index=idx,
                    error=str(e)
                )
                continue
        
        if not messages:
            logger.warning("All history messages are invalid")
            return []
        
        # 2. 分离 system 消息
        system_msg = None
        other_messages = messages
        
        if preserve_system and messages[0].role == "system":
            system_msg = messages[0]
            other_messages = messages[1:]
        
        # 3. 计算 system 消息的 tokens
        current_tokens = 0
        if system_msg:
            current_tokens = self.count_message_tokens(system_msg)
            
            # 检查 system 消息是否已超过限制
            if current_tokens >= self.max_tokens:
                logger.error(
                    "System message exceeds max_tokens",
                    system_tokens=current_tokens,
                    max_tokens=self.max_tokens
                )
                # 强制截断 system 消息
                if isinstance(system_msg.content, str):
                    truncate_length = int(len(system_msg.content) * self.max_tokens / current_tokens)
                    system_msg.content = system_msg.content[:truncate_length]
                    current_tokens = self.count_message_tokens(system_msg)
        
        # 4. 从最新消息开始累加（倒序）
        selected: List[Message] = []
        
        for msg in reversed(other_messages):
            msg_tokens = self.count_message_tokens(msg)
            
            # 检查是否会超过限制
            if current_tokens + msg_tokens > self.max_tokens:
                logger.debug(
                    "Reached token limit, stopping history loading",
                    current_tokens=current_tokens,
                    max_tokens=self.max_tokens,
                    total_messages=len(other_messages),
                    selected_messages=len(selected)
                )
                break
            
            selected.insert(0, msg)
            current_tokens += msg_tokens
        
        # 5. 重新加入 system 消息
        if system_msg:
            selected.insert(0, system_msg)
        
        logger.info(
            "History loaded",
            session_id=self.session_id,
            total_messages=len(messages),
            selected_messages=len(selected),
            total_tokens=current_tokens,
            max_tokens=self.max_tokens
        )
        
        return selected

    # ====================== 缓存管理 ======================

    def clear_cache(self):
        """清空 token 计数缓存"""
        cleared_size = len(self._token_cache)
        self._token_cache.clear()
        self._cache_hits = 0
        self._cache_misses = 0
        self._cache_evictions = 0
        
        logger.info("Token cache cleared", cleared_entries=cleared_size)

    def get_cache_stats(self) -> Dict[str, Any]:
        """
        获取缓存统计信息
        
        返回:
            包含缓存命中率、大小等信息的字典
        """
        total_requests = self._cache_hits + self._cache_misses
        hit_rate = self._cache_hits / total_requests if total_requests > 0 else 0.0
        
        return {
            "cache_size": len(self._token_cache),
            "max_cache_size": self.cache_size,
            "cache_utilization": len(self._token_cache) / self.cache_size,
            "hits": self._cache_hits,
            "misses": self._cache_misses,
            "evictions": self._cache_evictions,
            "total_requests": total_requests,
            "hit_rate": hit_rate,
        }

    def print_cache_stats(self):
        """打印缓存统计信息（格式化输出）"""
        stats = self.get_cache_stats()
        
        print("\n" + "=" * 60)
        print("Token Cache Statistics".center(60))
        print("=" * 60)
        print(f"Cache Size:        {stats['cache_size']} / {stats['max_cache_size']}")
        print(f"Cache Utilization: {stats['cache_utilization']:.1%}")
        print(f"Total Requests:    {stats['total_requests']}")
        print(f"Cache Hits:        {stats['hits']}")
        print(f"Cache Misses:      {stats['misses']}")
        print(f"Cache Evictions:   {stats['evictions']}")
        print(f"Hit Rate:          {stats['hit_rate']:.1%}")
        print("=" * 60 + "\n")

    # ====================== 工具方法 ======================

    def estimate_tokens(self, text: str) -> int:
        """
        快速估算文本的 token 数（不使用缓存）
        
        用于：
        - 快速预估
        - 不需要精确计数的场景
        """
        return len(self.tokenizer.encode(text))

    def __repr__(self) -> str:
        """字符串表示"""
        return (
            f"TokenMemory("
            f"session_id='{self.session_id}', "
            f"max_tokens={self.max_tokens}, "
            f"model='{self.model_name}', "
            f"cache_size={len(self._token_cache)}/{self.cache_size}"
            f")"
        )
```

[16] gecko/core/message.py
```python
# gecko/core/message.py
"""
Message 模型 - 对话消息的标准表示

核心功能：
1. 统一的消息格式（兼容 OpenAI API）
2. 多模态内容支持（文本 + 图片）
3. 工具调用支持
4. 类型安全的工厂方法

优化点：
1. 异步文件加载
2. 更好的文件大小检查
3. 消息验证
4. 边缘情况处理
5. 工具方法扩展
"""
from __future__ import annotations

import asyncio
import base64
import mimetypes
from pathlib import Path
from typing import Any, Dict, List, Literal, Optional, Union

from pydantic import BaseModel, Field, field_serializer, field_validator, model_validator

from gecko.core.logging import get_logger

logger = get_logger(__name__)

# ===== 类型定义 =====

Role = Literal["system", "user", "assistant", "tool"]


# ===== 媒体资源 =====

class MediaResource(BaseModel):
    """
    媒体资源（主要用于图片）
    
    支持：
    - URL（http/https）
    - Base64 编码的数据
    - 本地文件路径（通过工厂方法）
    
    示例:
        ```python
        # 从 URL
        img = MediaResource(url="https://example.com/image.jpg")
        
        # 从本地文件（同步）
        img = MediaResource.from_file("./image.png")
        
        # 从本地文件（异步）
        img = await MediaResource.from_file_async("./large_image.png")
        
        # 从 base64
        img = MediaResource(
            base64_data="iVBORw0KG...",
            mime_type="image/png"
        )
        ```
    """
    url: Optional[str] = None
    base64_data: Optional[str] = None
    mime_type: Optional[str] = None
    detail: Literal["auto", "low", "high"] = "auto"

    @model_validator(mode="after")
    def validate_source(self):
        """验证至少提供了一个数据源"""
        if not self.url and not self.base64_data:
            raise ValueError("必须提供 url 或 base64_data")
        return self

    @classmethod
    def from_file(
        cls,
        path: str,
        mime_type: Optional[str] = None,
        max_size_mb: int = 5,
        detail: Literal["auto", "low", "high"] = "auto"
    ) -> MediaResource:
        """
        从本地文件加载（同步版本）
        
        参数:
            path: 文件路径
            mime_type: MIME 类型（None 则自动推断）
            max_size_mb: 最大文件大小（MB）
            detail: 图片质量（OpenAI API 参数）
        
        返回:
            MediaResource 实例
        
        异常:
            FileNotFoundError: 文件不存在
            ValueError: 文件过大
        
        注意:
            这是同步方法，会阻塞事件循环。
            对于大文件，建议使用 from_file_async()
        """
        p = Path(path)
        
        # 检查文件是否存在
        if not p.exists():
            raise FileNotFoundError(f"文件不存在: {path}")
        
        if not p.is_file():
            raise ValueError(f"路径不是文件: {path}")
        
        # ✅ 优化：先检查文件大小，再读取
        file_size = p.stat().st_size
        max_size_bytes = max_size_mb * 1024 * 1024
        
        if file_size > max_size_bytes:
            raise ValueError(
                f"文件过大: {file_size / 1024 / 1024:.2f} MB "
                f"(最大 {max_size_mb} MB)"
            )
        
        # 读取并编码
        try:
            with open(p, "rb") as f:
                encoded = base64.b64encode(f.read()).decode("utf-8")
        except Exception as e:
            raise IOError(f"文件读取失败: {e}") from e
        
        # 推断 MIME 类型
        mime = mime_type or mimetypes.guess_type(p.name)[0] or "application/octet-stream"
        
        logger.debug(
            "Media loaded from file",
            path=path,
            size_kb=file_size / 1024,
            mime_type=mime
        )
        
        return cls(
            base64_data=encoded,
            mime_type=mime,
            detail=detail
        )

    @classmethod
    async def from_file_async(
        cls,
        path: str,
        mime_type: Optional[str] = None,
        max_size_mb: int = 5,
        detail: Literal["auto", "low", "high"] = "auto"
    ) -> MediaResource:
        """
        从本地文件加载（异步版本）
        
        对于大文件，使用此方法避免阻塞事件循环
        
        参数:
            同 from_file()
        
        返回:
            MediaResource 实例
        """
        p = Path(path)
        
        # 检查文件
        if not p.exists():
            raise FileNotFoundError(f"文件不存在: {path}")
        
        if not p.is_file():
            raise ValueError(f"路径不是文件: {path}")
        
        # 检查大小
        file_size = p.stat().st_size
        max_size_bytes = max_size_mb * 1024 * 1024
        
        if file_size > max_size_bytes:
            raise ValueError(
                f"文件过大: {file_size / 1024 / 1024:.2f} MB "
                f"(最大 {max_size_mb} MB)"
            )
        
        # ✅ 异步读取文件（在线程池中执行）
        def _read_file():
            with open(p, "rb") as f:
                return base64.b64encode(f.read()).decode("utf-8")
        
        try:
            encoded = await asyncio.to_thread(_read_file)
        except Exception as e:
            raise IOError(f"文件读取失败: {e}") from e
        
        # 推断 MIME 类型
        mime = mime_type or mimetypes.guess_type(p.name)[0] or "application/octet-stream"
        
        logger.debug(
            "Media loaded from file (async)",
            path=path,
            size_kb=file_size / 1024,
            mime_type=mime
        )
        
        return cls(
            base64_data=encoded,
            mime_type=mime,
            detail=detail
        )

    def to_openai_image_url(self) -> Dict[str, Any]:
        """
        转换为 OpenAI API 所需的 image_url 格式
        
        返回:
            符合 OpenAI 规范的字典
        """
        # 构建 URL
        if self.url:
            url_value = self.url
        elif self.base64_data:
            mime = self.mime_type or "image/jpeg"
            url_value = f"data:{mime};base64,{self.base64_data}"
        else:
            raise ValueError("MediaResource 缺少 URL 或 base64_data")
        
        return {
            "url": url_value,
            "detail": self.detail
        }

    def get_size_estimate(self) -> int:
        """
        估算数据大小（字节）
        
        返回:
            估算的字节数
        """
        if self.base64_data:
            # Base64 编码后的大小约为原始大小的 4/3
            return int(len(self.base64_data) * 3 / 4)
        elif self.url:
            # URL 无法估算实际大小
            return 0
        return 0


# ===== 内容块 =====

class ContentBlock(BaseModel):
    """
    消息内容块（用于多模态消息）
    
    支持：
    - 文本块
    - 图片块
    
    示例:
        ```python
        # 文本块
        text = ContentBlock(type="text", text="Hello")
        
        # 图片块
        image = ContentBlock(
            type="image_url",
            image_url=MediaResource(url="https://...")
        )
        ```
    """
    type: Literal["text", "image_url"]
    text: Optional[str] = None
    image_url: Optional[MediaResource] = None

    @model_validator(mode="after")
    def ensure_valid(self):
        """验证块的完整性"""
        if self.type == "text":
            if self.text is None:
                raise ValueError("文本块缺少 text 字段")
        elif self.type == "image_url":
            if self.image_url is None:
                raise ValueError("图片块缺少 image_url 字段")
        return self

    def to_openai_format(self) -> Dict[str, Any]:
        """转换为 OpenAI API 格式"""
        if self.type == "text":
            return {"type": "text", "text": self.text}
        elif self.type == "image_url":
            return {
                "type": "image_url",
                "image_url": self.image_url.to_openai_image_url()
            }
        else:
            raise ValueError(f"未知的内容类型: {self.type}")

    def get_text_content(self) -> str:
        """
        提取文本内容（用于调试/日志）
        
        返回:
            文本内容或占位符
        """
        if self.type == "text":
            return self.text or ""
        elif self.type == "image_url":
            return "[image]"
        return ""


# ===== 消息 =====

class Message(BaseModel):
    """
    标准消息对象
    
    兼容 OpenAI Chat Completion API 格式
    
    示例:
        ```python
        # 简单文本消息
        msg = Message.user("Hello!")
        
        # 多模态消息
        msg = Message.user(
            text="What's in this image?",
            images=["./photo.jpg"]
        )
        
        # 助手消息
        msg = Message.assistant("I'm here to help!")
        
        # 工具返回消息
        msg = Message.tool_result(
            tool_call_id="call_123",
            content="Search results: ...",
            tool_name="search"
        )
        
        # 从 OpenAI 格式解析
        msg = Message.from_openai({
            "role": "user",
            "content": "Hello"
        })
        ```
    """
    role: Role
    content: Union[str, List[ContentBlock]] = Field(default="")
    name: Optional[str] = None
    tool_calls: Optional[List[Dict[str, Any]]] = None
    tool_call_id: Optional[str] = None

    @field_validator("content", mode="before")
    @classmethod
    def validate_content(cls, v):
        """验证并规范化 content"""
        if v is None:
            return ""
        return v

    @field_serializer("content")
    def serialize_content(self, content: Union[str, List[ContentBlock]], _info):
        """序列化 content 为 OpenAI 格式"""
        if isinstance(content, str):
            return content
        elif isinstance(content, list):
            return [block.to_openai_format() for block in content]
        return str(content)

    # ===== 工厂方法 =====

    @classmethod
    def user(
        cls,
        text: str = "",
        images: Optional[List[str]] = None,
        name: Optional[str] = None
    ) -> Message:
        """
        创建用户消息
        
        参数:
            text: 文本内容
            images: 图片路径列表（URL 或本地文件）
            name: 用户名称（可选）
        
        返回:
            Message 实例
        
        示例:
            ```python
            # 纯文本
            msg = Message.user("Hello")
            
            # 文本 + 图片
            msg = Message.user(
                text="What's this?",
                images=["./photo.jpg", "https://example.com/img.png"]
            )
            ```
        """
        if not images:
            return cls(role="user", content=text, name=name)
        
        # 构建多模态内容
        blocks: List[ContentBlock] = []
        
        # 添加文本块
        if text:
            blocks.append(ContentBlock(type="text", text=text))
        
        # 添加图片块
        for img in images:
            try:
                # 判断是 URL 还是本地路径
                if img.startswith(("http://", "https://", "data:")):
                    resource = MediaResource(url=img)
                else:
                    resource = MediaResource.from_file(img)
                
                blocks.append(ContentBlock(type="image_url", image_url=resource))
            except Exception as e:
                logger.error("Failed to load image", path=img, error=str(e))
                # 继续处理其他图片
        
        return cls(role="user", content=blocks, name=name)

    @classmethod
    async def user_async(
        cls,
        text: str = "",
        images: Optional[List[str]] = None,
        name: Optional[str] = None
    ) -> Message:
        """
        创建用户消息（异步版本）
        
        对于大量或大文件图片，使用此方法避免阻塞
        """
        if not images:
            return cls(role="user", content=text, name=name)
        
        blocks: List[ContentBlock] = []
        
        if text:
            blocks.append(ContentBlock(type="text", text=text))
        
        # 异步加载所有图片
        async def _load_image(img: str) -> Optional[ContentBlock]:
            try:
                if img.startswith(("http://", "https://", "data:")):
                    resource = MediaResource(url=img)
                else:
                    resource = await MediaResource.from_file_async(img)
                return ContentBlock(type="image_url", image_url=resource)
            except Exception as e:
                logger.error("Failed to load image (async)", path=img, error=str(e))
                return None
        
        # 并发加载所有图片
        image_blocks = await asyncio.gather(*[_load_image(img) for img in images])
        blocks.extend([b for b in image_blocks if b is not None])
        
        return cls(role="user", content=blocks, name=name)

    @classmethod
    def assistant(cls, content: str, name: Optional[str] = None) -> Message:
        """
        创建助手消息
        
        参数:
            content: 回复内容
            name: 助手名称（可选）
        """
        return cls(role="assistant", content=content, name=name)

    @classmethod
    def system(cls, content: str) -> Message:
        """
        创建系统消息
        
        参数:
            content: 系统提示词
        """
        return cls(role="system", content=content)

    @classmethod
    def tool_result(
        cls,
        tool_call_id: str,
        content: Any,
        tool_name: str
    ) -> Message:
        """
        创建工具返回消息
        
        参数:
            tool_call_id: 工具调用 ID
            content: 工具返回结果（任意类型，会自动序列化）
            tool_name: 工具名称
        
        返回:
            Message 实例
        """
        # 序列化 content
        if isinstance(content, str):
            serialized = content
        elif isinstance(content, (dict, list)):
            import json
            serialized = json.dumps(content, ensure_ascii=False, indent=2)
        else:
            serialized = str(content)
        
        return cls(
            role="tool",
            content=serialized,
            tool_call_id=tool_call_id,
            name=tool_name
        )

    @classmethod
    def from_openai(cls, payload: Dict[str, Any]) -> Message:
        """
        从 OpenAI API 格式解析消息
        
        参数:
            payload: OpenAI 格式的消息字典
        
        返回:
            Message 实例
        
        示例:
            ```python
            openai_msg = {
                "role": "assistant",
                "content": "Hello!",
                "tool_calls": [...]
            }
            msg = Message.from_openai(openai_msg)
            ```
        """
        try:
            return cls(**payload)
        except Exception as e:
            logger.error("Failed to parse OpenAI message", error=str(e), payload=payload)
            raise ValueError(f"无效的 OpenAI 消息格式: {e}") from e

    # ===== 转换方法 =====

    def to_openai_format(self) -> Dict[str, Any]:
        """
        转换为 OpenAI API 格式
        
        返回:
            符合 OpenAI 规范的字典
        """
        # 使用 Pydantic 的序列化（会调用 field_serializer）
        data = self.model_dump(exclude_none=True, mode="json")
        
        # 确保必要字段存在
        if "role" not in data:
            raise ValueError("消息缺少 role 字段")
        
        return data

    # ===== 工具方法 =====

    def get_text_content(self) -> str:
        """
        提取文本内容（忽略多模态部分）
        
        返回:
            纯文本内容
        
        用途:
            - 日志记录
            - 文本搜索
            - Token 估算
        """
        if isinstance(self.content, str):
            return self.content
        elif isinstance(self.content, list):
            text_parts = []
            for block in self.content:
                text = block.get_text_content()
                if text:
                    text_parts.append(text)
            return " ".join(text_parts)
        return ""

    def is_empty(self) -> bool:
        """
        检查消息是否为空
        
        返回:
            是否为空消息
        """
        if isinstance(self.content, str):
            return not self.content.strip()
        elif isinstance(self.content, list):
            return len(self.content) == 0
        return True

    def has_images(self) -> bool:
        """
        检查消息是否包含图片
        
        返回:
            是否包含图片
        """
        if isinstance(self.content, list):
            return any(block.type == "image_url" for block in self.content)
        return False

    def get_image_count(self) -> int:
        """
        获取图片数量
        
        返回:
            图片数量
        """
        if isinstance(self.content, list):
            return sum(1 for block in self.content if block.type == "image_url")
        return 0

    def clone(self) -> Message:
        """
        创建消息的深拷贝
        
        返回:
            新的 Message 实例
        """
        return Message.model_validate(self.model_dump())

    def truncate_content(self, max_length: int) -> Message:
        """
        截断消息内容（返回新消息）
        
        参数:
            max_length: 最大字符长度
        
        返回:
            截断后的新消息
        
        注意:
            仅截断文本内容，图片保持不变
        """
        if isinstance(self.content, str):
            if len(self.content) > max_length:
                truncated = self.content[:max_length] + "..."
                return Message(
                    role=self.role,
                    content=truncated,
                    name=self.name,
                    tool_calls=self.tool_calls,
                    tool_call_id=self.tool_call_id
                )
        
        # 多模态消息：截断文本块
        elif isinstance(self.content, list):
            new_blocks = []
            for block in self.content:
                if block.type == "text" and block.text:
                    if len(block.text) > max_length:
                        new_blocks.append(ContentBlock(
                            type="text",
                            text=block.text[:max_length] + "..."
                        ))
                    else:
                        new_blocks.append(block)
                else:
                    new_blocks.append(block)
            
            return Message(
                role=self.role,
                content=new_blocks,
                name=self.name,
                tool_calls=self.tool_calls,
                tool_call_id=self.tool_call_id
            )
        
        return self

    def __str__(self) -> str:
        """字符串表示（用于调试）"""
        text = self.get_text_content()
        preview = text[:50] + "..." if len(text) > 50 else text
        
        extra = []
        if self.has_images():
            extra.append(f"{self.get_image_count()} images")
        if self.tool_calls:
            extra.append(f"{len(self.tool_calls)} tool_calls")
        
        extra_str = f" ({', '.join(extra)})" if extra else ""
        
        return f"Message(role={self.role}, content='{preview}'{extra_str})"

    def __repr__(self) -> str:
        """详细表示"""
        return (
            f"Message("
            f"role={self.role!r}, "
            f"content={self.get_text_content()[:30]!r}, "
            f"has_images={self.has_images()}, "
            f"tool_calls={'Yes' if self.tool_calls else 'No'}"
            f")"
        )
```

[17] gecko/core/output.py
```python
# gecko/core/output.py
"""
Agent 输出模型

定义 Agent 执行后的标准输出格式，包含：
- 最终回复内容
- 工具调用信息
- Token 使用统计
- 原始模型响应

优化点：
1. 结构化的 Usage 模型
2. 输出验证和后处理
3. 丰富的工具方法
4. 格式化输出
5. 统计信息提取
"""
from __future__ import annotations

from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field, field_validator, model_validator

from gecko.core.logging import get_logger

logger = get_logger(__name__)


# ===== Token 使用统计 =====

class TokenUsage(BaseModel):
    """
    Token 使用统计
    
    符合 OpenAI API 的 usage 格式
    
    示例:
        ```python
        usage = TokenUsage(
            prompt_tokens=100,
            completion_tokens=50,
            total_tokens=150
        )
        ```
    """
    prompt_tokens: int = Field(
        default=0,
        ge=0,
        description="提示词（输入）消耗的 tokens"
    )
    completion_tokens: int = Field(
        default=0,
        ge=0,
        description="生成（输出）消耗的 tokens"
    )
    total_tokens: int = Field(
        default=0,
        ge=0,
        description="总消耗 tokens"
    )
    
    # 扩展字段（某些模型提供）
    prompt_tokens_details: Optional[Dict[str, int]] = Field(
        default=None,
        description="提示词 tokens 详细信息"
    )
    completion_tokens_details: Optional[Dict[str, int]] = Field(
        default=None,
        description="生成 tokens 详细信息"
    )

    @model_validator(mode="after")
    def validate_total(self):
        """验证总 tokens 是否正确"""
        calculated_total = self.prompt_tokens + self.completion_tokens
        
        # 如果 total_tokens 为 0，自动计算
        if self.total_tokens == 0:
            self.total_tokens = calculated_total
        
        # 如果不一致，记录警告
        elif self.total_tokens != calculated_total:
            logger.warning(
                "Token usage total mismatch",
                total=self.total_tokens,
                calculated=calculated_total
            )
        
        return self

    def get_cost_estimate(
        self,
        prompt_price_per_1k: float = 0.0,
        completion_price_per_1k: float = 0.0
    ) -> float:
        """
        估算成本（美元）
        
        参数:
            prompt_price_per_1k: 输入 token 每 1000 个的价格
            completion_price_per_1k: 输出 token 每 1000 个的价格
        
        返回:
            估算成本（美元）
        
        示例:
            ```python
            # GPT-4 价格（示例）
            cost = usage.get_cost_estimate(
                prompt_price_per_1k=0.03,      # $0.03/1K tokens
                completion_price_per_1k=0.06   # $0.06/1K tokens
            )
            print(f"Estimated cost: ${cost:.4f}")
            ```
        """
        prompt_cost = (self.prompt_tokens / 1000) * prompt_price_per_1k
        completion_cost = (self.completion_tokens / 1000) * completion_price_per_1k
        return prompt_cost + completion_cost

    def __str__(self) -> str:
        """简洁的字符串表示"""
        return (
            f"TokenUsage("
            f"prompt={self.prompt_tokens}, "
            f"completion={self.completion_tokens}, "
            f"total={self.total_tokens}"
            f")"
        )


# ===== Agent 输出 =====

class AgentOutput(BaseModel):
    """
    Agent 执行结果
    
    包含 Agent 执行后的完整输出信息。
    
    属性:
        content: 最终文本回复（可能为空，如果只有工具调用）
        tool_calls: 工具调用列表
        usage: Token 使用统计（可选）
        raw: 原始模型响应（用于调试）
        metadata: 附加元数据
    
    示例:
        ```python
        # 简单文本输出
        output = AgentOutput(content="Hello, how can I help?")
        
        # 带工具调用的输出
        output = AgentOutput(
            content="I'll search for that information.",
            tool_calls=[
                {
                    "id": "call_1",
                    "function": {
                        "name": "search",
                        "arguments": '{"query": "AI"}'
                    }
                }
            ],
            usage=TokenUsage(
                prompt_tokens=100,
                completion_tokens=50
            )
        )
        
        # 检查输出
        if output.has_tool_calls():
            print(f"需要执行 {output.tool_call_count()} 个工具")
        
        if output.has_content():
            print(f"回复: {output.content}")
        ```
    """
    content: str = Field(
        default="",
        description="最终文本回复"
    )
    tool_calls: List[Dict[str, Any]] = Field(
        default_factory=list,
        description="工具调用列表（OpenAI 格式）"
    )
    usage: Optional[TokenUsage] = Field(
        default=None,
        description="Token 使用统计"
    )
    raw: Any = Field(
        default=None,
        description="原始模型响应（用于调试）"
    )
    metadata: Dict[str, Any] = Field(
        default_factory=dict,
        description="附加元数据"
    )

    model_config = {"arbitrary_types_allowed": True}

    @field_validator("tool_calls", mode="before")
    @classmethod
    def ensure_tool_calls(cls, value):
        """确保 tool_calls 始终是列表"""
        if value is None:
            return []
        if not isinstance(value, list):
            logger.warning("tool_calls should be a list", type=type(value).__name__)
            return []
        return value

    @field_validator("content", mode="before")
    @classmethod
    def ensure_content(cls, value):
        """确保 content 是字符串"""
        if value is None:
            return ""
        if not isinstance(value, str):
            return str(value)
        return value

    # ===== 检查方法 =====

    def has_content(self) -> bool:
        """
        检查是否有文本内容
        
        返回:
            是否有非空文本
        """
        return bool(self.content and self.content.strip())

    def has_tool_calls(self) -> bool:
        """
        检查是否有工具调用
        
        返回:
            是否包含工具调用
        """
        return len(self.tool_calls) > 0

    def tool_call_count(self) -> int:
        """
        获取工具调用数量
        
        返回:
            工具调用的数量
        """
        return len(self.tool_calls)

    def is_empty(self) -> bool:
        """
        检查输出是否完全为空
        
        返回:
            是否既无内容也无工具调用
        """
        return not self.has_content() and not self.has_tool_calls()

    def has_usage(self) -> bool:
        """
        检查是否有 usage 信息
        
        返回:
            是否包含 token 使用统计
        """
        return self.usage is not None

    # ===== 提取方法 =====

    def get_tool_names(self) -> List[str]:
        """
        提取所有被调用的工具名称
        
        返回:
            工具名称列表
        
        示例:
            ```python
            output = AgentOutput(tool_calls=[...])
            tools = output.get_tool_names()
            print(f"调用的工具: {', '.join(tools)}")
            ```
        """
        names = []
        for call in self.tool_calls:
            func = call.get("function", {})
            name = func.get("name")
            if name:
                names.append(name)
        return names

    def get_tool_call_by_id(self, call_id: str) -> Optional[Dict[str, Any]]:
        """
        根据 ID 获取工具调用
        
        参数:
            call_id: 工具调用 ID
        
        返回:
            工具调用字典，如果不存在返回 None
        """
        for call in self.tool_calls:
            if call.get("id") == call_id:
                return call
        return None

    def get_text_preview(self, max_length: int = 100) -> str:
        """
        获取内容预览（用于日志/显示）
        
        参数:
            max_length: 最大长度
        
        返回:
            截断后的文本预览
        """
        if not self.content:
            return ""
        
        if len(self.content) <= max_length:
            return self.content
        
        return self.content[:max_length] + "..."

    # ===== 转换方法 =====

    def to_dict(self) -> Dict[str, Any]:
        """
        转换为字典（便于序列化）
        
        返回:
            包含所有字段的字典
        """
        data = {
            "content": self.content,
            "tool_calls": self.tool_calls,
            "metadata": self.metadata,
        }
        
        if self.usage:
            data["usage"] = self.usage.model_dump()
        
        # raw 字段可能无法序列化，仅在调试模式下包含
        if self.raw and self.metadata.get("include_raw"):
            try:
                data["raw"] = str(self.raw)
            except Exception:
                data["raw"] = "<non-serializable>"
        
        return data

    def to_message_dict(self) -> Dict[str, Any]:
        """
        转换为 OpenAI 消息格式（用于下一轮对话）
        
        返回:
            符合 OpenAI API 的消息字典
        
        示例:
            ```python
            output = AgentOutput(content="Hello", tool_calls=[...])
            msg_dict = output.to_message_dict()
            # 可以直接添加到对话历史
            ```
        """
        msg = {
            "role": "assistant",
            "content": self.content or None,  # OpenAI 允许 null
        }
        
        if self.tool_calls:
            msg["tool_calls"] = self.tool_calls
        
        return msg

    # ===== 格式化输出 =====

    def format(self, include_metadata: bool = False) -> str:
        """
        格式化输出为可读文本
        
        参数:
            include_metadata: 是否包含元数据
        
        返回:
            格式化后的字符串
        
        示例:
            ```python
            output = AgentOutput(...)
            print(output.format())
            ```
        """
        lines = []
        
        # 内容
        if self.has_content():
            lines.append("=== 回复内容 ===")
            lines.append(self.content)
            lines.append("")
        
        # 工具调用
        if self.has_tool_calls():
            lines.append("=== 工具调用 ===")
            for i, call in enumerate(self.tool_calls, 1):
                func = call.get("function", {})
                name = func.get("name", "unknown")
                args = func.get("arguments", "{}")
                lines.append(f"{i}. {name}")
                lines.append(f"   参数: {args}")
            lines.append("")
        
        # Token 使用
        if self.usage:
            lines.append("=== Token 使用 ===")
            lines.append(f"输入: {self.usage.prompt_tokens}")
            lines.append(f"输出: {self.usage.completion_tokens}")
            lines.append(f"总计: {self.usage.total_tokens}")
            lines.append("")
        
        # 元数据
        if include_metadata and self.metadata:
            lines.append("=== 元数据 ===")
            for key, value in self.metadata.items():
                lines.append(f"{key}: {value}")
            lines.append("")
        
        return "\n".join(lines)

    def summary(self) -> str:
        """
        生成简短摘要
        
        返回:
            一行摘要文本
        
        示例:
            ```python
            output = AgentOutput(...)
            print(output.summary())
            # 输出: "回复: Hello... (50 chars) | 工具调用: 2 | Tokens: 150"
            ```
        """
        parts = []
        
        if self.has_content():
            preview = self.get_text_preview(30)
            parts.append(f"回复: {preview}")
        
        if self.has_tool_calls():
            parts.append(f"工具调用: {self.tool_call_count()}")
        
        if self.usage:
            parts.append(f"Tokens: {self.usage.total_tokens}")
        
        if not parts:
            return "空输出"
        
        return " | ".join(parts)

    # ===== 统计方法 =====

    def get_stats(self) -> Dict[str, Any]:
        """
        获取输出统计信息
        
        返回:
            包含各种统计数据的字典
        """
        stats = {
            "content_length": len(self.content),
            "has_content": self.has_content(),
            "tool_call_count": self.tool_call_count(),
            "tool_names": self.get_tool_names(),
            "is_empty": self.is_empty(),
        }
        
        if self.usage:
            stats["usage"] = {
                "prompt_tokens": self.usage.prompt_tokens,
                "completion_tokens": self.usage.completion_tokens,
                "total_tokens": self.usage.total_tokens,
            }
        
        return stats

    # ===== 字符串表示 =====

    def __str__(self) -> str:
        """简洁的字符串表示"""
        return self.summary()

    def __repr__(self) -> str:
        """详细的字符串表示"""
        return (
            f"AgentOutput("
            f"content_length={len(self.content)}, "
            f"tool_calls={self.tool_call_count()}, "
            f"has_usage={self.has_usage()}"
            f")"
        )

    def __bool__(self) -> bool:
        """
        布尔值转换（是否有有效输出）
        
        返回:
            是否不为空
        """
        return not self.is_empty()


# ===== 工具函数 =====

def create_text_output(
    content: str,
    usage: Optional[TokenUsage] = None,
    **metadata
) -> AgentOutput:
    """
    快速创建纯文本输出
    
    参数:
        content: 文本内容
        usage: Token 使用统计（可选）
        **metadata: 附加元数据
    
    返回:
        AgentOutput 实例
    
    示例:
        ```python
        output = create_text_output(
            "Hello, world!",
            usage=TokenUsage(prompt_tokens=10, completion_tokens=5)
        )
        ```
    """
    return AgentOutput(
        content=content,
        usage=usage,
        metadata=metadata
    )


def create_tool_output(
    tool_calls: List[Dict[str, Any]],
    content: str = "",
    usage: Optional[TokenUsage] = None,
    **metadata
) -> AgentOutput:
    """
    快速创建工具调用输出
    
    参数:
        tool_calls: 工具调用列表
        content: 可选的文本内容
        usage: Token 使用统计（可选）
        **metadata: 附加元数据
    
    返回:
        AgentOutput 实例
    """
    return AgentOutput(
        content=content,
        tool_calls=tool_calls,
        usage=usage,
        metadata=metadata
    )


def merge_outputs(outputs: List[AgentOutput]) -> AgentOutput:
    """
    合并多个输出（用于多 Agent 场景）
    
    参数:
        outputs: AgentOutput 列表
    
    返回:
        合并后的 AgentOutput
    
    策略:
        - 内容：用换行符连接
        - 工具调用：合并所有
        - Usage：累加 tokens
        - 元数据：合并（后者覆盖前者）
    
    示例:
        ```python
        output1 = AgentOutput(content="Part 1")
        output2 = AgentOutput(content="Part 2")
        merged = merge_outputs([output1, output2])
        print(merged.content)  # "Part 1\nPart 2"
        ```
    """
    if not outputs:
        return AgentOutput()
    
    if len(outputs) == 1:
        return outputs[0]
    
    # 合并内容
    contents = [o.content for o in outputs if o.has_content()]
    merged_content = "\n".join(contents)
    
    # 合并工具调用
    merged_tool_calls = []
    for output in outputs:
        merged_tool_calls.extend(output.tool_calls)
    
    # 合并 usage
    merged_usage = None
    if any(o.has_usage() for o in outputs):
        total_prompt = sum(
            o.usage.prompt_tokens for o in outputs if o.usage
        )
        total_completion = sum(
            o.usage.completion_tokens for o in outputs if o.usage
        )
        merged_usage = TokenUsage(
            prompt_tokens=total_prompt,
            completion_tokens=total_completion,
            total_tokens=total_prompt + total_completion
        )
    
    # 合并元数据
    merged_metadata = {}
    for output in outputs:
        merged_metadata.update(output.metadata)
    
    return AgentOutput(
        content=merged_content,
        tool_calls=merged_tool_calls,
        usage=merged_usage,
        metadata=merged_metadata
    )
```

[18] gecko/core/prompt.py
```python
# gecko/core/prompt.py
"""
Prompt 模板系统

提供灵活的提示词模板管理，基于 Jinja2 实现。

核心功能：
1. 动态变量替换
2. 模板验证
3. 模板缓存
4. 常用模板库
5. 模板组合

优化点：
1. 更好的错误处理
2. 模板缓存提升性能
3. 预定义模板库
4. 模板组合和继承
5. 安全的沙箱环境
"""
from __future__ import annotations

import re
from typing import Any, Dict, List, Optional, Set

from pydantic import BaseModel, Field, field_validator

from gecko.core.logging import get_logger

logger = get_logger(__name__)

# ===== Jinja2 相关 =====

# 延迟导入 Jinja2（避免强依赖）
_jinja2_available = None
_jinja2_env = None


def _check_jinja2():
    """检查 Jinja2 是否可用"""
    global _jinja2_available
    if _jinja2_available is None:
        try:
            import jinja2
            _jinja2_available = True
        except ImportError:
            _jinja2_available = False
    return _jinja2_available


def _get_jinja2_env():
    """获取 Jinja2 环境（带缓存）"""
    global _jinja2_env
    
    if _jinja2_env is None:
        if not _check_jinja2():
            raise ImportError(
                "PromptTemplate 依赖 jinja2。\n"
                "请安装：pip install jinja2\n"
                "或：rye add jinja2"
            )
        
        from jinja2 import Environment, StrictUndefined
        
        # 创建安全的 Jinja2 环境
        _jinja2_env = Environment(
            # 严格模式：未定义变量会报错
            undefined=StrictUndefined,
            # ✅ 修复1：禁用自动转义（直接设置为 False）
            autoescape=False,
            # 保留换行符
            keep_trailing_newline=True,
            # 启用扩展
            extensions=[]
        )
        
        logger.debug("Jinja2 environment initialized")
    
    return _jinja2_env


# ===== Prompt 模板 =====

class PromptTemplate(BaseModel):
    """
    Prompt 模板
    
    使用 Jinja2 语法，支持动态变量替换、条件判断、循环等。
    
    示例:
        ```python
        # 基础模板
        template = PromptTemplate(
            template="Hello, {{ name }}! You are {{ age }} years old.",
            input_variables=["name", "age"]
        )
        result = template.format(name="Alice", age=25)
        
        # 带条件的模板
        template = PromptTemplate(
            template='''
            {% if tools %}
            You have access to these tools:
            {% for tool in tools %}
            - {{ tool.name }}: {{ tool.description }}
            {% endfor %}
            {% endif %}
            
            User: {{ question }}
            ''',
            input_variables=["tools", "question"]
        )
        
        # 从文件加载
        template = PromptTemplate.from_file("./prompts/system.txt")
        ```
    
    属性:
        template: 模板字符串（Jinja2 语法）
        input_variables: 必需的变量列表
        template_format: 模板格式（默认 'jinja2'）
        validate_template: 是否验证模板语法（默认 True）
    """
    template: str = Field(..., description="模板字符串")
    input_variables: List[str] = Field(
        default_factory=list,
        description="必需的输入变量列表"
    )
    template_format: str = Field(
        default="jinja2",
        description="模板格式（jinja2/f-string）"
    )
    validate_template: bool = Field(
        default=True,
        description="是否验证模板语法"
    )
    
    # 私有字段：缓存编译后的模板
    _compiled_template: Any = None

    @field_validator("template_format")
    @classmethod
    def validate_format(cls, v: str) -> str:
        """验证模板格式"""
        valid_formats = {"jinja2", "f-string"}
        if v not in valid_formats:
            raise ValueError(
                f"不支持的模板格式: {v}。支持的格式: {valid_formats}"
            )
        return v

    def model_post_init(self, __context):
        """初始化后验证"""
        if self.validate_template:
            self._validate_template_syntax()

    def _validate_template_syntax(self):
        """验证模板语法"""
        if self.template_format == "jinja2":
            try:
                env = _get_jinja2_env()
                # 尝试编译模板
                self._compiled_template = env.from_string(self.template)
                logger.debug("Template syntax validated")
            except Exception as e:
                error_msg = self._format_jinja2_error(str(e))
                raise ValueError(f"模板语法错误:\n{error_msg}") from e
        elif self.template_format == "f-string":
            # f-string 格式验证（基础检查）
            self._validate_fstring_syntax()

    def _validate_fstring_syntax(self):
        """验证 f-string 语法（基础）"""
        # 检查是否有未闭合的大括号
        open_count = self.template.count("{")
        close_count = self.template.count("}")
        
        if open_count != close_count:
            raise ValueError(
                f"f-string 语法错误: 大括号不匹配 "
                f"({{ {open_count} 个, }} {close_count} 个)"
            )

    def _format_jinja2_error(self, error: str) -> str:
        """格式化 Jinja2 错误信息"""
        # 提取关键信息
        lines = error.split("\n")
        formatted_lines = []
        
        for line in lines[:5]:  # 只取前 5 行
            if line.strip():
                formatted_lines.append(f"  {line}")
        
        # 添加模板片段
        template_preview = self.template[:100].replace("\n", "\\n")
        formatted_lines.append(f"\n模板片段: {template_preview}...")
        
        return "\n".join(formatted_lines)

    # ===== 格式化方法 =====

    def format(self, **kwargs: Any) -> str:
        """
        格式化模板（填充变量）
        
        参数:
            **kwargs: 模板变量
        
        返回:
            格式化后的字符串
        
        异常:
            ValueError: 缺少必需变量或渲染失败
        
        示例:
            ```python
            template = PromptTemplate(
                template="Hello, {{ name }}!",
                input_variables=["name"]
            )
            result = template.format(name="Alice")
            ```
        """
        # 检查必需变量
        missing = self._check_missing_variables(kwargs)
        if missing:
            raise ValueError(
                f"缺少必需的模板变量: {', '.join(missing)}\n"
                f"需要: {self.input_variables}\n"
                f"提供: {list(kwargs.keys())}"
            )
        
        # 根据格式渲染
        if self.template_format == "jinja2":
            return self._format_jinja2(**kwargs)
        elif self.template_format == "f-string":
            return self._format_fstring(**kwargs)
        else:
            raise ValueError(f"不支持的模板格式: {self.template_format}")

    def _check_missing_variables(self, kwargs: Dict[str, Any]) -> List[str]:
        """检查缺失的变量"""
        provided = set(kwargs.keys())
        required = set(self.input_variables)
        missing = required - provided
        return sorted(missing)

    def _format_jinja2(self, **kwargs: Any) -> str:
        """使用 Jinja2 渲染"""
        try:
            # 使用缓存的编译模板（如果有）
            if self._compiled_template is None:
                env = _get_jinja2_env()
                self._compiled_template = env.from_string(self.template)
            
            result = self._compiled_template.render(**kwargs)
            return result
            
        except Exception as e:
            # 提供更友好的错误信息
            error_msg = str(e)
            
            # 尝试识别具体错误
            if "is undefined" in error_msg:
                # 提取未定义的变量名
                match = re.search(r"'(\w+)' is undefined", error_msg)
                if match:
                    var_name = match.group(1)
                    raise ValueError(
                        f"模板变量 '{var_name}' 未定义。\n"
                        f"可用变量: {list(kwargs.keys())}"
                    ) from e
            
            # 通用错误
            raise ValueError(
                f"模板渲染失败: {error_msg}\n"
                f"模板: {self.template[:100]}..."
            ) from e

    def _format_fstring(self, **kwargs: Any) -> str:
        """使用 f-string 格式化"""
        try:
            return self.template.format(**kwargs)
        except KeyError as e:
            raise ValueError(
                f"缺少变量: {e}\n"
                f"可用变量: {list(kwargs.keys())}"
            ) from e
        except Exception as e:
            raise ValueError(f"f-string 格式化失败: {e}") from e

    def format_safe(self, **kwargs: Any) -> str:
        """
        安全格式化（缺少变量时使用默认值）
        
        缺少的变量会被替换为 "<MISSING: var_name>"
        
        返回:
            格式化后的字符串
        
        注意:
            此方法会自动提取模板中的所有变量，
            不仅仅是 input_variables 中声明的变量。
        """
        try:
            all_vars = self.get_variables_from_template()
        except Exception as e:
            logger.warning("Failed to extract variables", error=str(e))
            all_vars = set(self.input_variables)
        
        safe_kwargs = dict(kwargs)
        for var in all_vars:
            if var not in safe_kwargs:
                # 智能推测默认值
                if var in ('history', 'messages', 'items', 'tools', 'examples'):
                    safe_kwargs[var] = []
                elif var in ('system', 'context', 'prefix', 'suffix'):
                    safe_kwargs[var] = None
                else:
                    safe_kwargs[var] = f"<MISSING: {var}>"
        
        try:
            if self.template_format == "jinja2":
                return self._format_jinja2(**safe_kwargs)
            elif self.template_format == "f-string":
                return self._format_fstring(**safe_kwargs)
            else:
                return f"<TEMPLATE ERROR: 不支持的格式>"
        except Exception as e:
            logger.error("Safe format failed", error=str(e))
            return f"<TEMPLATE ERROR: {e}>"

    # ===== 变量提取 =====

    def get_variables_from_template(self) -> Set[str]:
        """
        从模板中提取所有变量
        
        返回:
            变量名集合
        
        示例:
            ```python
            template = PromptTemplate(template="Hello {{ name }}, you are {{ age }}")
            vars = template.get_variables_from_template()
            # {'name', 'age'}
            ```
        """
        if self.template_format == "jinja2":
            return self._extract_jinja2_variables()
        elif self.template_format == "f-string":
            return self._extract_fstring_variables()
        return set()

    def _extract_jinja2_variables(self) -> Set[str]:
        """从 Jinja2 模板中提取变量"""
        try:
            env = _get_jinja2_env()
            from jinja2 import meta
            
            ast = env.parse(self.template)
            variables = meta.find_undeclared_variables(ast)
            return variables
        except Exception as e:
            logger.warning("Failed to extract Jinja2 variables", error=str(e))
            return set()

    def _extract_fstring_variables(self) -> Set[str]:
        """从 f-string 模板中提取变量"""
        # 简单正则匹配 {var_name}
        pattern = r'\{(\w+)\}'
        matches = re.findall(pattern, self.template)
        return set(matches)

    # ===== 模板操作 =====

    def partial(self, **kwargs: Any) -> "PromptTemplate":
        """
        部分填充变量（返回新模板）
        
        参数:
            **kwargs: 要填充的变量
        
        返回:
            新的 PromptTemplate，已填充部分变量
        
        示例:
            ```python
            template = PromptTemplate(
                template="Hello {{ name }}, you are {{ age }}",
                input_variables=["name", "age"]
            )
            partial = template.partial(name="Alice")
            result = partial.format(age=25)
            ```
        """
        # 填充变量
        partial_result = self.format_safe(**kwargs)
        
        # 计算剩余变量
        remaining_vars = [v for v in self.input_variables if v not in kwargs]
        
        return PromptTemplate(
            template=partial_result,
            input_variables=remaining_vars,
            template_format=self.template_format,
            validate_template=False  # 已经验证过了
        )

    def clone(self) -> "PromptTemplate":
        """
        克隆模板
        
        返回:
            新的 PromptTemplate 实例
        """
        return PromptTemplate(
            template=self.template,
            input_variables=self.input_variables.copy(),
            template_format=self.template_format,
            validate_template=False
        )

    # ===== 工厂方法 =====

    @classmethod
    def from_file(
        cls,
        path: str,
        input_variables: Optional[List[str]] = None,
        encoding: str = "utf-8"
    ) -> "PromptTemplate":
        """
        从文件加载模板
        
        参数:
            path: 文件路径
            input_variables: 变量列表（None 则自动提取）
            encoding: 文件编码
        
        返回:
            PromptTemplate 实例
        
        示例:
            ```python
            template = PromptTemplate.from_file("./prompts/system.txt")
            ```
        """
        from pathlib import Path
        
        file_path = Path(path)
        if not file_path.exists():
            raise FileNotFoundError(f"模板文件不存在: {path}")
        
        try:
            with open(file_path, "r", encoding=encoding) as f:
                template_str = f.read()
        except Exception as e:
            raise IOError(f"读取模板文件失败: {e}") from e
        
        # 创建模板
        prompt = cls(
            template=template_str,
            input_variables=input_variables or []
        )
        
        # 如果未提供变量，自动提取
        if not input_variables:
            detected_vars = prompt.get_variables_from_template()
            prompt.input_variables = sorted(detected_vars)
            logger.info(
                "Auto-detected template variables",
                path=path,
                variables=prompt.input_variables
            )
        
        return prompt

    @classmethod
    def from_examples(
        cls,
        examples: List[Dict[str, str]],
        template: str = "{{ input }}\n{{ output }}\n",
        separator: str = "\n---\n"
    ) -> "PromptTemplate":
        """
        从示例列表创建 few-shot 模板
        
        参数:
            examples: 示例列表 [{"input": "...", "output": "..."}, ...]
            template: 单个示例的模板
            separator: 示例之间的分隔符
        
        返回:
            PromptTemplate 实例
        
        示例:
            ```python
            examples = [
                {"input": "2+2", "output": "4"},
                {"input": "3+5", "output": "8"},
            ]
            template = PromptTemplate.from_examples(examples)
            ```
        """
        # 渲染所有示例
        example_template = cls(template=template, input_variables=[])
        
        rendered_examples = []
        for ex in examples:
            rendered = example_template.format_safe(**ex)
            rendered_examples.append(rendered)
        
        # 合并为完整模板
        full_template = separator.join(rendered_examples)
        
        return cls(
            template=full_template,
            input_variables=[]
        )

    # ===== 字符串表示 =====

    def __str__(self) -> str:
        """简洁表示"""
        preview = self.template[:50].replace("\n", "\\n")
        if len(self.template) > 50:
            preview += "..."
        return f"PromptTemplate('{preview}', vars={self.input_variables})"

    def __repr__(self) -> str:
        """详细表示"""
        return (
            f"PromptTemplate("
            f"template_length={len(self.template)}, "
            f"input_variables={self.input_variables}, "
            f"format={self.template_format}"
            f")"
        )


# ===== 预定义模板库 =====

class PromptLibrary:
    """
    常用 Prompt 模板库
    
    提供预定义的常用模板。
    
    示例:
        ```python
        # 使用预定义模板
        template = PromptLibrary.get_react_prompt()
        prompt = template.format(
            tools=[...],
            question="What is AI?"
        )
        ```
    """
    
    @staticmethod
    def get_react_prompt() -> PromptTemplate:
        """
        获取 ReAct 推理模板
        
        返回:
            ReAct 格式的 PromptTemplate
        """
        template = """You are a helpful AI assistant with access to tools.

{% if tools %}
Available Tools:
{% for tool in tools %}
- {{ tool.name }}: {{ tool.description }}
{% endfor %}
{% endif %}

To use a tool, respond with a tool call in the following format:
Action: tool_name
Action Input: {"param": "value"}

Then wait for the observation before continuing.

Question: {{ question }}

Let's think step by step."""
        
        return PromptTemplate(
            template=template,
            input_variables=["tools", "question"]
        )
    
    @staticmethod
    def get_chat_prompt() -> PromptTemplate:
        """
        获取对话模板
        
        返回:
            对话格式的 PromptTemplate
        """
        template = """{% if system %}{{ system }}

{% endif %}{% for message in history %}{{ message.role }}: {{ message.content }}
{% endfor %}User: {{ user_input }}
Assistant:"""
        
        return PromptTemplate(
            template=template,
            input_variables=["user_input"],
            # system 和 history 是可选的
        )
    
    @staticmethod
    def get_summarization_prompt() -> PromptTemplate:
        """
        获取摘要模板
        
        返回:
            摘要格式的 PromptTemplate
        """
        template = """Please summarize the following text in {{ max_words }} words or less:

{{ text }}

Summary:"""
        
        return PromptTemplate(
            template=template,
            input_variables=["text", "max_words"]
        )
    
    @staticmethod
    def get_extraction_prompt() -> PromptTemplate:
        """
        获取信息提取模板
        
        返回:
            信息提取格式的 PromptTemplate
        """
        template = """Extract the following information from the text:

{% for field in fields %}
- {{ field }}
{% endfor %}

Text: {{ text }}

Respond in JSON format."""
        
        return PromptTemplate(
            template=template,
            input_variables=["fields", "text"]
        )
    
    @staticmethod
    def get_translation_prompt() -> PromptTemplate:
        """
        获取翻译模板
        
        返回:
            翻译格式的 PromptTemplate
        """
        template = """Translate the following text from {{ source_lang }} to {{ target_lang }}:

{{ text }}

Translation:"""
        
        return PromptTemplate(
            template=template,
            input_variables=["source_lang", "target_lang", "text"]
        )


# ===== 原有的默认模板（保持兼容性）=====

DEFAULT_REACT_PROMPT = PromptTemplate(
    template="""You are a helpful AI assistant.
Current time: {{ current_time }}

{% if tools %}
You have access to the following tools:
{% for tool in tools %}
- {{ tool.name }}: {{ tool.description }}
{% endfor %}
{% endif %}

Answer the user's question using the tools if necessary.
""",
    input_variables=["current_time", "tools"],
)
```

[19] gecko/core/protocols.py
```python
# gecko/core/protocols.py  
"""  
模型协议定义（扩展版）  
  
- 基础模型需实现 acompletion  
- 如支持流式输出，还应实现 astream  
"""  
  
from __future__ import annotations  
  
from typing import Any, AsyncIterator, Dict, List, Protocol, runtime_checkable  
  
  
@runtime_checkable  
class ModelProtocol(Protocol):  
    async def acompletion(self, messages: List[Dict[str, Any]], **kwargs) -> Any:  
        ...  
  
    async def astream(self, messages: List[Dict[str, Any]], **kwargs) -> AsyncIterator[Any]:  
        """  
        可选：支持流式输出的模型应实现此方法  
        """  
        ...  
```

[20] gecko/core/session.py
```python
# gecko/core/session.py
"""
会话管理系统

提供会话的创建、存储、检索和生命周期管理。

核心功能：
1. 会话状态管理（内存 + 持久化）
2. 会话元数据（创建时间、更新时间、访问次数等）
3. 会话生命周期（过期、自动清理）
4. 并发安全（异步锁）
5. 会话克隆和序列化

优化点：
1. 集成存储后端
2. 完善的元数据管理
3. TTL 和自动过期
4. 并发安全
5. 事件通知
"""
from __future__ import annotations

import asyncio
import time
import uuid
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Set

from pydantic import BaseModel, Field

from gecko.core.events import BaseEvent, EventBus
from gecko.core.logging import get_logger
from gecko.plugins.storage.interfaces import SessionInterface

logger = get_logger(__name__)


# ===== 会话元数据 =====

class SessionMetadata(BaseModel):
    """
    会话元数据
    
    属性:
        session_id: 会话唯一标识
        created_at: 创建时间戳
        updated_at: 最后更新时间戳
        accessed_at: 最后访问时间戳
        access_count: 访问次数
        ttl: 生存时间（秒），None 表示永不过期
        tags: 会话标签
        custom: 自定义元数据
    """
    session_id: str = Field(..., description="会话 ID")
    created_at: float = Field(default_factory=time.time, description="创建时间")
    updated_at: float = Field(default_factory=time.time, description="更新时间")
    accessed_at: float = Field(default_factory=time.time, description="访问时间")
    access_count: int = Field(default=0, description="访问次数")
    ttl: Optional[int] = Field(default=None, description="生存时间（秒）")
    tags: Set[str] = Field(default_factory=set, description="标签")
    custom: Dict[str, Any] = Field(default_factory=dict, description="自定义数据")
    
    def is_expired(self) -> bool:
        """检查会话是否过期"""
        if self.ttl is None:
            return False
        
        age = time.time() - self.created_at
        return age > self.ttl
    
    def time_to_expire(self) -> Optional[float]:
        """
        获取距离过期的剩余时间（秒）
        
        返回:
            剩余时间，None 表示永不过期，负数表示已过期
        """
        if self.ttl is None:
            return None
        
        age = time.time() - self.created_at
        return self.ttl - age
    
    def touch(self):
        """更新访问时间和计数"""
        self.accessed_at = time.time()
        self.access_count += 1


# ===== 会话事件 =====

class SessionEvent(BaseEvent):
    """会话相关事件"""
    pass


# ===== 会话对象 =====

class Session:
    """
    会话对象
    
    管理单个会话的状态和元数据。
    
    示例:
        ```python
        # 创建会话
        session = Session(session_id="user_123")
        
        # 设置状态
        session.set("user_name", "Alice")
        session.set("preferences", {"theme": "dark"})
        
        # 获取状态
        name = session.get("user_name")
        
        # 检查过期
        if not session.is_expired():
            print("会话有效")
        
        # 持久化
        await session.save()
        ```
    """
    
    def __init__(
        self,
        session_id: Optional[str] = None,
        state: Optional[Dict[str, Any]] = None,
        storage: Optional[SessionInterface] = None,
        ttl: Optional[int] = None,
        event_bus: Optional[EventBus] = None,
        auto_save: bool = True,
    ):
        """
        初始化会话
        
        参数:
            session_id: 会话 ID（None 则自动生成）
            state: 初始状态
            storage: 存储后端（可选）
            ttl: 生存时间（秒）
            event_bus: 事件总线（可选）
            auto_save: 是否自动保存到存储
        """
        self.session_id = session_id or self._generate_id()
        self.state: Dict[str, Any] = state or {}
        self.storage = storage
        self.event_bus = event_bus or EventBus()
        self.auto_save = auto_save
        
        # 元数据
        self.metadata = SessionMetadata(
            session_id=self.session_id,
            ttl=ttl
        )
        
        # 并发锁
        self._lock = asyncio.Lock()
        
        # 标记为已修改（用于优化持久化）
        self._dirty = False
        
        logger.debug("Session created", session_id=self.session_id)
    
    @staticmethod
    def _generate_id() -> str:
        """生成唯一会话 ID"""
        return f"session_{uuid.uuid4().hex[:16]}"
    
    # ===== 状态管理 =====
    
    def get(self, key: str, default: Any = None) -> Any:
        """
        获取状态值
        
        参数:
            key: 键
            default: 默认值
        
        返回:
            状态值
        """
        self.metadata.touch()
        return self.state.get(key, default)
    
    def set(self, key: str, value: Any):
        """
        设置状态值
        
        参数:
            key: 键
            value: 值
        """
        self.state[key] = value
        self.metadata.updated_at = time.time()
        self.metadata.touch()
        self._dirty = True
        
        # 发布事件
        self.event_bus.publish(SessionEvent(
            type="session_updated",
            data={"session_id": self.session_id, "key": key}
        ))
        
        # 自动保存
        if self.auto_save and self.storage:
            asyncio.create_task(self.save())
    
    def delete(self, key: str) -> bool:
        """
        删除状态值
        
        参数:
            key: 键
        
        返回:
            是否成功删除
        """
        if key in self.state:
            del self.state[key]
            self.metadata.updated_at = time.time()
            self._dirty = True
            
            if self.auto_save and self.storage:
                asyncio.create_task(self.save())
            
            return True
        return False
    
    def clear(self):
        """清空所有状态"""
        self.state.clear()
        self.metadata.updated_at = time.time()
        self._dirty = True
        
        if self.auto_save and self.storage:
            asyncio.create_task(self.save())
    
    def update(self, data: Dict[str, Any]):
        """
        批量更新状态
        
        参数:
            data: 要更新的数据
        """
        self.state.update(data)
        self.metadata.updated_at = time.time()
        self._dirty = True
        
        if self.auto_save and self.storage:
            asyncio.create_task(self.save())
    
    def keys(self) -> List[str]:
        """获取所有键"""
        return list(self.state.keys())
    
    def values(self) -> List[Any]:
        """获取所有值"""
        return list(self.state.values())
    
    def items(self) -> List[tuple]:
        """获取所有键值对"""
        return list(self.state.items())
    
    def __contains__(self, key: str) -> bool:
        """支持 in 操作"""
        return key in self.state
    
    def __getitem__(self, key: str) -> Any:
        """支持 [] 读取"""
        return self.state[key]
    
    def __setitem__(self, key: str, value: Any):
        """支持 [] 设置"""
        self.set(key, value)
    
    # ===== 生命周期管理 =====
    
    def is_expired(self) -> bool:
        """检查会话是否过期"""
        return self.metadata.is_expired()
    
    def extend_ttl(self, extra_seconds: int):
        """
        延长生存时间
        
        参数:
            extra_seconds: 额外的秒数
        """
        if self.metadata.ttl is not None:
            self.metadata.ttl += extra_seconds
            logger.debug(
                "Session TTL extended",
                session_id=self.session_id,
                new_ttl=self.metadata.ttl
            )
    
    def renew(self):
        """
        重置会话（从当前时间重新计算 TTL）
        """
        self.metadata.created_at = time.time()
        logger.debug("Session renewed", session_id=self.session_id)
    
    # ===== 标签管理 =====
    
    def add_tag(self, tag: str):
        """添加标签"""
        self.metadata.tags.add(tag)
        self._dirty = True
    
    def remove_tag(self, tag: str):
        """移除标签"""
        self.metadata.tags.discard(tag)
        self._dirty = True
    
    def has_tag(self, tag: str) -> bool:
        """检查是否有标签"""
        return tag in self.metadata.tags
    
    # ===== 持久化 =====
    
    async def save(self, force: bool = False):
        """
        保存会话到存储
        
        参数:
            force: 是否强制保存（忽略 _dirty 标记）
        """
        if not self.storage:
            return
        
        if not force and not self._dirty:
            return
        
        async with self._lock:
            try:
                data = self.to_dict()
                await self.storage.set(self.session_id, data)
                self._dirty = False
                
                logger.debug("Session saved", session_id=self.session_id)
                
                self.event_bus.publish(SessionEvent(
                    type="session_saved",
                    data={"session_id": self.session_id}
                ))
            except Exception as e:
                logger.error(
                    "Failed to save session",
                    session_id=self.session_id,
                    error=str(e)
                )
    
    async def load(self) -> bool:
        """
        从存储加载会话
        
        返回:
            是否成功加载
        """
        if not self.storage:
            return False
        
        async with self._lock:
            try:
                data = await self.storage.get(self.session_id)
                if not data:
                    return False
                
                self.from_dict(data)
                self._dirty = False
                
                logger.debug("Session loaded", session_id=self.session_id)
                
                self.event_bus.publish(SessionEvent(
                    type="session_loaded",
                    data={"session_id": self.session_id}
                ))
                
                return True
            except Exception as e:
                logger.error(
                    "Failed to load session",
                    session_id=self.session_id,
                    error=str(e)
                )
                return False
    
    async def destroy(self):
        """
        销毁会话（从存储中删除）
        """
        if self.storage:
            async with self._lock:
                try:
                    await self.storage.delete(self.session_id)
                    logger.info("Session destroyed", session_id=self.session_id)
                    
                    self.event_bus.publish(SessionEvent(
                        type="session_destroyed",
                        data={"session_id": self.session_id}
                    ))
                except Exception as e:
                    logger.error(
                        "Failed to destroy session",
                        session_id=self.session_id,
                        error=str(e)
                    )
        
        self.state.clear()
    
    # ===== 序列化 =====
    
    def to_dict(self) -> Dict[str, Any]:
        """
        序列化为字典
        
        返回:
            包含状态和元数据的字典
        """
        return {
            "state": self.state,
            "metadata": self.metadata.model_dump(),
        }
    
    def from_dict(self, data: Dict[str, Any]):
        """
        从字典反序列化
        
        参数:
            data: 数据字典
        """
        self.state = data.get("state", {})
        
        metadata_data = data.get("metadata", {})
        if metadata_data:
            self.metadata = SessionMetadata(**metadata_data)
    
    def clone(self, new_id: Optional[str] = None) -> Session:
        """
        克隆会话
        
        参数:
            new_id: 新会话 ID（None 则自动生成）
        
        返回:
            新的 Session 实例
        """
        cloned = Session(
            session_id=new_id,
            state=self.state.copy(),
            storage=self.storage,
            ttl=self.metadata.ttl,
            event_bus=self.event_bus,
            auto_save=False,  # 克隆时不自动保存
        )
        
        # 复制标签
        cloned.metadata.tags = self.metadata.tags.copy()
        cloned.metadata.custom = self.metadata.custom.copy()
        
        return cloned
    
    # ===== 调试信息 =====
    
    def get_info(self) -> Dict[str, Any]:
        """
        获取会话信息（用于调试/监控）
        
        返回:
            会话信息字典
        """
        return {
            "session_id": self.session_id,
            "state_keys": len(self.state),
            "created_at": datetime.fromtimestamp(self.metadata.created_at).isoformat(),
            "updated_at": datetime.fromtimestamp(self.metadata.updated_at).isoformat(),
            "accessed_at": datetime.fromtimestamp(self.metadata.accessed_at).isoformat(),
            "access_count": self.metadata.access_count,
            "ttl": self.metadata.ttl,
            "time_to_expire": self.metadata.time_to_expire(),
            "is_expired": self.is_expired(),
            "tags": list(self.metadata.tags),
            "has_storage": self.storage is not None,
            "is_dirty": self._dirty,
        }
    
    def __repr__(self) -> str:
        """字符串表示"""
        return (
            f"Session("
            f"id={self.session_id}, "
            f"keys={len(self.state)}, "
            f"accessed={self.metadata.access_count}, "
            f"expired={self.is_expired()}"
            f")"
        )


# ===== 会话管理器 =====

class SessionManager:
    """
    会话管理器
    
    负责管理多个会话的生命周期、持久化和清理。
    
    示例:
        ```python
        # 创建管理器
        manager = SessionManager(storage=storage)
        
        # 创建会话
        session = await manager.create_session(ttl=3600)
        
        # 获取会话
        session = await manager.get_session(session_id)
        
        # 清理过期会话
        await manager.cleanup_expired()
        ```
    """
    
    def __init__(
        self,
        storage: Optional[SessionInterface] = None,
        default_ttl: Optional[int] = None,
        auto_cleanup: bool = True,
        cleanup_interval: int = 300,  # 5 分钟
    ):
        """
        初始化会话管理器
        
        参数:
            storage: 存储后端
            default_ttl: 默认 TTL（秒）
            auto_cleanup: 是否自动清理过期会话
            cleanup_interval: 清理间隔（秒）
        """
        self.storage = storage
        self.default_ttl = default_ttl
        self.auto_cleanup = auto_cleanup
        self.cleanup_interval = cleanup_interval
        
        # 内存缓存（session_id -> Session）
        self._sessions: Dict[str, Session] = {}
        self._lock = asyncio.Lock()
        
        # 自动清理任务
        self._cleanup_task: Optional[asyncio.Task] = None
        
        if auto_cleanup:
            self._start_cleanup_task()
        
        logger.info("SessionManager initialized", default_ttl=default_ttl)
    
    def _start_cleanup_task(self):
        """启动自动清理任务"""
        async def _cleanup_loop():
            while True:
                try:
                    await asyncio.sleep(self.cleanup_interval)
                    await self.cleanup_expired()
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    logger.error("Cleanup task error", error=str(e))
        
        self._cleanup_task = asyncio.create_task(_cleanup_loop())
        logger.debug("Cleanup task started", interval=self.cleanup_interval)
    
    async def create_session(
        self,
        session_id: Optional[str] = None,
        ttl: Optional[int] = None,
        **initial_state
    ) -> Session:
        """
        创建新会话
        
        参数:
            session_id: 会话 ID（None 则自动生成）
            ttl: 生存时间（None 则使用默认值）
            **initial_state: 初始状态
        
        返回:
            Session 实例
        """
        async with self._lock:
            session = Session(
                session_id=session_id,
                state=initial_state,
                storage=self.storage,
                ttl=ttl or self.default_ttl,
                auto_save=True,
            )
            
            self._sessions[session.session_id] = session
            
            if self.storage:
                await session.save()
            
            logger.info("Session created", session_id=session.session_id)
            return session
    
    async def get_session(
        self,
        session_id: str,
        create_if_missing: bool = False
    ) -> Optional[Session]:
        """
        获取会话
        
        参数:
            session_id: 会话 ID
            create_if_missing: 如果不存在是否创建
        
        返回:
            Session 实例，如果不存在返回 None
        """
        # 1. 检查内存缓存
        if session_id in self._sessions:
            session = self._sessions[session_id]
            
            # 检查过期
            if session.is_expired():
                await self.destroy_session(session_id)
                if create_if_missing:
                    return await self.create_session(session_id=session_id)
                return None
            
            return session
        
        # 2. 尝试从存储加载
        if self.storage:
            session = Session(
                session_id=session_id,
                storage=self.storage,
                auto_save=True,
            )
            
            if await session.load():
                if session.is_expired():
                    await session.destroy()
                    if create_if_missing:
                        return await self.create_session(session_id=session_id)
                    return None
                
                async with self._lock:
                    self._sessions[session_id] = session
                
                return session
        
        # 3. 创建新会话（如果允许）
        if create_if_missing:
            return await self.create_session(session_id=session_id)
        
        return None
    
    async def destroy_session(self, session_id: str) -> bool:
        """
        销毁会话
        
        参数:
            session_id: 会话 ID
        
        返回:
            是否成功
        """
        async with self._lock:
            session = self._sessions.pop(session_id, None)
            
            if session:
                await session.destroy()
                return True
            elif self.storage:
                try:
                    await self.storage.delete(session_id)
                    return True
                except Exception as e:
                    logger.error("Failed to destroy session", session_id=session_id, error=str(e))
        
        return False
    
    async def cleanup_expired(self) -> int:
        """
        清理所有过期会话
        
        返回:
            清理的会话数量
        """
        expired_ids = []
        
        async with self._lock:
            for session_id, session in list(self._sessions.items()):
                if session.is_expired():
                    expired_ids.append(session_id)
        
        for session_id in expired_ids:
            await self.destroy_session(session_id)
        
        if expired_ids:
            logger.info("Expired sessions cleaned", count=len(expired_ids))
        
        return len(expired_ids)
    
    def get_active_count(self) -> int:
        """获取活跃会话数量"""
        return len(self._sessions)
    
    def get_all_sessions(self) -> List[Session]:
        """获取所有活跃会话"""
        return list(self._sessions.values())
    
    async def shutdown(self):
        """关闭管理器（取消清理任务，保存所有会话）"""
        if self._cleanup_task:
            self._cleanup_task.cancel()
            try:
                await self._cleanup_task
            except asyncio.CancelledError:
                pass
        
        # 保存所有会话
        for session in self._sessions.values():
            await session.save(force=True)
        
        logger.info("SessionManager shutdown", sessions_saved=len(self._sessions))
```

[21] gecko/core/structure.py
```python
# gecko/core/structure.py
"""
结构化输出引擎

负责将 LLM 的文本/工具调用输出解析为 Pydantic 模型。

核心功能：
1. 多策略 JSON 提取（Tool Call、直接 JSON、Markdown、暴力截取）
2. Schema 验证与修复
3. 带反馈的重试机制
4. OpenAI Function Calling Schema 生成

优化点：
1. 改进错误信息收集和报告
2. 更智能的 JSON 提取算法
3. Schema 自动修复
4. 详细的调试日志
5. 可配置的解析策略
"""
from __future__ import annotations

import json
import re
from typing import Any, Dict, List, Optional, Type, TypeVar

from pydantic import BaseModel, ValidationError

from gecko.core.logging import get_logger

logger = get_logger(__name__)

T = TypeVar("T", bound=BaseModel)


# ===== 自定义异常 =====

class StructureParseError(ValueError):
    """
    结构化解析失败异常
    
    属性:
        message: 错误信息
        attempts: 所有尝试的解析策略及其错误
        raw_content: 原始内容
    """
    def __init__(
        self,
        message: str,
        attempts: Optional[List[Dict[str, str]]] = None,
        raw_content: Optional[str] = None
    ):
        super().__init__(message)
        self.attempts = attempts or []
        self.raw_content = raw_content
    
    def get_detailed_error(self) -> str:
        """获取详细错误信息"""
        lines = [f"结构化解析失败: {self.args[0]}"]
        
        if self.attempts:
            lines.append("\n尝试的解析策略:")
            for i, attempt in enumerate(self.attempts, 1):
                strategy = attempt.get("strategy", "unknown")
                error = attempt.get("error", "unknown error")
                lines.append(f"  {i}. {strategy}: {error}")
        
        if self.raw_content:
            preview = self.raw_content[:200].replace("\n", "\\n")
            lines.append(f"\n原始内容预览: {preview}...")
        
        return "\n".join(lines)


# ===== 结构化输出引擎 =====

class StructureEngine:
    """
    结构化输出引擎
    
    提供多种策略将文本解析为 Pydantic 模型。
    
    示例:
        ```python
        from pydantic import BaseModel
        
        class User(BaseModel):
            name: str
            age: int
        
        # 从工具调用解析
        result = await StructureEngine.parse(
            content="",
            model_class=User,
            raw_tool_calls=[{
                "function": {
                    "arguments": '{"name": "Alice", "age": 25}'
                }
            }]
        )
        
        # 从文本解析
        result = await StructureEngine.parse(
            content='{"name": "Bob", "age": 30}',
            model_class=User
        )
        ```
    """
    
    # ===== Schema 生成 =====
    
    @staticmethod
    def to_openai_tool(model: Type[BaseModel]) -> Dict[str, Any]:
        """
        将 Pydantic 模型转换为 OpenAI Function Calling 所需的 schema
        
        参数:
            model: Pydantic 模型类
        
        返回:
            OpenAI tool 定义
        
        示例:
            ```python
            from pydantic import BaseModel, Field
            
            class SearchQuery(BaseModel):
                query: str = Field(description="搜索关键词")
                max_results: int = Field(default=5, description="最大结果数")
            
            tool = StructureEngine.to_openai_tool(SearchQuery)
            # 可用于 OpenAI API 的 tools 参数
            ```
        """
        schema = model.model_json_schema()
        
        # 提取模型名称（移除特殊字符）
        name = re.sub(r"\W+", "_", schema.get("title", "extract_data")).lower()
        
        # 移除 Pydantic 内部字段
        if "title" in schema:
            del schema["title"]
        if "$defs" in schema:
            # 展开 definitions
            schema = StructureEngine._flatten_schema(schema)
        
        return {
            "type": "function",
            "function": {
                "name": name,
                "description": schema.get("description", f"Extract {name} data"),
                "parameters": schema,
            },
        }
    
    @staticmethod
    def _flatten_schema(schema: Dict[str, Any]) -> Dict[str, Any]:
        """
        展开 schema 中的 $ref 引用
        
        简化版实现，处理常见情况
        """
        # 暂时保持原样，复杂的展开可以后续实现
        return schema
    
    # ===== 解析方法 =====
    
    @classmethod
    async def parse(
        cls,
        content: str,
        model_class: Type[T],
        raw_tool_calls: Optional[List[Dict[str, Any]]] = None,
        strict: bool = True,
        auto_fix: bool = True,
    ) -> T:
        """
        解析文本为 Pydantic 模型
        
        参数:
            content: 文本内容
            model_class: 目标 Pydantic 模型类
            raw_tool_calls: 原始工具调用列表（优先使用）
            strict: 是否严格模式（False 时会尝试修复）
            auto_fix: 是否自动修复常见问题
        
        返回:
            模型实例
        
        异常:
            StructureParseError: 解析失败
        """
        attempts = []
        
        # 策略 1: 从 Tool Calls 提取
        if raw_tool_calls:
            for idx, call in enumerate(raw_tool_calls):
                try:
                    result = cls._parse_from_tool_call(call, model_class)
                    logger.info(
                        "Parsed from tool call",
                        model=model_class.__name__,
                        tool_call_index=idx
                    )
                    return result
                except Exception as e:
                    attempts.append({
                        "strategy": f"tool_call_{idx}",
                        "error": str(e)
                    })
                    logger.debug("Tool call parse failed", index=idx, error=str(e))
        
        # 策略 2-5: 从文本提取
        try:
            return cls._extract_json(content, model_class, strict=strict, auto_fix=auto_fix)
        except Exception as e:
            # 收集所有尝试的错误
            if hasattr(e, 'attempts'):
                attempts.extend(e.attempts)
            else:
                attempts.append({
                    "strategy": "text_extraction",
                    "error": str(e)
                })
            
            # 构建详细错误信息
            error_details = "\n".join(
                f"  - {a['strategy']}: {a['error'][:100]}"
                for a in attempts
            )
            
            raise StructureParseError(
                f"无法解析为 {model_class.__name__}。尝试了 {len(attempts)} 种策略:\n{error_details}",
                attempts=attempts,
                raw_content=content
            ) from e
    
    # ===== 内部解析方法 =====
    
    @classmethod
    def _parse_from_tool_call(
        cls,
        call: Dict[str, Any],
        model_class: Type[T]
    ) -> T:
        """从单个工具调用中解析"""
        func = call.get("function", {})
        args = func.get("arguments", "")
        
        # 解析参数
        if isinstance(args, str):
            data = json.loads(args)
        elif isinstance(args, dict):
            data = args
        else:
            raise ValueError(f"Invalid arguments type: {type(args)}")
        
        # 验证并创建模型实例
        return model_class(**data)
    
    @classmethod
    def _extract_json(
        cls,
        text: str,
        model_class: Type[T],
        strict: bool = True,
        auto_fix: bool = True,
    ) -> T:
        """
        从文本中提取 JSON 并解析为模型
        
        尝试多种策略：
        1. 直接解析整个文本
        2. 提取 Markdown 代码块
        3. 暴力括号匹配
        4. 清理并重试
        """
        text = text.strip()
        attempts = []
        
        # 策略 A: 直接 JSON
        try:
            data = json.loads(text)
            return model_class(**data)
        except json.JSONDecodeError as e:
            attempts.append({
                "strategy": "direct_json",
                "error": f"JSON 解码失败: {str(e)}"
            })
        except ValidationError as e:
            attempts.append({
                "strategy": "direct_json_validation",
                "error": f"验证失败: {str(e)}"
            })
        
        # 策略 B: Markdown 代码块
        markdown_patterns = [
            r"```json\s*([\s\S]*?)```",
            r"```\s*([\s\S]*?)```",
        ]
        
        for pattern_idx, pattern in enumerate(markdown_patterns):
            for match_idx, match in enumerate(re.finditer(pattern, text)):
                candidate = match.group(1).strip()
                try:
                    data = json.loads(candidate)
                    return model_class(**data)
                except Exception as e:
                    attempts.append({
                        "strategy": f"markdown_{pattern_idx}_{match_idx}",
                        "error": str(e)[:100]
                    })
        
        # 策略 C: 暴力括号匹配
        json_candidates = cls._extract_braced_json(text)
        for idx, candidate in enumerate(json_candidates):
            try:
                data = json.loads(candidate)
                return model_class(**data)
            except Exception as e:
                attempts.append({
                    "strategy": f"braced_{idx}",
                    "error": str(e)[:100]
                })
        
        # 策略 D: 清理并重试（如果启用 auto_fix）
        if auto_fix:
            cleaned = cls._clean_json_string(text)
            if cleaned != text:  # 有清理操作
                try:
                    data = json.loads(cleaned)
                    logger.info("Parsed after cleaning", model=model_class.__name__)
                    return model_class(**data)
                except Exception as e:
                    attempts.append({
                        "strategy": "cleaned_json",
                        "error": str(e)[:100]
                    })
        
        # 所有策略都失败
        error = StructureParseError(
            f"无法从文本中提取有效的 JSON",
            attempts=attempts,
            raw_content=text
        )
        error.attempts = attempts
        raise error
    
    @staticmethod
    def _extract_braced_json(text: str) -> List[str]:
        """
        使用栈提取所有 {...} 块
        
        改进：
        - 返回所有可能的 JSON 对象，不仅仅是第一个
        - 按长度排序，优先尝试最长的
        """
        candidates = []
        stack = []
        start = None
        
        for idx, ch in enumerate(text):
            if ch == "{":
                if not stack:
                    start = idx
                stack.append(ch)
            elif ch == "}" and stack:
                stack.pop()
                if not stack and start is not None:
                    candidates.append(text[start:idx + 1])
                    start = None
        
        # 按长度降序排序（更长的 JSON 可能更完整）
        candidates.sort(key=len, reverse=True)
        
        return candidates
    
    @staticmethod
    def _clean_json_string(text: str) -> str:
        """
        清理常见的 JSON 格式问题
        
        处理：
        - 单引号 -> 双引号
        - 尾部逗号
        - 注释
        - 控制字符
        """
        # 移除注释
        text = re.sub(r'//.*?\n', '\n', text)
        text = re.sub(r'/\*.*?\*/', '', text, flags=re.DOTALL)
        
        # 尝试修复单引号（简单情况）
        # 注意：这可能会误伤字符串内容，需谨慎
        # text = text.replace("'", '"')
        
        # 移除尾部逗号
        text = re.sub(r',(\s*[}\]])', r'\1', text)
        
        # 移除控制字符
        text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)
        
        return text.strip()
    
    # ===== 辅助方法 =====
    
    @classmethod
    def validate(cls, data: Dict[str, Any], model_class: Type[T]) -> T:
        """
        验证数据并创建模型实例
        
        参数:
            data: 数据字典
            model_class: 模型类
        
        返回:
            模型实例
        
        异常:
            ValidationError: 验证失败
        """
        try:
            return model_class(**data)
        except ValidationError as e:
            logger.error(
                "Model validation failed",
                model=model_class.__name__,
                errors=e.errors()
            )
            raise
    
    @classmethod
    def get_schema_diff(
        cls,
        data: Dict[str, Any],
        model_class: Type[BaseModel]
    ) -> Dict[str, Any]:
        """
        比较数据与 Schema 的差异
        
        参数:
            data: 实际数据
            model_class: 期望的模型
        
        返回:
            差异信息
        """
        schema = model_class.model_json_schema()
        required = set(schema.get("required", []))
        properties = schema.get("properties", {})
        
        data_keys = set(data.keys())
        schema_keys = set(properties.keys())
        
        return {
            "missing_required": list(required - data_keys),
            "extra_fields": list(data_keys - schema_keys),
            "type_mismatches": cls._check_type_mismatches(data, properties),
        }
    
    @staticmethod
    def _check_type_mismatches(
        data: Dict[str, Any],
        properties: Dict[str, Any]
    ) -> List[Dict[str, str]]:
        """检查类型不匹配"""
        mismatches = []
        
        for key, value in data.items():
            if key not in properties:
                continue
            
            expected_type = properties[key].get("type")
            actual_type = type(value).__name__
            
            # 简化的类型检查
            type_map = {
                "string": str,
                "integer": int,
                "number": (int, float),
                "boolean": bool,
                "array": list,
                "object": dict,
            }
            
            expected_python_type = type_map.get(expected_type)
            if expected_python_type and not isinstance(value, expected_python_type):
                mismatches.append({
                    "field": key,
                    "expected": expected_type,
                    "actual": actual_type,
                })
        
        return mismatches


# ===== 工具函数 =====

def parse_structured_output(
    content: str,
    model_class: Type[T],
    tool_calls: Optional[List[Dict[str, Any]]] = None,
) -> T:
    """
    同步版本的结构化输出解析（便捷函数）
    
    参数:
        content: 文本内容
        model_class: 目标模型类
        tool_calls: 工具调用列表
    
    返回:
        模型实例
    """
    import asyncio
    
    # 创建事件循环执行异步解析
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    
    return loop.run_until_complete(
        StructureEngine.parse(content, model_class, tool_calls)
    )


def extract_json_from_text(text: str) -> Optional[Dict[str, Any]]:
    """
    从文本中提取第一个有效的 JSON 对象
    
    参数:
        text: 文本内容
    
    返回:
        JSON 字典，如果未找到返回 None
    """
    # 尝试直接解析
    try:
        return json.loads(text.strip())
    except json.JSONDecodeError:
        pass
    
    # 尝试 Markdown
    pattern = r"```(?:json)?\s*([\s\S]*?)```"
    for match in re.finditer(pattern, text):
        try:
            return json.loads(match.group(1).strip())
        except json.JSONDecodeError:
            continue
    
    # 尝试括号匹配
    candidates = StructureEngine._extract_braced_json(text)
    for candidate in candidates:
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            continue
    
    return None
```

[22] gecko/core/toolbox.py
```python
# gecko/core/toolbox.py
"""
ToolBox - Agent 工具箱

核心功能：
1. 工具注册与管理
2. 单个/批量工具执行
3. 并发控制与超时管理
4. 执行统计与监控
5. OpenAI Function Calling Schema 生成

优化点：
- 修复并发控制的信号量使用方式（在任务内部 acquire/release）
- 线程安全的统计数据（使用 threading.Lock）
- 统一的返回值类型（ToolExecutionResult）
- 完善的错误处理和日志
- 可配置的重试机制
"""
from __future__ import annotations

import asyncio
import time
import threading
from collections import defaultdict
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

from anyio import create_task_group, fail_after, to_thread
from anyio import get_cancelled_exc_class  # ✅ 用于捕获取消异常

from gecko.config import settings
from gecko.core.exceptions import ToolError, ToolNotFoundError, ToolTimeoutError
from gecko.core.logging import get_logger
from gecko.plugins.tools.base import BaseTool

logger = get_logger(__name__)


# ===== 返回值模型 =====

@dataclass
class ToolExecutionResult:
    """
    工具执行结果（统一返回类型）
    
    属性:
        tool_name: 工具名称
        call_id: 调用 ID（用于关联请求）
        result: 执行结果（成功时为字符串，失败时为错误信息）
        is_error: 是否执行失败
        duration: 执行耗时（秒）
        metadata: 附加信息
    """
    tool_name: str
    call_id: str
    result: str
    is_error: bool
    duration: float = 0.0
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
    
    def to_dict(self) -> Dict[str, Any]:
        """转换为字典格式"""
        return {
            "tool_name": self.tool_name,
            "call_id": self.call_id,
            "result": self.result,
            "is_error": self.is_error,
            "duration": self.duration,
            "metadata": self.metadata,
        }


# ===== 工具箱主类 =====

class ToolBox:
    """
    Agent 工具箱
    
    负责工具的注册、执行、并发控制和统计。
    
    示例:
        ```python
        # 创建工具箱
        toolbox = ToolBox(
            tools=[search_tool, calculator],
            max_concurrent=5,
            default_timeout=30.0
        )
        
        # 单个工具执行
        result = await toolbox.execute(
            "search",
            {"query": "Python asyncio"}
        )
        print(result)  # "搜索结果：..."
        
        # 批量并发执行
        tool_calls = [
            {"id": "1", "name": "search", "arguments": {"query": "AI"}},
            {"id": "2", "name": "calculator", "arguments": {"expression": "2+2"}},
        ]
        results = await toolbox.execute_many(tool_calls)
        for r in results:
            print(f"{r.tool_name}: {r.result}")
        
        # 查看统计
        toolbox.print_stats()
        ```
    """

    def __init__(
        self,
        tools: Optional[List[BaseTool]] = None,
        max_concurrent: int = 5,
        default_timeout: float | None = None,
        enable_retry: bool = False,
        max_retries: int = 2,
    ):
        """
        初始化工具箱
        
        参数:
            tools: 初始工具列表
            max_concurrent: 最大并发执行数（默认 5）
            default_timeout: 默认超时时间（秒，默认读取配置）
            enable_retry: 是否启用工具执行重试（默认 False）
            max_retries: 最大重试次数（默认 2）
        """
        # 工具存储
        self._tools: Dict[str, BaseTool] = {}
        
        # 并发与超时配置
        self.max_concurrent = max_concurrent
        self.default_timeout = default_timeout or settings.tool_execution_timeout
        self.enable_retry = enable_retry
        self.max_retries = max_retries
        
        # 统计数据（线程安全）
        self._stats_lock = threading.Lock()
        self._execution_count: Dict[str, int] = defaultdict(int)
        self._error_count: Dict[str, int] = defaultdict(int)
        self._total_time: Dict[str, float] = defaultdict(float)
        
        # 注册初始工具
        if tools:
            for tool in tools:
                self.register(tool)
    
    # ====================== 工具管理 ======================
    
    def register(self, tool: BaseTool, replace: bool = True) -> "ToolBox":
        """
        注册工具
        
        参数:
            tool: 工具实例（必须继承 BaseTool）
            replace: 如果工具名已存在，是否替换（默认 True）
        
        返回:
            self（支持链式调用）
        
        异常:
            ValueError: 工具名已存在且 replace=False
            TypeError: 工具不继承 BaseTool
        """
        if not isinstance(tool, BaseTool):
            raise TypeError(
                f"工具必须继承 BaseTool，收到类型: {type(tool).__name__}"
            )
        
        if tool.name in self._tools and not replace:
            raise ValueError(
                f"工具 '{tool.name}' 已注册，如需覆盖请设置 replace=True"
            )
        
        if tool.name in self._tools:
            logger.warning(
                "Tool replaced",
                tool_name=tool.name,
                old_type=type(self._tools[tool.name]).__name__,
                new_type=type(tool).__name__
            )
        
        self._tools[tool.name] = tool
        
        # 初始化统计数据
        with self._stats_lock:
            if tool.name not in self._execution_count:
                self._execution_count[tool.name] = 0
                self._error_count[tool.name] = 0
                self._total_time[tool.name] = 0.0
        
        logger.info("Tool registered", tool_name=tool.name, description=tool.description[:50])
        return self
    
    def unregister(self, tool_name: str) -> "ToolBox":
        """
        注销工具
        
        参数:
            tool_name: 工具名称
        
        返回:
            self（支持链式调用）
        """
        if tool_name in self._tools:
            del self._tools[tool_name]
            logger.info("Tool unregistered", tool_name=tool_name)
        else:
            logger.warning("Attempt to unregister non-existent tool", tool_name=tool_name)
        
        return self
    
    def get(self, name: str) -> Optional[BaseTool]:
        """
        获取工具实例
        
        参数:
            name: 工具名称
        
        返回:
            工具实例，如果不存在返回 None
        """
        return self._tools.get(name)
    
    def list_tools(self) -> List[BaseTool]:
        """
        获取所有已注册的工具
        
        返回:
            工具列表
        """
        return list(self._tools.values())
    
    def has_tool(self, name: str) -> bool:
        """
        检查工具是否存在
        
        参数:
            name: 工具名称
        
        返回:
            是否存在
        """
        return name in self._tools
    
    # ====================== OpenAI Schema ======================
    
    def to_openai_schema(self) -> List[Dict[str, Any]]:
        """
        生成 OpenAI Function Calling 所需的 schema
        
        返回:
            工具定义列表，格式符合 OpenAI API 规范
        """
        schemas = []
        for tool in self._tools.values():
            schemas.append({
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": tool.parameters,
                }
            })
        return schemas
    
    # ====================== 单个工具执行 ======================
    
    async def execute(
        self,
        name: str,
        arguments: Dict[str, Any],
        timeout: Optional[float] = None,
        call_id: str = "",
    ) -> str:
        """
        执行单个工具（简化版，仅返回字符串）
        
        参数:
            name: 工具名称
            arguments: 工具参数（字典）
            timeout: 超时时间（秒），None 则使用默认值
            call_id: 调用 ID（可选，用于日志追踪）
        
        返回:
            执行结果字符串
        
        异常:
            ToolNotFoundError: 工具不存在
            ToolTimeoutError: 执行超时
            ToolError: 执行失败
        """
        result = await self.execute_with_result(name, arguments, timeout, call_id)
        
        if result.is_error:
            raise ToolError(
                f"工具 '{name}' 执行失败: {result.result}",
                context={
                    "tool_name": name,
                    "arguments": arguments,
                    "call_id": call_id,
                }
            )
        
        return result.result
    
    async def execute_with_result(
        self,
        name: str,
        arguments: Dict[str, Any],
        timeout: Optional[float] = None,
        call_id: str = "",
    ) -> ToolExecutionResult:
        """
        执行单个工具（完整版，返回结构化结果）
        
        参数:
            name: 工具名称
            arguments: 工具参数
            timeout: 超时时间（秒）
            call_id: 调用 ID
        
        返回:
            ToolExecutionResult 包含结果和元数据
        """
        # 检查工具是否存在
        tool = self.get(name)
        if not tool:
            self._update_stats(name, 0, is_error=True)
            raise ToolNotFoundError(name)
        
        actual_timeout = timeout or self.default_timeout
        start_time = time.time()
        
        logger.debug(
            "Tool execution started",
            tool=name,
            timeout=actual_timeout,
            call_id=call_id
        )
        
        # 执行（带重试）
        if self.enable_retry:
            result_str, is_error = await self._execute_with_retry(
                tool, arguments, actual_timeout, name
            )
        else:
            result_str, is_error = await self._execute_once(
                tool, arguments, actual_timeout, name
            )
        
        duration = time.time() - start_time
        
        # 更新统计
        self._update_stats(name, duration, is_error=is_error)
        
        # 记录日志
        if is_error:
            logger.error(
                "Tool execution failed",
                tool=name,
                duration=f"{duration:.3f}s",
                error=result_str[:200],
                call_id=call_id
            )
        else:
            logger.info(
                "Tool execution succeeded",
                tool=name,
                duration=f"{duration:.3f}s",
                result_length=len(result_str),
                call_id=call_id
            )
        
        return ToolExecutionResult(
            tool_name=name,
            call_id=call_id,
            result=result_str,
            is_error=is_error,
            duration=duration,
        )
    
    async def _execute_once(
    self,
    tool: BaseTool,
    arguments: Dict[str, Any],
    timeout: float,
    tool_name: str,
    ) -> tuple[str, bool]:
        """
        单次执行工具（内部方法）
        
        返回:
            (result_string, is_error)
        """
        try:
            # ✅ 使用同步 with（不是 async with）
            with fail_after(timeout):
                result = await tool.execute(arguments)
        except TimeoutError:
            # ✅ 捕获标准库的 TimeoutError（anyio.fail_after 会抛出这个）
            return f"工具执行超时（{timeout}秒）", True
        except get_cancelled_exc_class():
            # ✅ 防御性捕获：某些边缘情况可能只抛出 CancelledError
            return f"工具执行被取消（{timeout}秒）", True
        except Exception as e:
            logger.exception("Tool execution exception", tool=tool_name)
            return f"执行异常: {str(e)}", True
        
        # 确保返回字符串
        if isinstance(result, str):
            return result, False
        else:
            return str(result), False
    
    async def _execute_with_retry(
        self,
        tool: BaseTool,
        arguments: Dict[str, Any],
        timeout: float,
        tool_name: str,
    ) -> tuple[str, bool]:
        """
        带重试的工具执行
        
        返回:
            (result_string, is_error)
        """
        last_error = None
        
        for attempt in range(self.max_retries + 1):
            try:
                result_str, is_error = await self._execute_once(
                    tool, arguments, timeout, tool_name
                )
                
                if not is_error:
                    if attempt > 0:
                        logger.info(
                            "Tool succeeded after retry",
                            tool=tool_name,
                            attempt=attempt + 1
                        )
                    return result_str, False
                
                last_error = result_str
                
                # 如果还有重试机会，等待后重试
                if attempt < self.max_retries:
                    wait_time = 2 ** attempt  # 指数退避
                    logger.warning(
                        "Tool failed, retrying",
                        tool=tool_name,
                        attempt=attempt + 1,
                        max_retries=self.max_retries,
                        wait_time=wait_time,
                        error=result_str[:100]
                    )
                    await asyncio.sleep(wait_time)
                
            except Exception as e:
                last_error = str(e)
                if attempt < self.max_retries:
                    wait_time = 2 ** attempt
                    logger.warning(
                        "Tool exception, retrying",
                        tool=tool_name,
                        attempt=attempt + 1,
                        error=str(e)
                    )
                    await asyncio.sleep(wait_time)
        
        # 所有重试都失败
        return f"工具执行失败（已重试 {self.max_retries} 次）: {last_error}", True
    
    # ====================== 批量并发执行 ======================
    
    async def execute_many(
        self,
        tool_calls: List[Dict[str, Any]],
        timeout: Optional[float] = None
    ) -> List[ToolExecutionResult]:
        """
        并发执行多个工具，保持结果顺序与输入一致
        
        参数:
            tool_calls: 工具调用列表
            timeout: 单个工具的超时时间（秒）
        
        返回:
            ToolExecutionResult 列表，顺序与输入一致
        """
        if not tool_calls:
            return []
        
        logger.info(
            "Executing tools concurrently",
            count=len(tool_calls),
            max_concurrent=self.max_concurrent
        )
        
        # 预分配结果数组
        results: List[Optional[ToolExecutionResult]] = [None] * len(tool_calls)
        
        # ✅ 使用 anyio.Semaphore（同步创建）
        from anyio import Semaphore
        semaphore = Semaphore(self.max_concurrent)
        
        async def _run_one(idx: int, call: Dict[str, Any]):
            """执行单个工具（在信号量控制下）"""
            # ✅ 在任务内部使用信号量
            async with semaphore:
                tool_name = call.get("name", "")
                arguments = call.get("arguments", {})
                call_id = call.get("id", "")
                
                if not tool_name:
                    results[idx] = ToolExecutionResult(
                        tool_name="unknown",
                        call_id=call_id,
                        result="缺少工具名称",
                        is_error=True,
                    )
                    return
                
                try:
                    result = await self.execute_with_result(
                        tool_name,
                        arguments,
                        timeout,
                        call_id
                    )
                    results[idx] = result
                except Exception as e:
                    # 捕获所有异常，确保不影响其他任务
                    logger.error(
                        "Tool execution failed in batch",
                        tool=tool_name,
                        index=idx,
                        error=str(e)
                    )
                    results[idx] = ToolExecutionResult(
                        tool_name=tool_name,
                        call_id=call_id,
                        result=f"执行异常: {str(e)}",
                        is_error=True,
                    )
        
        # ✅ 并发执行
        async with create_task_group() as tg:
            for idx, call in enumerate(tool_calls):
                tg.start_soon(_run_one, idx, call)
        
        # 确保所有结果都已填充
        final_results = []
        for idx, result in enumerate(results):
            if result is None:
                # 理论上不应该发生，但作为保险
                logger.error("Missing result in batch execution", index=idx)
                final_results.append(ToolExecutionResult(
                    tool_name="unknown",
                    call_id="",
                    result="结果缺失",
                    is_error=True,
                ))
            else:
                final_results.append(result)
        
        logger.info(
            "Batch execution completed",
            total=len(final_results),
            successful=sum(1 for r in final_results if not r.is_error),
            failed=sum(1 for r in final_results if r.is_error)
        )
        
        return final_results
    
    # ====================== 统计信息 ======================
    
    def _update_stats(self, tool_name: str, duration: float, is_error: bool = False):
        """
        更新统计数据（线程安全）
        """
        with self._stats_lock:
            self._execution_count[tool_name] += 1
            self._total_time[tool_name] += duration
            if is_error:
                self._error_count[tool_name] += 1
    
    def get_stats(self) -> Dict[str, Dict[str, Any]]:
        """
        获取所有工具的统计信息
        """
        with self._stats_lock:
            stats = {}
            
            for tool_name in self._tools:
                exec_count = self._execution_count.get(tool_name, 0)
                error_count = self._error_count.get(tool_name, 0)
                total_time = self._total_time.get(tool_name, 0.0)
                
                stats[tool_name] = {
                    "executions": exec_count,
                    "errors": error_count,
                    "total_time": total_time,
                    "avg_time": total_time / exec_count if exec_count > 0 else 0.0,
                    "success_rate": (exec_count - error_count) / exec_count if exec_count > 0 else 1.0,
                }
            
            return stats
    
    def print_stats(self):
        """
        打印统计信息到控制台（格式化输出）
        """
        stats = self.get_stats()
        
        if not stats:
            print("\n=== ToolBox Statistics ===")
            print("No tools registered or executed.")
            return
        
        print("\n" + "=" * 60)
        print("ToolBox Statistics".center(60))
        print("=" * 60)
        
        for tool_name, data in sorted(stats.items()):
            print(f"\n📦 {tool_name}")
            print(f"   Executions:   {data['executions']}")
            print(f"   Errors:       {data['errors']}")
            print(f"   Success Rate: {data['success_rate']:.1%}")
            print(f"   Avg Time:     {data['avg_time']:.3f}s")
            print(f"   Total Time:   {data['total_time']:.3f}s")
        
        print("\n" + "=" * 60 + "\n")
    
    def reset_stats(self):
        """
        重置所有统计数据
        """
        with self._stats_lock:
            for tool_name in self._tools:
                self._execution_count[tool_name] = 0
                self._error_count[tool_name] = 0
                self._total_time[tool_name] = 0.0
        
        logger.info("Statistics reset")
    
    def get_summary(self) -> Dict[str, Any]:
        """
        获取工具箱的全局摘要
        """
        stats = self.get_stats()
        
        total_executions = sum(s["executions"] for s in stats.values())
        total_errors = sum(s["errors"] for s in stats.values())
        total_time = sum(s["total_time"] for s in stats.values())
        
        return {
            "tool_count": len(self._tools),
            "total_executions": total_executions,
            "total_errors": total_errors,
            "total_time": total_time,
            "overall_success_rate": (
                (total_executions - total_errors) / total_executions
                if total_executions > 0 else 1.0
            ),
            "avg_time_per_call": (
                total_time / total_executions
                if total_executions > 0 else 0.0
            ),
        }
    
    # ====================== 工具箱信息 ======================
    
    def __repr__(self) -> str:
        """字符串表示"""
        return (
            f"ToolBox(tools={len(self._tools)}, "
            f"max_concurrent={self.max_concurrent}, "
            f"default_timeout={self.default_timeout}s)"
        )
    
    def __len__(self) -> int:
        """返回工具数量"""
        return len(self._tools)
    
    def __contains__(self, tool_name: str) -> bool:
        """支持 'tool_name' in toolbox 语法"""
        return tool_name in self._tools
```

[23] gecko/core/utils.py
```python
# gecko/core/utils.py
"""
通用工具函数库

提供框架常用的工具函数，包括：
- 异步/同步统一处理
- 重试机制
- 超时控制
- 数据转换
- 字符串处理
- 装饰器

优化点：
1. 扩展工具函数集合
2. 添加超时和重试支持
3. 提供数据转换工具
4. 添加常用装饰器
"""
from __future__ import annotations

import asyncio
import functools
import hashlib
import inspect
import time
from typing import Any, Awaitable, Callable, Dict, List, Optional, TypeVar, Union

from gecko.core.logging import get_logger

logger = get_logger(__name__)

T = TypeVar("T")
R = TypeVar("R")


# ===== 异步/同步统一处理 =====

async def ensure_awaitable(
    func: Callable[..., T | Awaitable[T]],
    *args,
    timeout: Optional[float] = None,
    **kwargs
) -> T:
    """
    统一处理同步/异步函数调用
    
    参数:
        func: 可调用对象（同步或异步）
        *args: 位置参数
        timeout: 超时时间（秒），None 表示无限制
        **kwargs: 关键字参数
    
    返回:
        函数执行结果
    
    异常:
        asyncio.TimeoutError: 超时
        Exception: 函数执行异常
    
    示例:
        ```python
        # 同步函数
        result = await ensure_awaitable(sync_func, arg1, arg2)
        
        # 异步函数
        result = await ensure_awaitable(async_func, arg1, arg2)
        
        # 带超时
        result = await ensure_awaitable(func, timeout=5.0)
        ```
    """
    # 确定是否为协程函数
    if asyncio.iscoroutinefunction(func):
        coro = func(*args, **kwargs)
    else:
        result = func(*args, **kwargs)
        if asyncio.iscoroutine(result):
            coro = result
        else:
            # 同步函数，直接返回结果
            return result
    
    # 执行异步函数（带可选超时）
    if timeout:
        try:
            return await asyncio.wait_for(coro, timeout=timeout)
        except asyncio.TimeoutError:
            logger.warning(
                "Function execution timeout",
                func=getattr(func, "__name__", str(func)),
                timeout=timeout
            )
            raise
    else:
        return await coro


def run_sync(coro: Awaitable[T]) -> T:
    """
    在同步上下文中运行异步函数
    
    参数:
        coro: 协程对象
    
    返回:
        执行结果
    
    示例:
        ```python
        async def async_func():
            return "result"
        
        # 在同步代码中调用
        result = run_sync(async_func())
        ```
    """
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # 如果事件循环正在运行，创建新的事件循环
            import nest_asyncio
            nest_asyncio.apply()
            return loop.run_until_complete(coro)
        else:
            return loop.run_until_complete(coro)
    except RuntimeError:
        # 没有事件循环，创建新的
        return asyncio.run(coro)


# ===== 重试机制 =====

async def retry_async(
    func: Callable[..., Awaitable[T]],
    *args,
    max_attempts: int = 3,
    delay: float = 1.0,
    backoff: float = 2.0,
    exceptions: tuple = (Exception,),
    on_retry: Optional[Callable[[int, Exception], None]] = None,
    **kwargs
) -> T:
    """
    异步函数重试装饰器
    
    参数:
        func: 异步函数
        *args: 位置参数
        max_attempts: 最大尝试次数
        delay: 初始延迟（秒）
        backoff: 退避倍数
        exceptions: 需要重试的异常类型
        on_retry: 重试时的回调函数
        **kwargs: 关键字参数
    
    返回:
        函数执行结果
    
    异常:
        最后一次尝试的异常
    
    示例:
        ```python
        async def unstable_api_call():
            # 可能失败的 API 调用
            ...
        
        result = await retry_async(
            unstable_api_call,
            max_attempts=5,
            delay=2.0,
            backoff=2.0
        )
        ```
    """
    last_exception = None
    current_delay = delay
    
    for attempt in range(1, max_attempts + 1):
        try:
            return await func(*args, **kwargs)
        except exceptions as e:
            last_exception = e
            
            if attempt >= max_attempts:
                logger.error(
                    "All retry attempts failed",
                    func=getattr(func, "__name__", str(func)),
                    attempts=max_attempts,
                    error=str(e)
                )
                raise
            
            logger.warning(
                "Function failed, retrying",
                func=getattr(func, "__name__", str(func)),
                attempt=attempt,
                max_attempts=max_attempts,
                delay=current_delay,
                error=str(e)
            )
            
            if on_retry:
                try:
                    on_retry(attempt, e)
                except Exception as callback_error:
                    logger.warning("Retry callback failed", error=str(callback_error))
            
            await asyncio.sleep(current_delay)
            current_delay *= backoff
    
    raise last_exception


def retry(
    max_attempts: int = 3,
    delay: float = 1.0,
    backoff: float = 2.0,
    exceptions: tuple = (Exception,)
):
    """
    重试装饰器（支持同步和异步）
    
    参数:
        max_attempts: 最大尝试次数
        delay: 初始延迟（秒）
        backoff: 退避倍数
        exceptions: 需要重试的异常类型
    
    示例:
        ```python
        @retry(max_attempts=5, delay=2.0)
        async def unstable_function():
            # 可能失败的操作
            ...
        ```
    """
    def decorator(func: Callable) -> Callable:
        if asyncio.iscoroutinefunction(func):
            @functools.wraps(func)
            async def async_wrapper(*args, **kwargs):
                return await retry_async(
                    func,
                    *args,
                    max_attempts=max_attempts,
                    delay=delay,
                    backoff=backoff,
                    exceptions=exceptions,
                    **kwargs
                )
            return async_wrapper
        else:
            @functools.wraps(func)
            def sync_wrapper(*args, **kwargs):
                last_exception = None
                current_delay = delay
                
                for attempt in range(1, max_attempts + 1):
                    try:
                        return func(*args, **kwargs)
                    except exceptions as e:
                        last_exception = e
                        if attempt >= max_attempts:
                            raise
                        time.sleep(current_delay)
                        current_delay *= backoff
                
                raise last_exception
            
            return sync_wrapper
    
    return decorator


# ===== 数据转换 =====

def safe_dict(obj: Any, max_depth: int = 3, _current_depth: int = 0) -> Any:
    """
    安全地将对象转换为字典（递归处理）
    
    参数:
        obj: 要转换的对象
        max_depth: 最大递归深度
        _current_depth: 当前深度（内部使用）
    
    返回:
        字典或可序列化的值
    
    示例:
        ```python
        class MyClass:
            def __init__(self):
                self.name = "test"
                self.value = 123
        
        obj = MyClass()
        data = safe_dict(obj)
        # {"name": "test", "value": 123}
        ```
    """
    if _current_depth >= max_depth:
        return str(obj)[:100]
    
    # Pydantic 模型
    if hasattr(obj, "model_dump"):
        try:
            return obj.model_dump()
        except Exception:
            pass
    
    # 字典
    if isinstance(obj, dict):
        return {
            str(k): safe_dict(v, max_depth, _current_depth + 1)
            for k, v in obj.items()
        }
    
    # 列表/元组
    if isinstance(obj, (list, tuple)):
        return [safe_dict(item, max_depth, _current_depth + 1) for item in obj]
    
    # 基本类型
    if isinstance(obj, (str, int, float, bool, type(None))):
        return obj
    
    # 对象属性
    if hasattr(obj, "__dict__"):
        return {
            k: safe_dict(v, max_depth, _current_depth + 1)
            for k, v in obj.__dict__.items()
            if not k.startswith("_")
        }
    
    # 其他情况：转字符串
    return str(obj)[:200]


def merge_dicts(*dicts: Dict, deep: bool = False) -> Dict:
    """
    合并多个字典
    
    参数:
        *dicts: 要合并的字典
        deep: 是否深度合并
    
    返回:
        合并后的字典
    
    示例:
        ```python
        d1 = {"a": 1, "b": {"x": 1}}
        d2 = {"b": {"y": 2}, "c": 3}
        
        # 浅合并
        result = merge_dicts(d1, d2)
        # {"a": 1, "b": {"y": 2}, "c": 3}
        
        # 深合并
        result = merge_dicts(d1, d2, deep=True)
        # {"a": 1, "b": {"x": 1, "y": 2}, "c": 3}
        ```
    """
    if not dicts:
        return {}
    
    result = {}
    
    for d in dicts:
        if not isinstance(d, dict):
            continue
        
        for key, value in d.items():
            if deep and key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = merge_dicts(result[key], value, deep=True)
            else:
                result[key] = value
    
    return result


# ===== 字符串处理 =====

def truncate(
    text: str,
    max_length: int = 100,
    suffix: str = "..."
) -> str:
    """
    截断文本
    
    参数:
        text: 文本
        max_length: 最大长度
        suffix: 后缀
    
    返回:
        截断后的文本
    """
    if len(text) <= max_length:
        return text
    
    return text[:max_length - len(suffix)] + suffix


def format_size(size_bytes: int) -> str:
    """
    格式化字节大小
    
    参数:
        size_bytes: 字节数
    
    返回:
        可读的大小字符串
    
    示例:
        ```python
        format_size(1024)       # "1.00 KB"
        format_size(1048576)    # "1.00 MB"
        format_size(1073741824) # "1.00 GB"
        ```
    """
    for unit in ["B", "KB", "MB", "GB", "TB"]:
        if size_bytes < 1024.0:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.2f} PB"


def format_duration(seconds: float) -> str:
    """
    格式化时长
    
    参数:
        seconds: 秒数
    
    返回:
        可读的时长字符串
    
    示例:
        ```python
        format_duration(65)    # "1m 5s"
        format_duration(3665)  # "1h 1m 5s"
        ```
    """
    if seconds < 60:
        return f"{seconds:.1f}s"
    
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    
    if minutes < 60:
        return f"{minutes}m {secs}s"
    
    hours = minutes // 60
    minutes = minutes % 60
    
    return f"{hours}h {minutes}m {secs}s"


def compute_hash(text: str, algorithm: str = "md5") -> str:
    """
    计算文本的哈希值
    
    参数:
        text: 文本
        algorithm: 算法（md5/sha1/sha256）
    
    返回:
        哈希值（十六进制字符串）
    
    示例:
        ```python
        hash_value = compute_hash("Hello, World!")
        ```
    """
    if algorithm == "md5":
        hasher = hashlib.md5()
    elif algorithm == "sha1":
        hasher = hashlib.sha1()
    elif algorithm == "sha256":
        hasher = hashlib.sha256()
    else:
        raise ValueError(f"不支持的哈希算法: {algorithm}")
    
    hasher.update(text.encode("utf-8"))
    return hasher.hexdigest()


# ===== 性能监控 =====

class Timer:
    """
    简单的计时器（上下文管理器）
    
    示例:
        ```python
        with Timer("操作名称") as t:
            # 执行耗时操作
            do_something()
        
        print(f"耗时: {t.elapsed:.2f}s")
        ```
    """
    
    def __init__(self, name: str = "Timer", log: bool = True):
        self.name = name
        self.log = log
        self.start_time = None
        self.end_time = None
        self.elapsed = 0.0
    
    def __enter__(self):
        self.start_time = time.time()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.end_time = time.time()
        self.elapsed = self.end_time - self.start_time
        
        if self.log:
            logger.info(
                "Timer completed",
                name=self.name,
                elapsed=f"{self.elapsed:.3f}s"
            )
        
        return False


def timing(func: Callable) -> Callable:
    """
    计时装饰器（支持同步和异步）
    
    示例:
        ```python
        @timing
        async def slow_function():
            await asyncio.sleep(1)
        ```
    """
    if asyncio.iscoroutinefunction(func):
        @functools.wraps(func)
        async def async_wrapper(*args, **kwargs):
            start = time.time()
            try:
                result = await func(*args, **kwargs)
                return result
            finally:
                elapsed = time.time() - start
                logger.info(
                    "Function executed",
                    func=func.__name__,
                    elapsed=f"{elapsed:.3f}s"
                )
        return async_wrapper
    else:
        @functools.wraps(func)
        def sync_wrapper(*args, **kwargs):
            start = time.time()
            try:
                result = func(*args, **kwargs)
                return result
            finally:
                elapsed = time.time() - start
                logger.info(
                    "Function executed",
                    func=func.__name__,
                    elapsed=f"{elapsed:.3f}s"
                )
        return sync_wrapper


# ===== 函数签名工具 =====

def get_function_args(func: Callable) -> List[str]:
    """
    获取函数的参数名列表
    
    参数:
        func: 函数对象
    
    返回:
        参数名列表
    """
    sig = inspect.signature(func)
    return [
        name for name, param in sig.parameters.items()
        if param.kind in (
            inspect.Parameter.POSITIONAL_OR_KEYWORD,
            inspect.Parameter.KEYWORD_ONLY,
        )
    ]


def has_argument(func: Callable, arg_name: str) -> bool:
    """
    检查函数是否有指定参数
    
    参数:
        func: 函数对象
        arg_name: 参数名
    
    返回:
        是否存在该参数
    """
    return arg_name in get_function_args(func)


# ===== 其他工具 =====

def chunk_list(lst: List[T], chunk_size: int) -> List[List[T]]:
    """
    将列表分块
    
    参数:
        lst: 列表
        chunk_size: 每块大小
    
    返回:
        分块后的列表
    
    示例:
        ```python
        chunks = chunk_list([1, 2, 3, 4, 5], chunk_size=2)
        # [[1, 2], [3, 4], [5]]
        ```
    """
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]


def flatten_list(nested: List[List[T]]) -> List[T]:
    """
    展平嵌套列表
    
    参数:
        nested: 嵌套列表
    
    返回:
        展平后的列表
    
    示例:
        ```python
        flat = flatten_list([[1, 2], [3, 4], [5]])
        # [1, 2, 3, 4, 5]
        ```
    """
    return [item for sublist in nested for item in sublist]


def deduplicate(
    items: List[T],
    key: Optional[Callable[[T], Any]] = None
) -> List[T]:
    """
    列表去重（保持顺序）
    
    参数:
        items: 列表
        key: 可选的键函数
    
    返回:
        去重后的列表
    
    示例:
        ```python
        # 简单去重
        unique = deduplicate([1, 2, 2, 3, 1])
        # [1, 2, 3]
        
        # 按属性去重
        users = [{"id": 1, "name": "A"}, {"id": 1, "name": "B"}]
        unique = deduplicate(users, key=lambda u: u["id"])
        ```
    """
    seen = set()
    result = []
    
    for item in items:
        k = key(item) if key else item
        
        # 处理不可哈希的情况
        try:
            if k not in seen:
                seen.add(k)
                result.append(item)
        except TypeError:
            # 不可哈希，使用 == 比较
            if not any(k == s for s in seen):
                seen.add(k)
                result.append(item)
    
    return result


# ===== 向后兼容导出 =====

__all__ = [
    # 异步工具
    "ensure_awaitable",
    "run_sync",
    # 重试
    "retry",
    "retry_async",
    # 数据转换
    "safe_dict",
    "merge_dicts",
    # 字符串
    "truncate",
    "format_size",
    "format_duration",
    "compute_hash",
    # 性能
    "Timer",
    "timing",
    # 函数工具
    "get_function_args",
    "has_argument",
    # 列表工具
    "chunk_list",
    "flatten_list",
    "deduplicate",
]
```

[24] gecko/plugins/__init__.py
```python
```

[25] gecko/plugins/base.py
```python
# gecko/plugins/base.py  
  
"""  
占位：未来可在此定义所有插件的抽象基类或通用接口。  
目前实际内容请参考各子目录（tools/ storage/ knowledge 等）。  
"""  
```

[26] gecko/plugins/guardrails/__init__.py
```python
```

[27] gecko/plugins/guardrails/pii.py
```python
```

[28] gecko/plugins/knowledge/__init__.py
```python
# gecko/plugins/knowledge/__init__.py
from gecko.plugins.knowledge.document import Document
from gecko.plugins.knowledge.interfaces import EmbedderProtocol
from gecko.plugins.knowledge.embedders import OpenAIEmbedder, OllamaEmbedder
from gecko.plugins.knowledge.splitters import RecursiveCharacterTextSplitter
from gecko.plugins.knowledge.pipeline import IngestionPipeline
from gecko.plugins.knowledge.tool import RetrievalTool

__all__ = [
    "Document", 
    "EmbedderProtocol", 
    "OpenAIEmbedder", 
    "OllamaEmbedder",
    "RecursiveCharacterTextSplitter",
    "IngestionPipeline",
    "RetrievalTool"
]
```

[29] gecko/plugins/knowledge/base.py
```python
```

[30] gecko/plugins/knowledge/default.py
```python
```

[31] gecko/plugins/knowledge/document.py
```python
# gecko/plugins/knowledge/document.py
from __future__ import annotations
from uuid import uuid4
from typing import Dict, Any, Optional, List
from pydantic import BaseModel, Field

class Document(BaseModel):
    """
    Gecko 标准文档对象
    在 Pipeline 中流转的核心数据结构
    """
    id: str = Field(default_factory=lambda: str(uuid4()))
    text: str
    metadata: Dict[str, Any] = Field(default_factory=dict)
    embedding: Optional[List[float]] = None

    def to_dict(self) -> Dict[str, Any]:
        """转换为存储层所需的字典格式"""
        return {
            "id": self.id,
            "text": self.text,
            "metadata": self.metadata,
            "embedding": self.embedding
        }
```

[32] gecko/plugins/knowledge/embedders.py
```python
# gecko/plugins/knowledge/embedders.py
from __future__ import annotations
import os
from typing import List
import litellm
from gecko.plugins.knowledge.interfaces import EmbedderProtocol

class OpenAIEmbedder(EmbedderProtocol):
    """
    基于 LiteLLM 的通用 Embedder
    支持 OpenAI, Azure, Ollama 等所有 LiteLLM 支持的 embedding 模型
    """
    def __init__(self, model: str = "text-embedding-3-small", dimension: int = 1536, **kwargs):
        self.model = model
        self._dimension = dimension
        self.kwargs = kwargs

    @property
    def dimension(self) -> int:
        return self._dimension

    async def embed_documents(self, texts: List[str]) -> List[List[float]]:
        # 替换换行符以提升某些模型的表现
        texts = [t.replace("\n", " ") for t in texts]
        response = await litellm.aembedding(
            model=self.model,
            input=texts,
            **self.kwargs
        )
        return [r["embedding"] for r in response.data]

    async def embed_query(self, text: str) -> List[float]:
        text = text.replace("\n", " ")
        response = await litellm.aembedding(
            model=self.model,
            input=[text],
            **self.kwargs
        )
        return response.data[0]["embedding"]

# 预设 Ollama 配置
class OllamaEmbedder(OpenAIEmbedder):
    """
    Ollama 本地嵌入模型适配器
    """
    def __init__(self, model: str = "ollama/nomic-embed-text", base_url: str = "http://localhost:11434", dimension: int = 768):
        super().__init__(
            model=model, 
            dimension=dimension, 
            api_base=base_url
        )
```

[33] gecko/plugins/knowledge/interfaces.py
```python
# gecko/plugins/knowledge/interfaces.py
from __future__ import annotations
from typing import List, Protocol, runtime_checkable

@runtime_checkable
class EmbedderProtocol(Protocol):
    """
    嵌入模型协议
    负责将文本转换为向量
    """
    @property
    def dimension(self) -> int:
        """返回向量维度 (例如 1536)"""
        ...

    async def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """批量嵌入文档列表"""
        ...

    async def embed_query(self, text: str) -> List[float]:
        """嵌入单个查询语句"""
        ...

@runtime_checkable
class ReaderProtocol(Protocol):
    """
    文件读取协议
    """
    def load(self, file_path: str) -> str:
        """读取文件内容为字符串"""
        ...
```

[34] gecko/plugins/knowledge/pipeline.py
```python
# gecko/plugins/knowledge/pipeline.py
from typing import List, Optional
from gecko.plugins.knowledge.interfaces import EmbedderProtocol
from gecko.plugins.storage.interfaces import VectorInterface
from gecko.plugins.knowledge.splitters import RecursiveCharacterTextSplitter
from gecko.plugins.knowledge.readers import AutoReader
from gecko.core.utils import ensure_awaitable

class IngestionPipeline:
    """
    RAG 数据入库流水线
    Load -> Split -> Embed -> Store
    """
    def __init__(
        self,
        vector_store: VectorInterface,
        embedder: EmbedderProtocol,
        splitter = None
    ):
        self.vector_store = vector_store
        self.embedder = embedder
        self.splitter = splitter or RecursiveCharacterTextSplitter()

    async def run(self, file_paths: List[str], batch_size: int = 100):
        """
        执行入库流程
        :param file_paths: 文件路径列表
        :param batch_size: 向量库写入批次大小
        """
        print(f"🚀 开始处理 {len(file_paths)} 个文件...")
        
        # 1. Load
        raw_docs = []
        for path in file_paths:
            try:
                docs = AutoReader.read(path)
                raw_docs.extend(docs)
            except Exception as e:
                print(f"⚠️ 读取失败 {path}: {e}")

        # 2. Split
        chunks = self.splitter.split_documents(raw_docs)
        print(f"✂️ 切分为 {len(chunks)} 个片段")

        # 3. Embed & Store (Batch Processing)
        for i in range(0, len(chunks), batch_size):
            batch = chunks[i : i + batch_size]
            texts = [doc.text for doc in batch]
            
            # 生成向量
            embeddings = await ensure_awaitable(self.embedder.embed_documents, texts)
            
            # 注入向量到文档对象
            docs_to_upsert = []
            for doc, emb in zip(batch, embeddings):
                doc.embedding = emb
                docs_to_upsert.append(doc.to_dict())
            
            # 写入数据库
            await self.vector_store.upsert(docs_to_upsert)
            print(f"💾 已存储批次 {i} - {i+len(batch)}")
            
        print("✅ 入库完成")
```

[35] gecko/plugins/knowledge/readers.py
```python
# gecko/plugins/knowledge/readers.py
import os
from pathlib import Path
from typing import List
from gecko.plugins.knowledge.document import Document
from gecko.plugins.knowledge.interfaces import ReaderProtocol

class TextReader(ReaderProtocol):
    """简单文本读取器 (.txt, .md, .py, etc)"""
    def load(self, file_path: str) -> str:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()

class PDFReader(ReaderProtocol):
    """PDF 读取器 (依赖 pypdf)"""
    def load(self, file_path: str) -> str:
        try:
            import pypdf
        except ImportError:
            raise ImportError("请安装 pypdf 以支持 PDF 读取: pip install pypdf")
            
        text = ""
        with open(file_path, "rb") as f:
            reader = pypdf.PdfReader(f)
            for page in reader.pages:
                text += page.extract_text() + "\n"
        return text

class AutoReader:
    """自动分发读取器"""
    _READERS = {
        ".txt": TextReader,
        ".md": TextReader,
        ".py": TextReader,
        ".json": TextReader,
        ".pdf": PDFReader
    }

    @classmethod
    def read(cls, file_path: str) -> List[Document]:
        path = Path(file_path)
        ext = path.suffix.lower()
        
        reader_cls = cls._READERS.get(ext)
        if not reader_cls:
            raise ValueError(f"不支持的文件类型: {ext}")
        
        content = reader_cls().load(str(path))
        return [Document(text=content, metadata={"source": str(path), "filename": path.name})]
```

[36] gecko/plugins/knowledge/splitters.py
```python
# gecko/plugins/knowledge/splitters.py
from typing import List
from gecko.plugins.knowledge.document import Document

class RecursiveCharacterTextSplitter:
    """
    递归字符切分器 (参考 LangChain 逻辑)
    尝试按顺序使用分隔符切分文本，直到块大小符合要求。
    """
    def __init__(
        self, 
        chunk_size: int = 1000, 
        chunk_overlap: int = 200,
        separators: List[str] | None = None
    ):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.separators = separators or ["\n\n", "\n", " ", ""]

    def split_documents(self, documents: List[Document]) -> List[Document]:
        """切分文档列表"""
        final_docs = []
        for doc in documents:
            chunks = self.split_text(doc.text)
            for i, chunk in enumerate(chunks):
                # 继承元数据，并增加切片信息
                new_meta = doc.metadata.copy()
                new_meta.update({"chunk_index": i, "source_id": doc.id})
                final_docs.append(Document(text=chunk, metadata=new_meta))
        return final_docs

    def split_text(self, text: str) -> List[str]:
        """切分单文本核心逻辑"""
        final_chunks = []
        if self._length(text) <= self.chunk_size:
            return [text]
            
        # 找到最优分隔符
        separator = self.separators[-1]
        for sep in self.separators:
            if sep == "":
                separator = ""
                break
            if sep in text:
                separator = sep
                break
                
        # 切分
        splits = text.split(separator) if separator else list(text)
        
        # 合并碎片
        good_splits = []
        current_chunk = ""
        
        for s in splits:
            if self._length(current_chunk) + self._length(s) < self.chunk_size:
                current_chunk += (separator if current_chunk else "") + s
            else:
                if current_chunk:
                    good_splits.append(current_chunk)
                current_chunk = s
        
        if current_chunk:
            good_splits.append(current_chunk)
            
        return good_splits

    def _length(self, text: str) -> int:
        return len(text)
```

[37] gecko/plugins/knowledge/tool.py
```python
# gecko/plugins/knowledge/tool.py
from typing import Type
from pydantic import BaseModel, Field
from gecko.plugins.tools.base import BaseTool
from gecko.plugins.storage.interfaces import VectorInterface
from gecko.plugins.knowledge.interfaces import EmbedderProtocol
from gecko.core.utils import ensure_awaitable

class RetrievalTool(BaseTool):
    name: str = "knowledge_search"
    description: str = "搜索内部知识库以获取相关信息。当问题涉及特定文档、报告或私有数据时使用。"
    parameters: dict = {
        "type": "object",
        "properties": {
            "query": {
                "type": "string", 
                "description": "用于在知识库中检索的查询语句"
            }
        },
        "required": ["query"]
    }

    def __init__(self, vector_store: VectorInterface, embedder: EmbedderProtocol, top_k: int = 3):
        super().__init__()
        # Private attributes are not Pydantic fields
        object.__setattr__(self, "_vector_store", vector_store)
        object.__setattr__(self, "_embedder", embedder)
        object.__setattr__(self, "_top_k", top_k)

    async def execute(self, arguments: dict) -> str:
        query = arguments.get("query")
        if not query:
            return "错误：查询语句为空"

        # 1. Embed Query
        query_vec = await ensure_awaitable(self._embedder.embed_query, query)
        
        # 2. Vector Search
        results = await self._vector_store.search(query_vec, top_k=self._top_k)
        
        if not results:
            return "未在知识库中找到相关内容。"
            
        # 3. Format Results
        context = "找到以下相关内容：\n\n"
        for i, res in enumerate(results, 1):
            source = res['metadata'].get('filename', 'unknown')
            score = f"{res['score']:.2f}" if 'score' in res else 'N/A'
            context += f"--- 文档 {i} (来源: {source}, 相关度: {score}) ---\n{res['text']}\n\n"
            
        return context
```

[38] gecko/plugins/models/__init__.py
```python
```

[39] gecko/plugins/models/anthropic.py
```python
```

[40] gecko/plugins/models/gemini.py
```python
```

[41] gecko/plugins/models/groq.py
```python
```

[42] gecko/plugins/models/litellm.py
```python
# gecko/plugins/models/litellm.py
from __future__ import annotations

import os
from typing import Any

import litellm
from pydantic import BaseModel


class LiteLLMModel(BaseModel):
    """
    Gecko 官方推荐模型适配器：支持任意 OpenAI-compatible 私有部署
    用法示例：
        .with_model(
            model="kimi-k2-thinking",
            base_url="http://172.19.37.104:8095/v1",
            api_key="optional",
            temperature=0.7
        )
    """
    model: str
    base_url: str | None = None
    api_key: str | None = None
    temperature: float = 0.7
    max_tokens: int | None = None
    timeout: float = 300.0
    # 支持所有 litellm 参数
    extra_kwargs: dict[str, Any] = {}

    def model_post_init(self, __context) -> None:
        # 优先使用显式传入的参数
        if self.base_url:
            litellm.api_base = self.base_url
        if self.api_key:
            os.environ.setdefault("OPENAI_API_KEY", self.api_key)

    async def acompletion(self, messages: list[dict], **kwargs) -> Any:
        params = {
            "model": self.model,
            "messages": messages,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "timeout": self.timeout,
            "custom_llm_provider": "openai",  # 关键：强制走 OpenAI 协议
            **self.extra_kwargs,
            **kwargs,
        }
        if self.base_url:
            params["api_base"] = self.base_url
        if self.api_key:
            params["api_key"] = self.api_key

        return await litellm.acompletion(**params)
```

[43] gecko/plugins/models/openai.py
```python
```

[44] gecko/plugins/models/zhipu.py
```python
# gecko/plugins/models/zhipu.py
from __future__ import annotations

import os
from typing import Any, AsyncIterator # [新增] 导入 AsyncIterator

import litellm
from pydantic import BaseModel, Field

ZHIPU_BASE_URL = "https://open.bigmodel.cn/api/paas/v4/"

class ZhipuGLM(BaseModel):
    model: str = "glm-4.5-air"
    api_key: str = Field(
        default="3bd5e6fdc377489c80dbb435b84d7560.izN8bDXCVR1FNSYS",
        description="智谱官方 API Key"
    )
    base_url: str = Field(default=ZHIPU_BASE_URL, exclude=True)
    temperature: float = 0.7
    max_tokens: int | None = None
    timeout: float = 300.0
    extra_kwargs: dict[str, Any] = Field(default_factory=dict)

    def model_post_init(self, __context) -> None:
        os.environ.setdefault("ZHIPU_API_KEY", self.api_key)

    async def acompletion(self, messages: list[dict], **kwargs) -> Any:
        # [保持不变]
        params = {
            "model": self.model,
            "messages": messages, # 这里的 messages 已经被 Engine 序列化为标准字典了
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "timeout": self.timeout,
            "custom_llm_provider": "openai",
            "api_base": self.base_url,
            "api_key": self.api_key,
            **self.extra_kwargs,
            **kwargs,
        }
        return await litellm.acompletion(**params)

    # [新增] 实现流式接口
    async def astream(self, messages: list[dict], **kwargs) -> AsyncIterator[Any]:
        params = {
            "model": self.model,
            "messages": messages,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "timeout": self.timeout,
            "custom_llm_provider": "openai",
            "api_base": self.base_url,
            "api_key": self.api_key,
            "stream": True,  # 开启流式
            **self.extra_kwargs,
            **kwargs,
        }
        
        # litellm 在 stream=True 时返回 AsyncGenerator
        response_iterator = await litellm.acompletion(**params)
        async for chunk in response_iterator:
            yield chunk

def glm_4_5_air(api_key: str | None = None, **kwargs) -> ZhipuGLM:
    return ZhipuGLM(api_key=api_key or "3bd5e6fdc377489c80dbb435b84d7560.izN8bDXCVR1FNSYS", **kwargs)
```

[45] gecko/plugins/registry.py
```python
# gecko/plugins/registry.py  
  
"""  
占位：预留统一插件注册机制的位置。  
  
TODO:  
    - 整合 tools/storage 等注册器  
    - 支持入口点加载第三方插件  
"""  
```

[46] gecko/plugins/storage/__init__.py
```python
# gecko/plugins/storage/__init__.py
from gecko.plugins.storage.factory import get_storage_by_url
from gecko.plugins.storage.interfaces import SessionInterface, VectorInterface

# 显式导入以触发 @register_storage 装饰器
import gecko.plugins.storage.sqlite
import gecko.plugins.storage.redis
try:
    import gecko.plugins.storage.lancedb
except ImportError:
    pass # 允许用户不安装 lancedb

# Postgres 依赖较重，通常作为 extra 安装，这里尝试可选导入
try:
    import gecko.plugins.storage.postgres_pgvector
except ImportError:
    pass

__all__ = ["get_storage_by_url", "SessionInterface", "VectorInterface"]
```

[47] gecko/plugins/storage/base.py
```python
# gecko/plugins/storage/base.py
from __future__ import annotations
from pydantic import BaseModel, Field, AnyUrl

class BaseStorageConfig(BaseModel):
    """
    纯配置类：只包含 Pydantic 可验证的字段
    - 用于所有存储插件的统一配置
    - 避免运行时对象混入 Pydantic 模型导致冲突
    """
    storage_url: AnyUrl = Field(..., description="存储连接 URL，例如 sqlite://./db.db 或 lancedb://./db")
    collection_name: str = Field(default="gecko_default", description="集合/表名")
    embedding_dim: int = Field(default=1536, description="向量维度，默认兼容主流 LLM")
    
    model_config = {"arbitrary_types_allowed": False, "extra": "forbid"}  # 严格模式，避免任意类型
```

[48] gecko/plugins/storage/chroma.py
```python
# gecko/plugins/storage/chroma.py
from __future__ import annotations
import chromadb
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
from typing import List, Dict, Any
from gecko.plugins.storage.registry import register_storage
from gecko.plugins.storage.interfaces import SessionInterface, VectorInterface

@register_storage("chroma")
class ChromaStorage(SessionInterface, VectorInterface):
    """
    生产级本地存储插件：Chroma
    - URL 示例：chroma://./chroma_db
    - 特点：持久化目录、自动嵌入（SentenceTransformer）、支持 Session + Vector
    - 适用：本地开发到中小型生产（<100万向量）
    """
    def __init__(self, storage_url: str, collection_name: str = "gecko_default", **kwargs):
        db_path = storage_url.removeprefix("chroma://")
        self.client = chromadb.PersistentClient(path=db_path)
        self.embedding_fn = SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
        
        self.vector_collection = self.client.get_or_create_collection(
            name=collection_name,
            embedding_function=self.embedding_fn
        )
        self.session_collection = self.client.get_or_create_collection(name="gecko_sessions")

    # Session 接口
    async def get(self, session_id: str) -> Dict[str, Any] | None:
        result = self.session_collection.get(ids=[session_id], include=["metadatas"])
        return result["metadatas"][0] if result["metadatas"] else None

    async def set(self, session_id: str, state: Dict[str, Any]):
        self.session_collection.upsert(ids=[session_id], metadatas=[state])

    async def delete(self, session_id: str):
        self.session_collection.delete(ids=[session_id])

    # Vector 接口
    async def upsert(self, documents: List[Dict]):
        self.vector_collection.upsert(
            ids=[d["id"] for d in documents],
            documents=[d["text"] for d in documents],
            metadatas=[d.get("metadata", {}) for d in documents],
            embeddings=[d.get("embedding") for d in documents]  # 可选外部嵌入
        )

    async def search(self, query_embedding: List[float], top_k: int = 5):
        results = self.vector_collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["documents", "metadatas", "distances"]
        )
        return [
            {
                "text": doc,
                "metadata": meta,
                "score": 1 - dist  # 转为相似度
            }
            for doc, meta, dist in zip(
                results["documents"][0],
                results["metadatas"][0],
                results["distances"][0]
            )
        ]
```

[49] gecko/plugins/storage/factory.py
```python
# gecko/plugins/storage/factory.py
from __future__ import annotations
import importlib
import logging
from urllib.parse import urlparse
from gecko.plugins.storage.registry import _STORAGE_FACTORIES

logger = logging.getLogger(__name__)

def get_storage_by_url(storage_url: str, required: str = "any", **overrides) -> Any:
    """
    根据 URL 自动初始化对应的存储后端
    """
    if "://" in storage_url:
        scheme = storage_url.split("://")[0]
    else:
        raise ValueError(f"无效的存储 URL: {storage_url}")

    # 1. 查找已注册的工厂
    factory = _STORAGE_FACTORIES.get(scheme)

    # 2. [优化] 如果未找到，尝试动态导入同名模块 (gecko.plugins.storage.{scheme})
    if not factory:
        try:
            module_name = f"gecko.plugins.storage.{scheme}"
            logger.debug(f"尝试动态加载存储插件: {module_name}")
            importlib.import_module(module_name)
            # 重新获取
            factory = _STORAGE_FACTORIES.get(scheme)
        except ImportError as e:
            # 如果是因为缺少依赖包（如 lancedb），抛出更明确的错误
            if scheme in str(e) and "No module named" not in str(e):
                raise ImportError(f"加载存储插件 {scheme} 失败，请安装对应依赖: {e}")
            pass
        except Exception as e:
            logger.warning(f"动态加载存储插件 {scheme} 失败: {e}")

    if not factory:
        # 尝试加载外部插件（entry_points）
        raise ValueError(f"未找到存储实现: {scheme}。\n"
                         f"请确保：\n"
                         f"1. 已安装对应依赖 (如 `rye add lancedb`)\n"
                         f"2. URL 协议头正确 (如 lancedb://)")

    instance = factory(storage_url, **overrides)
    
    # 简单的接口检查
    if required == "session" and not hasattr(instance, "get"):
         raise TypeError(f"存储 {scheme} 不支持 Session 接口")
    if required == "vector" and not hasattr(instance, "search"):
         raise TypeError(f"存储 {scheme} 不支持 Vector 接口")

    return instance
```

[50] gecko/plugins/storage/interfaces.py
```python
# gecko/plugins/storage/interfaces.py
from __future__ import annotations
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional

class SessionInterface(ABC):
    """
    Session 存储接口协议
    负责 Agent 的短期记忆（Conversation History）和状态（State）的持久化
    """
    @abstractmethod
    async def get(self, session_id: str) -> Dict[str, Any] | None:
        """
        获取会话状态
        :param session_id: 会话唯一标识
        :return: 状态字典，如果不存在返回 None
        """
        pass

    @abstractmethod
    async def set(self, session_id: str, state: Dict[str, Any]) -> None:
        """
        设置/更新会话状态
        :param session_id: 会话唯一标识
        :param state: 要保存的状态字典（需可 JSON 序列化）
        """
        pass

    @abstractmethod
    async def delete(self, session_id: str) -> None:
        """
        删除会话
        :param session_id: 会话唯一标识
        """
        pass

class VectorInterface(ABC):
    """
    Vector 存储接口协议 (RAG 用)
    负责文档的向量存储与检索
    """
    @abstractmethod
    async def upsert(self, documents: List[Dict[str, Any]]) -> None:
        """
        插入或更新向量文档
        :param documents: 文档列表，每项需包含 id, embedding, text, metadata
        """
        pass

    @abstractmethod
    async def search(self, query_embedding: List[float], top_k: int = 5) -> List[Dict]:
        """
        向量相似度搜索
        :param query_embedding: 查询向量
        :param top_k: 返回结果数量
        :return: 包含 text, metadata, score 的结果列表
        """
        pass
```

[51] gecko/plugins/storage/lancedb.py
```python
# gecko/plugins/storage/lancedb.py
from __future__ import annotations
import lancedb
import pyarrow as pa
from typing import List, Dict
from gecko.plugins.storage.registry import register_storage
from gecko.plugins.storage.interfaces import VectorInterface

@register_storage("lancedb")
class LanceDBVectorStorage(VectorInterface):
    """
    快速开发专用 Vector 存储插件
    - URL 示例：lancedb://./dev_vector_db
    - 特点：纯 Python、本地目录存储、毫秒启动、支持 ANN 搜索
    - 适用：本地 RAG 验证
    - 注意：首次 upsert 时自动创建表
    """
    def __init__(self, storage_url: str, collection_name: str = "gecko_default", embedding_dim: int = 1536, **kwargs):
        db_path = storage_url.removeprefix("lancedb://")
        self.db = lancedb.connect(db_path)
        self.collection_name = collection_name
        self.embedding_dim = embedding_dim
        # 检查表是否存在
        if collection_name in self.db.table_names():
            self.table = self.db.open_table(collection_name)
        else:
            self.table = None

    async def upsert(self, documents: List[Dict]):
        """插入/更新文档，首次自动创建表"""
        if not documents:
            return

        # 构造 pyarrow 表数据
        data = pa.table({
            "id": [d["id"] for d in documents],
            "vector": [d["embedding"] for d in documents],
            "text": [d["text"] for d in documents],
            "metadata": [d.get("metadata", {}) for d in documents]
        })

        if self.table is None:
            self.table = self.db.create_table(self.collection_name, data=data)
        else:
            self.table.add(data)

    async def search(self, query_embedding: List[float], top_k: int = 5):
        """搜索相似文档"""
        if self.table is None:
            return []

        # [修复] 使用 to_list() 替代 to_pylist()
        results = self.table.search(query_embedding).limit(top_k).to_list()
        return [
            {"text": r["text"], "metadata": r["metadata"], "score": 1 - r["_distance"]}
            for r in results
        ]
```

[52] gecko/plugins/storage/milvus.py
```python
# gecko/plugins/storage/milvus.py
from __future__ import annotations
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType
from typing import List, Dict
from gecko.plugins.storage.registry import register_storage
from gecko.plugins.storage.interfaces import VectorInterface

@register_storage("milvus")
class MilvusStorage(VectorInterface):
    """
    超大规模生产级 Vector 存储：Milvus
    - URL 示例：milvus://localhost:19530
    - 特点：支持十亿级向量、分布式
    """
    def __init__(self, storage_url: str, collection_name: str = "gecko_default", embedding_dim: int = 1536, **kwargs):
        uri = storage_url.removeprefix("milvus://")
        connections.connect(uri=uri)
        self.collection_name = collection_name
        
        if not Collection.has_collection(collection_name):
            fields = [
                FieldSchema(name="id", dtype=DataType.VARCHAR, is_primary=True, max_length=500),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim),
                FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=65535),
                FieldSchema(name="metadata", dtype=DataType.JSON)
            ]
            schema = CollectionSchema(fields)
            self.collection = Collection(collection_name, schema)
            self.collection.create_index("embedding", {"index_type": "IVF_FLAT", "metric_type": "IP", "params": {"nlist": 128}})
        else:
            self.collection = Collection(collection_name)
        self.collection.load()

    async def upsert(self, documents: List[Dict]):
        self.collection.insert([
            [d["id"] for d in documents],
            [d["embedding"] for d in documents],
            [d["text"] for d in documents],
            [d.get("metadata", {}) for d in documents]
        ])

    async def search(self, query_embedding: List[float], top_k: int = 5):
        params = {"metric_type": "IP", "params": {"nprobe": 16}}
        results = self.collection.search([query_embedding], "embedding", params, top_k, output_fields=["text", "metadata"])
        return [
            {"text": r.entity.get("text"), "metadata": r.entity.get("metadata"), "score": r.distance}
            for r in results[0]
        ]
```

[53] gecko/plugins/storage/postgres_pgvector.py
```python
# gecko/plugins/storage/postgres_pgvector.py
from __future__ import annotations
import json
from typing import List, Dict, Any

try:
    import asyncpg
except ImportError:
    raise ImportError("请安装 asyncpg: pip install asyncpg")

from gecko.plugins.storage.registry import register_storage
from gecko.plugins.storage.interfaces import SessionInterface, VectorInterface

@register_storage("postgres+pgvector")
class PostgresPgVectorStorage(SessionInterface, VectorInterface):
    """
    基于 PostgreSQL 的企业级存储
    同时支持 Session (JSONB) 和 Vector (pgvector)
    URL 示例: postgres+pgvector://user:pass@localhost:5432/dbname
    """
    def __init__(self, storage_url: str, collection_name: str = "gecko_default", **kwargs):
        # 移除自定义协议头，还原为标准 postgres URL
        self.dsn = storage_url.replace("postgres+pgvector://", "postgresql://")
        self.collection_name = collection_name
        self._pool = None
        
    async def _get_pool(self):
        if not self._pool:
            self._pool = await asyncpg.create_pool(self.dsn)
            await self._init_schema()
        return self._pool

    async def _init_schema(self):
        """初始化数据库 Schema"""
        async with self._pool.acquire() as conn:
            # 1. 启用 pgvector 扩展
            await conn.execute("CREATE EXTENSION IF NOT EXISTS vector")
            
            # 2. 创建 Session 表
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS gecko_sessions (
                    session_id TEXT PRIMARY KEY,
                    state JSONB,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # 3. 创建 Vector 表
            # 注意：这里假设 embedding 维度为 1536 (OpenAI)，生产环境应动态处理
            await conn.execute(f"""
                CREATE TABLE IF NOT EXISTS gecko_vectors (
                    id TEXT PRIMARY KEY,
                    collection TEXT,
                    embedding vector(1536),
                    text TEXT,
                    metadata JSONB,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            # 创建向量索引 (IVFFlat)
            # await conn.execute("CREATE INDEX ON gecko_vectors USING ivfflat (embedding vector_cosine_ops)")

    # --- Session Interface ---
    
    async def get(self, session_id: str) -> Dict[str, Any] | None:
        pool = await self._get_pool()
        row = await pool.fetchrow(
            "SELECT state FROM gecko_sessions WHERE session_id = $1", 
            session_id
        )
        return json.loads(row['state']) if row else None

    async def set(self, session_id: str, state: Dict[str, Any]) -> None:
        pool = await self._get_pool()
        state_json = json.dumps(state)
        await pool.execute("""
            INSERT INTO gecko_sessions (session_id, state) 
            VALUES ($1, $2)
            ON CONFLICT (session_id) 
            DO UPDATE SET state = $2, updated_at = CURRENT_TIMESTAMP
        """, session_id, state_json)

    async def delete(self, session_id: str) -> None:
        pool = await self._get_pool()
        await pool.execute("DELETE FROM gecko_sessions WHERE session_id = $1", session_id)

    # --- Vector Interface ---

    async def upsert(self, documents: List[Dict[str, Any]]) -> None:
        pool = await self._get_pool()
        async with pool.acquire() as conn:
            async with conn.transaction():
                for doc in documents:
                    await conn.execute("""
                        INSERT INTO gecko_vectors (id, collection, embedding, text, metadata)
                        VALUES ($1, $2, $3, $4, $5)
                        ON CONFLICT (id) DO UPDATE 
                        SET embedding = $3, text = $4, metadata = $5
                    """, 
                    doc["id"], 
                    self.collection_name, 
                    doc["embedding"], 
                    doc["text"], 
                    json.dumps(doc.get("metadata", {}))
                    )

    async def search(self, query_embedding: List[float], top_k: int = 5) -> List[Dict]:
        pool = await self._get_pool()
        # 使用 <=> 操作符计算余弦距离 (Cosine Distance)
        # 相似度 = 1 - 距离
        rows = await pool.fetch("""
            SELECT text, metadata, 1 - (embedding <=> $1) as score
            FROM gecko_vectors
            WHERE collection = $2
            ORDER BY embedding <=> $1
            LIMIT $3
        """, query_embedding, self.collection_name, top_k)
        
        return [
            {
                "text": r["text"],
                "metadata": json.loads(r["metadata"]),
                "score": r["score"]
            } for r in rows
        ]
```

[54] gecko/plugins/storage/qdrant.py
```python
# gecko/plugins/storage/qdrant.py
from __future__ import annotations
from typing import List, Dict
try:
    from qdrant_client import QdrantClient
    from qdrant_client.http.models import Distance, VectorParams, PointStruct
except ImportError:
    raise ImportError("请安装 qdrant-client: pip install qdrant-client")

from gecko.plugins.storage.registry import register_storage
from gecko.plugins.storage.interfaces import VectorInterface

@register_storage("qdrant")
class QdrantStorage(VectorInterface):
    """
    Qdrant 向量存储实现
    URL 示例: qdrant://localhost:6333
    """
    def __init__(self, storage_url: str, collection_name: str = "gecko_default", embedding_dim: int = 1536, **kwargs):
        url = storage_url.removeprefix("qdrant://")
        # 支持内存模式
        if url == ":memory:":
            self.client = QdrantClient(":memory:")
        else:
            self.client = QdrantClient(url=f"http://{url}")
            
        self.collection_name = collection_name
        
        # 检查并创建集合
        if not self.client.collection_exists(collection_name):
            self.client.create_collection(
                collection_name=collection_name,
                vectors_config=VectorParams(size=embedding_dim, distance=Distance.COSINE)
            )

    async def upsert(self, documents: List[Dict]):
        if not documents:
            return
        points = [
            PointStruct(
                id=d["id"],
                vector=d["embedding"],
                payload={"text": d["text"], "metadata": d.get("metadata", {})}
            )
            for d in documents
        ]
        # Qdrant 客户端方法通常是同步的，但在 gecko 协议中我们包装为异步
        self.client.upsert(collection_name=self.collection_name, points=points)

    async def search(self, query_embedding: List[float], top_k: int = 5):
        results = self.client.search(
            collection_name=self.collection_name,
            query_vector=query_embedding,
            limit=top_k
        )
        return [
            {
                "text": r.payload["text"], # type: ignore
                "metadata": r.payload["metadata"], # type: ignore
                "score": r.score
            }
            for r in results
        ]
```

[55] gecko/plugins/storage/redis.py
```python
# gecko/plugins/storage/redis.py
from __future__ import annotations
import json
from typing import Dict, Any

try:
    import redis.asyncio as redis
except ImportError:
    raise ImportError("请安装 redis 客户端: pip install redis")

from gecko.plugins.storage.registry import register_storage
from gecko.plugins.storage.interfaces import SessionInterface

@register_storage("redis")
class RedisStorage(SessionInterface):
    """
    基于 Redis 的高性能 Session 存储
    URL 示例: redis://localhost:6379/0
    """
    def __init__(self, storage_url: str, ttl: int = 3600 * 24 * 7, **kwargs):
        """
        :param storage_url: Redis 连接 URL
        :param ttl: 数据过期时间（秒），默认 7 天
        """
        # redis-py 可以直接解析 redis:// URL
        self.client = redis.from_url(storage_url, decode_responses=True)
        self.ttl = ttl
        self.prefix = "gecko:session:"

    async def get(self, session_id: str) -> Dict[str, Any] | None:
        key = f"{self.prefix}{session_id}"
        data = await self.client.get(key)
        if data:
            return json.loads(data)
        return None

    async def set(self, session_id: str, state: Dict[str, Any]) -> None:
        key = f"{self.prefix}{session_id}"
        json_str = json.dumps(state, ensure_ascii=False)
        # 设置值并重置过期时间
        await self.client.set(key, json_str, ex=self.ttl)

    async def delete(self, session_id: str) -> None:
        key = f"{self.prefix}{session_id}"
        await self.client.delete(key)
        
    async def close(self):
        await self.client.aclose()
```

[56] gecko/plugins/storage/registry.py
```python
# gecko/plugins/storage/registry.py
from __future__ import annotations
from typing import Dict, Callable, Type, Any

# 存储后端工厂注册表
_STORAGE_FACTORIES: Dict[str, Callable] = {}

def register_storage(scheme: str):
    """
    装饰器：注册存储后端实现
    :param scheme: URL 协议前缀，如 'sqlite', 'redis', 'postgres'
    """
    def decorator(cls):
        if scheme in _STORAGE_FACTORIES:
            raise ValueError(f"存储方案 '{scheme}' 已注册")
        
        # 包装为工厂函数
        def factory(storage_url: str, **overrides):
            return cls(storage_url=storage_url, **overrides)
            
        _STORAGE_FACTORIES[scheme] = factory
        return cls
    return decorator

def get_storage_factory(scheme: str) -> Callable | None:
    """获取指定协议的工厂函数"""
    return _STORAGE_FACTORIES.get(scheme)
```

[57] gecko/plugins/storage/sqlite.py
```python
# gecko/plugins/storage/sqlite.py (改进版)
from __future__ import annotations
import json
from pathlib import Path
from typing import Dict, Any, Optional

from sqlmodel import SQLModel, Field, create_engine, select, Session as SQLSession

from gecko.plugins.storage.registry import register_storage
from gecko.plugins.storage.interfaces import SessionInterface
from gecko.plugins.storage.utils import parse_storage_url, validate_storage_url  # ✅ 使用统一解析
from gecko.core.logging import get_logger

logger = get_logger(__name__)

class SessionModel(SQLModel, table=True):
    """会话数据模型"""
    __tablename__ = "gecko_sessions"
    session_id: str = Field(primary_key=True)
    state_json: str = Field(default="{}")

@register_storage("sqlite")
class SQLiteSessionStorage(SessionInterface):
    """
    SQLite 会话存储（改进版）
    
    改进：
    1. 使用统一 URL 解析
    2. 支持 URL 参数
    3. 更好的错误处理
    """
    
    def __init__(self, storage_url: str, **kwargs):
        # ✅ 使用统一解析
        validate_storage_url(storage_url, required_scheme="sqlite")
        scheme, db_path, params = parse_storage_url(storage_url)
        
        # 处理 :memory:
        if db_path == ":memory:":
            self.db_path = ":memory:"
        else:
            self.db_path = db_path
            # 创建父目录
            if db_path != ":memory:":
                path_obj = Path(db_path)
                if not path_obj.parent.exists():
                    path_obj.parent.mkdir(parents=True, exist_ok=True)
                    logger.info("Created database directory", path=str(path_obj.parent))
        
        # 应用 URL 参数
        timeout = params.get("timeout", "30")
        
        # 创建引擎
        connect_args = {"timeout": int(timeout)}
        self.engine = create_engine(
            f"sqlite:///{self.db_path}",
            echo=False,
            connect_args=connect_args
        )
        
        # 建表
        SQLModel.metadata.create_all(self.engine)
        logger.info("SQLite storage initialized", db_path=self.db_path)

    async def get(self, session_id: str) -> Dict[str, Any] | None:
        """获取会话状态"""
        try:
            with SQLSession(self.engine) as session:
                statement = select(SessionModel).where(
                    SessionModel.session_id == session_id
                )
                result = session.exec(statement).first()
                
                if result:
                    return json.loads(result.state_json)
                return None
        except Exception as e:
            logger.error("Failed to get session", session_id=session_id, error=str(e))
            raise

    async def set(self, session_id: str, state: Dict[str, Any]) -> None:
        """设置会话状态"""
        try:
            with SQLSession(self.engine) as session:
                statement = select(SessionModel).where(
                    SessionModel.session_id == session_id
                )
                existing = session.exec(statement).first()
                
                json_str = json.dumps(state, ensure_ascii=False)
                
                if existing:
                    existing.state_json = json_str
                    session.add(existing)
                else:
                    new_session = SessionModel(
                        session_id=session_id,
                        state_json=json_str
                    )
                    session.add(new_session)
                
                session.commit()
        except Exception as e:
            logger.error("Failed to set session", session_id=session_id, error=str(e))
            raise

    async def delete(self, session_id: str) -> None:
        """删除会话"""
        try:
            with SQLSession(self.engine) as session:
                statement = select(SessionModel).where(
                    SessionModel.session_id == session_id
                )
                result = session.exec(statement).first()
                
                if result:
                    session.delete(result)
                    session.commit()
        except Exception as e:
            logger.error("Failed to delete session", session_id=session_id, error=str(e))
            raise
```

[58] gecko/plugins/storage/utils.py
```python
# gecko/plugins/storage/utils.py
"""
Storage 插件工具函数

提供：
1. 统一的 URL 解析
2. 连接参数验证
3. URL 构建工具
"""
from __future__ import annotations
from urllib.parse import urlparse, parse_qs, urlencode
from typing import Tuple, Dict, Any
from gecko.core.exceptions import StorageError

def parse_storage_url(url: str) -> Tuple[str, str, Dict[str, str]]:
    """
    解析存储 URL
    
    格式：scheme://path?param1=value1&param2=value2
    
    返回：(scheme, path, params)
    
    示例:
        parse_storage_url("sqlite://./data.db?timeout=30")
        => ("sqlite", "./data.db", {"timeout": "30"})
        
        parse_storage_url("redis://localhost:6379/0?password=secret")
        => ("redis", "localhost:6379/0", {"password": "secret"})
    """
    if "://" not in url:
        raise StorageError(
            f"Invalid storage URL: '{url}'. Must include scheme (e.g., sqlite://)",
            context={"url": url}
        )
    
    parsed = urlparse(url)
    
    # 1. 提取 scheme
    scheme = parsed.scheme
    if not scheme:
        raise StorageError(
            f"Missing scheme in URL: '{url}'",
            context={"url": url}
        )
    
    # 2. 提取 path
    # 对于 sqlite://./data.db，path 是 './data.db'
    # 对于 redis://localhost:6379，netloc 是 'localhost:6379'
    if parsed.path and parsed.path != "/":
        # 有路径，使用路径
        path = parsed.path
        if path.startswith("/"):
            path = path[1:]  # 移除开头的 /
        
        # 如果有 netloc，拼接
        if parsed.netloc:
            path = f"{parsed.netloc}/{path}"
    else:
        # 无路径或路径为 /，使用 netloc
        path = parsed.netloc or ""
    
    # 3. 解析查询参数
    params: Dict[str, str] = {}
    if parsed.query:
        query_dict = parse_qs(parsed.query)
        # 只取第一个值（简化处理）
        params = {k: v[0] for k, v in query_dict.items()}
    
    return scheme, path, params

def build_storage_url(
    scheme: str,
    path: str,
    **params
) -> str:
    """
    构建存储 URL
    
    示例:
        build_storage_url("sqlite", "./data.db", timeout=30)
        => "sqlite://./data.db?timeout=30"
    """
    url = f"{scheme}://{path}"
    
    if params:
        query = urlencode(params)
        url += f"?{query}"
    
    return url

def validate_storage_url(url: str, required_scheme: str | None = None):
    """
    验证存储 URL
    
    参数:
        url: URL 字符串
        required_scheme: 要求的 scheme（如 'sqlite'）
    
    抛出:
        StorageError: 如果验证失败
    """
    try:
        scheme, path, params = parse_storage_url(url)
    except Exception as e:
        raise StorageError(
            f"Invalid storage URL: {e}",
            context={"url": url}
        ) from e
    
    # 检查 scheme
    if required_scheme and scheme != required_scheme:
        raise StorageError(
            f"Invalid scheme '{scheme}', expected '{required_scheme}'",
            context={"url": url, "expected": required_scheme, "actual": scheme}
        )
    
    # 检查 path
    if not path and scheme not in ["memory"]:  # :memory: 可以没有 path
        raise StorageError(
            f"Missing path in URL: '{url}'",
            context={"url": url}
        )

# ========== 常用 URL 工厂 ==========

def make_sqlite_url(
    db_path: str = "./gecko_data.db",
    timeout: int | None = None
) -> str:
    """创建 SQLite URL"""
    params = {}
    if timeout:
        params["timeout"] = str(timeout)
    
    return build_storage_url("sqlite", db_path, **params)

def make_redis_url(
    host: str = "localhost",
    port: int = 6379,
    db: int = 0,
    password: str | None = None
) -> str:
    """创建 Redis URL"""
    path = f"{host}:{port}/{db}"
    params = {}
    if password:
        params["password"] = password
    
    return build_storage_url("redis", path, **params)

def make_postgres_url(
    user: str,
    password: str,
    host: str = "localhost",
    port: int = 5432,
    database: str = "gecko"
) -> str:
    """创建 PostgreSQL URL"""
    path = f"{user}:{password}@{host}:{port}/{database}"
    return build_storage_url("postgres+pgvector", path)
```

[59] gecko/plugins/tools/__init__.py
```python
```

[60] gecko/plugins/tools/base.py
```python
from __future__ import annotations  
  
from typing import Any, Dict, Optional, Type  
  
from pydantic import BaseModel, Field, ValidationError  
  
from gecko.core.utils import ensure_awaitable  
  
  
class ToolResult(BaseModel):  
    content: str  
    is_error: bool = False  
    metadata: Dict[str, Any] = Field(default_factory=dict)  
  
  
class ToolArgsModel(BaseModel):  
    """可选：工具参数模型。"""  
    pass  
  
  
class BaseTool(BaseModel):  
    name: str = Field(..., description="工具唯一名称")  
    description: str = Field(..., description="工具功能描述")  
    parameters: Dict[str, Any] = Field(  
        default_factory=lambda: {"type": "object", "properties": {}, "required": []},  
        description="OpenAI 风格的参数 schema",  
    )  
    args_model: Optional[Type[ToolArgsModel]] = None  # 子类如需校验参数，可设置该字段  
  
    async def execute(self, arguments: Dict[str, Any]) -> ToolResult:  
        """  
        通用执行入口：  
        1. 如声明 args_model，则先用 Pydantic 校验  
        2. 调用 _execute_impl（可同步/异步）  
        3. 返回 ToolResult  
        """  
        payload = arguments  
        if self.args_model:  
            try:  
                payload = self.args_model(**arguments)  
            except ValidationError as e:  
                return ToolResult(content=str(e), is_error=True)  
  
        result = await ensure_awaitable(self._execute_impl, payload)  
        if isinstance(result, ToolResult):  
            return result  
        return ToolResult(content=str(result))  
  
    def _execute_impl(self, arguments: Any) -> ToolResult:  
        """子类需要实现具体逻辑，参数为校验后的对象或原始 dict"""  
        raise NotImplementedError("子类必须实现 _execute_impl")  
```

[61] gecko/plugins/tools/calculator.py
```python
from __future__ import annotations  
  
from typing import Any, Dict, Type  
  
from pydantic import BaseModel, Field  
  
from gecko.plugins.tools.base import BaseTool, ToolResult  
from gecko.plugins.tools.registry import tool  
  
  
class CalculatorArgs(BaseModel):  
    expression: str = Field(..., description="数学表达式，例如：(1 + 2) * 3")  
  
  
@tool  
class CalculatorTool(BaseTool):  
    name: str = "calculator"  
    description: str = "执行安全的数学计算，支持加减乘除等"  
    parameters: Dict[str, Any] = CalculatorArgs.model_json_schema()  
    args_model: Type[CalculatorArgs] = CalculatorArgs  
  
    def _execute_impl(self, args: CalculatorArgs) -> ToolResult:  
        expr = args.expression.strip()  
        allowed = set("0123456789.+-*/() ")  
        if not all(c in allowed for c in expr):  
            return ToolResult(content="错误：表达式包含非法字符", is_error=True)  
  
        try:  
            result = eval(expr, {"__builtins__": {}})  
            return ToolResult(content=f"计算结果：{result}")  
        except Exception as e:  
            return ToolResult(content=f"计算错误：{e}", is_error=True)  
```

[62] gecko/plugins/tools/duckduckgo.py
```python
from __future__ import annotations  
  
from typing import Any, Dict, Type  
  
from duckduckgo_search import DDGS  
from pydantic import BaseModel, Field  
  
from gecko.plugins.tools.base import BaseTool, ToolResult  
from gecko.plugins.tools.registry import tool  
  
  
class DuckDuckGoArgs(BaseModel):  
    query: str = Field(..., description="搜索关键词")  
  
  
@tool  
class DuckDuckGoSearch(BaseTool):  
    name: str = "duckduckgo_search"  
    description: str = "使用 DuckDuckGo 搜索互联网，返回前 5 条结果（无需 API Key）"  
    parameters: Dict[str, Any] = DuckDuckGoArgs.model_json_schema()  
    args_model: Type[DuckDuckGoArgs] = DuckDuckGoArgs  
  
    async def _execute_impl(self, args: DuckDuckGoArgs) -> ToolResult:  
        query = args.query.strip()  
        if not query:  
            return ToolResult(content="错误：搜索关键词为空", is_error=True)  
  
        try:  
            with DDGS() as ddgs:  
                results = list(ddgs.text(query, max_results=5))  
        except Exception as e:  
            return ToolResult(content=f"搜索失败：{e}", is_error=True)  
  
        if not results:  
            return ToolResult(content="未找到相关结果")  
  
        lines = [f"{i+1}. {r['title']}\n   {r['href']}" for i, r in enumerate(results)]  
        return ToolResult(content="搜索结果：\n" + "\n".join(lines))  
```

[63] gecko/plugins/tools/executor.py
```python
from __future__ import annotations  
  
from typing import Any, Dict, List, Optional  
  
import anyio  
  
from gecko.plugins.tools.base import ToolResult  
from gecko.plugins.tools.registry import ToolRegistry  
  
  
class ToolExecutor:  
    @staticmethod  
    async def concurrent_execute(  
        tool_calls: List[Dict[str, Any]],  
        *,  
        raise_on_error: bool = False,  
        max_concurrent: int = 5,  
    ) -> List[ToolResult]:  
        results: List[Optional[ToolResult]] = [None] * len(tool_calls)  
  
        async def _run_one(idx: int, call: Dict[str, Any]):  
            tool_name = call.get("name")  
            arguments = call.get("arguments", {})  
            tool = ToolRegistry.get(tool_name)  
            if not tool:  
                res = ToolResult(content=f"工具 {tool_name} 未找到", is_error=True)  
            else:  
                try:  
                    res = await tool.execute(arguments)  
                except Exception as e:  
                    res = ToolResult(content=f"执行失败: {e}", is_error=True)  
            results[idx] = res  
            if raise_on_error and res.is_error:  
                raise RuntimeError(res.content)  
  
        async with anyio.create_task_group() as tg:  
            sem = anyio.Semaphore(max_concurrent)  
            for idx, call in enumerate(tool_calls):  
                await sem.acquire()  
                tg.start_soon(ToolExecutor._run_with_sem, sem, _run_one, idx, call)  
  
        return [r for r in results if r]  
  
    @staticmethod  
    async def _run_with_sem(sem: anyio.Semaphore, fn, *args):  
        try:  
            await fn(*args)  
        finally:  
            sem.release()  
```

[64] gecko/plugins/tools/registry.py
```python
from __future__ import annotations  
  
from typing import Dict, List, Optional, Type  
  
from gecko.plugins.tools.base import BaseTool  
  
  
class ToolRegistry:  
    _tools: Dict[str, BaseTool | Type[BaseTool]] = {}  
  
    @classmethod  
    def register(cls, tool: BaseTool | Type[BaseTool], *, replace: bool = True):  
        instance = tool if isinstance(tool, BaseTool) else tool()  
        if instance.name in cls._tools and not replace:  
            raise ValueError(f"工具 '{instance.name}' 已注册")  
        cls._tools[instance.name] = tool  # 保留原对象（类或实例）  
  
    @classmethod  
    def get(cls, name: str) -> Optional[BaseTool]:  
        tool = cls._tools.get(name)  
        if tool is None:  
            return None  
        if isinstance(tool, type):  
            tool = tool()  
            cls._tools[name] = tool  
        return tool  
  
    @classmethod  
    def list_all(cls) -> List[str]:  
        return list(cls._tools.keys())  
  
  
def tool(cls: Type[BaseTool]):  
    ToolRegistry.register(cls, replace=True)  
    return cls  
```

[65] gecko/utils/cleanup.py
```python
# gecko/utils/cleanup.py
import atexit
import asyncio

def register_litellm_cleanup():
    """在进程退出时优雅关闭 LiteLLM 异步客户端，避免 RuntimeWarning"""
    def _cleanup():
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # 如果循环还在运行，调度清理任务
                loop.create_task(_close_clients())
            else:
                # 循环已关闭，直接新开一个临时循环执行清理
                asyncio.run(_close_clients())
        except Exception:
            pass  # 防止清理本身抛错

    async def _close_clients():
        try:
            import litellm
            # LiteLLM 官方提供的异步关闭方法（v1.40+ 支持）
            if hasattr(litellm, "async_http_handler"):
                if litellm.async_http_handler:
                    await litellm.async_http_handler.client.close()
            # 兼容旧版本
            if hasattr(litellm, "http_client"):
                if litellm.http_client:
                    await litellm.http_client.close()
        except Exception:
            pass

    atexit.register(_cleanup)

# 自动注册（模块导入即生效）
register_litellm_cleanup()
```

